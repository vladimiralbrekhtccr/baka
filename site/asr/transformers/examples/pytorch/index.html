
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../../../../assets/favicon.ico">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.22">
    
    
      
        <title>Index - Ohayou</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.84d31ad4.min.css">
      
        
        <link rel="stylesheet" href="../../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../../assets/extra.css">
    
    <script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#examples" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../.." title="Ohayou" class="md-header__button md-logo" aria-label="Ohayou" data-md-component="logo">
      
  <img src="../../../../assets/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Ohayou
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Index
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../ohayou/" class="md-tabs__link">
        
  
  
    
  
  Ohayou

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../vllm/open_ai_vllm_example_a_v_t/" class="md-tabs__link">
          
  
  
    
  
  vLLM

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../llm/speculative_decoding/" class="md-tabs__link">
          
  
  
    
  
  LLM

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../vlm/qwen3_vl_4B_object_detection/" class="md-tabs__link">
          
  
  
    
  
  VLM

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../md_format_helpers/" class="md-tabs__link">
        
  
  
    
  
  MD format helpers

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../docker/" class="md-tabs__link">
        
  
  
    
  
  Docker

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../linux/" class="md-tabs__link">
        
  
  
    
  
  Linux

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../moe/" class="md-tabs__link">
        
  
  
    
  
  Mixture of Experts

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../slurm/" class="md-tabs__link">
        
  
  
    
  
  Slurm

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../japanese-phrases/" class="md-tabs__link">
          
  
  
    
  
  Japanese Phrases

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../hackathon/index.md" class="md-tabs__link">
        
  
  
    
  
  Hack

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="Ohayou" class="md-nav__button md-logo" aria-label="Ohayou" data-md-component="logo">
      
  <img src="../../../../assets/logo.png" alt="logo">

    </a>
    Ohayou
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../ohayou/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Ohayou
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    vLLM
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            vLLM
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../vllm/open_ai_vllm_example_a_v_t/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Single Request
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../vllm/bash_vllm_serve/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Bash online serve
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../vllm/benchmarks/performance_eval/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Benchmarks
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    LLM
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            LLM
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../llm/speculative_decoding/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Speculative Decoding
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    VLM
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            VLM
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../vlm/qwen3_vl_4B_object_detection/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Qwen3VL
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../md_format_helpers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    MD format helpers
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../docker/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Docker
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../linux/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Linux
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../moe/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Mixture of Experts
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../slurm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Slurm
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_11" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../../japanese-phrases/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Japanese Phrases
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_11" id="__nav_11_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_11">
            <span class="md-nav__icon md-icon"></span>
            Japanese Phrases
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_11_2" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../../japanese-phrases/daily-life/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Daily Life
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_11_2" id="__nav_11_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_11_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_11_2">
            <span class="md-nav__icon md-icon"></span>
            Daily Life
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../japanese-phrases/daily-life/shopping/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Shopping
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_11_3" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../../japanese-phrases/greetings/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Greetings
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_11_3" id="__nav_11_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_11_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_11_3">
            <span class="md-nav__icon md-icon"></span>
            Greetings
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../japanese-phrases/greetings/casual/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Casual
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../japanese-phrases/emotions/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Emotions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../japanese-phrases/anime-manga/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Anime/Manga
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../hackathon/index.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Hack
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#the-big-table-of-tasks" class="md-nav__link">
    <span class="md-ellipsis">
      The Big Table of Tasks
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#running-quick-tests" class="md-nav__link">
    <span class="md-ellipsis">
      Running quick tests
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#resuming-training" class="md-nav__link">
    <span class="md-ellipsis">
      Resuming training
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Resuming training">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#upload-the-trainedfine-tuned-model-to-the-hub" class="md-nav__link">
    <span class="md-ellipsis">
      Upload the trained/fine-tuned model to the Hub
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#distributed-training-and-mixed-precision" class="md-nav__link">
    <span class="md-ellipsis">
      Distributed training and mixed precision
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#running-on-tpus" class="md-nav__link">
    <span class="md-ellipsis">
      Running on TPUs
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#using-accelerate" class="md-nav__link">
    <span class="md-ellipsis">
      Using Accelerate
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#logging-experiment-tracking" class="md-nav__link">
    <span class="md-ellipsis">
      Logging &amp; Experiment tracking
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Logging &amp; Experiment tracking">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#weights-biases" class="md-nav__link">
    <span class="md-ellipsis">
      Weights &amp; Biases
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#comet" class="md-nav__link">
    <span class="md-ellipsis">
      Comet
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#neptune" class="md-nav__link">
    <span class="md-ellipsis">
      Neptune
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#clearml" class="md-nav__link">
    <span class="md-ellipsis">
      ClearML
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<!---
Copyright 2020 The HuggingFace Team. All rights reserved.
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->

<h1 id="examples">Examples</h1>
<p>This folder contains actively maintained examples of use of ðŸ¤— Transformers using the PyTorch backend, organized by ML task.</p>
<h2 id="the-big-table-of-tasks">The Big Table of Tasks</h2>
<p>Here is the list of all our examples:
- with information on whether they are <strong>built on top of <code>Trainer</code></strong> (if not, they still work, they might
  just lack some features),
- whether or not they have a version using the <a href="https://github.com/huggingface/accelerate">ðŸ¤— Accelerate</a> library.
- whether or not they leverage the <a href="https://github.com/huggingface/datasets">ðŸ¤— Datasets</a> library.
- links to <strong>Colab notebooks</strong> to walk through the scripts and run them easily,</p>
<!--
Coming soon!
- links to **Cloud deployments** to be able to deploy large-scale trainings in the Cloud with little to no setup.
-->

<table>
<thead>
<tr>
<th>Task</th>
<th>Example datasets</th>
<th style="text-align: center;">Trainer support</th>
<th style="text-align: center;">ðŸ¤— Accelerate</th>
<th style="text-align: center;">ðŸ¤— Datasets</th>
<th style="text-align: center;">Colab</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/huggingface/transformers/tree/main/examples/pytorch/language-modeling"><strong><code>language-modeling</code></strong></a></td>
<td><a href="https://huggingface.co/datasets/wikitext">WikiText-2</a></td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;"><a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></td>
</tr>
<tr>
<td><a href="https://github.com/huggingface/transformers/tree/main/examples/pytorch/multiple-choice"><strong><code>multiple-choice</code></strong></a></td>
<td><a href="https://huggingface.co/datasets/swag">SWAG</a></td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;"><a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/multiple_choice.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></td>
</tr>
<tr>
<td><a href="https://github.com/huggingface/transformers/tree/main/examples/pytorch/question-answering"><strong><code>question-answering</code></strong></a></td>
<td><a href="https://huggingface.co/datasets/squad">SQuAD</a></td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;"><a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/question_answering.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></td>
</tr>
<tr>
<td><a href="https://github.com/huggingface/transformers/tree/main/examples/pytorch/summarization"><strong><code>summarization</code></strong></a></td>
<td><a href="https://huggingface.co/datasets/xsum">XSum</a></td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;"><a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/summarization.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></td>
</tr>
<tr>
<td><a href="https://github.com/huggingface/transformers/tree/main/examples/pytorch/text-classification"><strong><code>text-classification</code></strong></a></td>
<td><a href="https://huggingface.co/datasets/glue">GLUE</a></td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;"><a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/text_classification.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></td>
</tr>
<tr>
<td><a href="https://github.com/huggingface/transformers/tree/main/examples/pytorch/text-generation"><strong><code>text-generation</code></strong></a></td>
<td>-</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;"><a href="https://colab.research.google.com/github/huggingface/blog/blob/main/notebooks/02_how_to_generate.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></td>
</tr>
<tr>
<td><a href="https://github.com/huggingface/transformers/tree/main/examples/pytorch/token-classification"><strong><code>token-classification</code></strong></a></td>
<td><a href="https://huggingface.co/datasets/conll2003">CoNLL NER</a></td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;"><a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/token_classification.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></td>
</tr>
<tr>
<td><a href="https://github.com/huggingface/transformers/tree/main/examples/pytorch/translation"><strong><code>translation</code></strong></a></td>
<td><a href="https://huggingface.co/datasets/wmt17">WMT</a></td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;"><a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/translation.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></td>
</tr>
<tr>
<td><a href="https://github.com/huggingface/transformers/tree/main/examples/pytorch/speech-recognition"><strong><code>speech-recognition</code></strong></a></td>
<td><a href="https://huggingface.co/datasets/timit_asr">TIMIT</a></td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;"><a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/speech_recognition.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></td>
</tr>
<tr>
<td><a href="https://github.com/huggingface/transformers/tree/main/examples/pytorch/speech-recognition"><strong><code>multi-lingual speech-recognition</code></strong></a></td>
<td><a href="https://huggingface.co/datasets/common_voice">Common Voice</a></td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;"><a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/multi_lingual_speech_recognition.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></td>
</tr>
<tr>
<td><a href="https://github.com/huggingface/transformers/tree/main/examples/pytorch/audio-classification"><strong><code>audio-classification</code></strong></a></td>
<td><a href="https://huggingface.co/datasets/superb">SUPERB KS</a></td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;"><a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/audio_classification.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></td>
</tr>
<tr>
<td><a href="https://github.com/huggingface/transformers/tree/main/examples/pytorch/image-pretraining"><strong><code>image-pretraining</code></strong></a></td>
<td><a href="https://huggingface.co/datasets/imagenet-1k">ImageNet-1k</a></td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;">/</td>
</tr>
<tr>
<td><a href="https://github.com/huggingface/transformers/tree/main/examples/pytorch/image-classification"><strong><code>image-classification</code></strong></a></td>
<td><a href="https://huggingface.co/datasets/cifar10">CIFAR-10</a></td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;"><a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></td>
</tr>
<tr>
<td><a href="https://github.com/huggingface/transformers/tree/main/examples/pytorch/semantic-segmentation"><strong><code>semantic-segmentation</code></strong></a></td>
<td><a href="https://huggingface.co/datasets/scene_parse_150">SCENE_PARSE_150</a></td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;"><a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/semantic_segmentation.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></td>
</tr>
<tr>
<td><a href="https://github.com/huggingface/transformers/tree/main/examples/pytorch/object-detection"><strong><code>object-detection</code></strong></a></td>
<td><a href="https://huggingface.co/datasets/cppe-5">CPPE-5</a></td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;"><a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/pytorch/object_detection.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></td>
</tr>
<tr>
<td><a href="https://github.com/huggingface/transformers/tree/main/examples/pytorch/instance-segmentation"><strong><code>instance-segmentation</code></strong></a></td>
<td><a href="https://huggingface.co/datasets/qubvel-hf/ade20k-mini">ADE20K sample</a></td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<h2 id="running-quick-tests">Running quick tests</h2>
<p>Most examples are equipped with a mechanism to truncate the number of dataset samples to the desired length. This is useful for debugging purposes, for example to quickly check that all stages of the programs can complete, before running the same setup on the full dataset which may take hours to complete.</p>
<p>For example here is how to truncate all three splits to just 50 samples each:
<div class="language-bash highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>examples/pytorch/token-classification/run_ner.py<span class="w"> </span><span class="se">\</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>--max_train_samples<span class="w"> </span><span class="m">50</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>--max_eval_samples<span class="w"> </span><span class="m">50</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>--max_predict_samples<span class="w"> </span><span class="m">50</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="o">[</span>...<span class="o">]</span>
</span></code></pre></div></p>
<p>Most example scripts should have the first two command line arguments and some have the third one. You can quickly check if a given example supports any of these by passing a <code>-h</code> option, e.g.:
<div class="language-bash highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a>token-classification/run_ner.py<span class="w"> </span>-h
</span></code></pre></div></p>
<h2 id="resuming-training">Resuming training</h2>
<p>You can resume training from a previous checkpoint like this:</p>
<ol>
<li>Pass <code>--resume_from_checkpoint path_to_a_specific_checkpoint</code> to resume training from that checkpoint folder.</li>
</ol>
<p>Should you want to turn an example into a notebook where you'd no longer have access to the command
line, ðŸ¤— Trainer supports resuming from a checkpoint via <code>trainer.train(resume_from_checkpoint)</code>.</p>
<ol>
<li>If <code>resume_from_checkpoint</code> is <code>True</code> it will look for the last checkpoint in the value of <code>output_dir</code> passed via <code>TrainingArguments</code>.</li>
<li>If <code>resume_from_checkpoint</code> is a path to a specific checkpoint it will use that saved checkpoint folder to resume the training from.</li>
</ol>
<h3 id="upload-the-trainedfine-tuned-model-to-the-hub">Upload the trained/fine-tuned model to the Hub</h3>
<p>All the example scripts support automatic upload of your final model to the <a href="https://huggingface.co/models">Model Hub</a> by adding a <code>--push_to_hub</code> argument. It will then create a repository with your username slash the name of the folder you are using as <code>output_dir</code>. For instance, <code>"sgugger/test-mrpc"</code> if your username is <code>sgugger</code> and you are working in the folder <code>~/tmp/test-mrpc</code>.</p>
<p>To specify a given repository name, use the <code>--hub_model_id</code> argument. You will need to specify the whole repository name (including your username), for instance <code>--hub_model_id sgugger/finetuned-bert-mrpc</code>. To upload to an organization you are a member of, just use the name of that organization instead of your username: <code>--hub_model_id huggingface/finetuned-bert-mrpc</code>.</p>
<p>A few notes on this integration:</p>
<ul>
<li>you will need to be logged in to the Hugging Face website locally for it to work, the easiest way to achieve this is to run <code>hf auth login</code> and then type your username and password when prompted. You can also pass along your authentication token with the <code>--hub_token</code> argument.</li>
<li>the <code>output_dir</code> you pick will either need to be a new folder or a local clone of the distant repository you are using.</li>
</ul>
<h2 id="distributed-training-and-mixed-precision">Distributed training and mixed precision</h2>
<p>All the PyTorch scripts mentioned above work out of the box with distributed training and mixed precision, thanks to
the <a href="https://huggingface.co/transformers/main_classes/trainer.html">Trainer API</a>. To launch one of them on <em>n</em> GPUs,
use the following command:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a>torchrun<span class="w"> </span><span class="se">\</span>
</span><span id="__span-2-2"><a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a><span class="w">    </span>--nproc_per_node<span class="w"> </span>number_of_gpu_you_have<span class="w"> </span>path_to_script.py<span class="w"> </span><span class="se">\</span>
</span><span id="__span-2-3"><a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a><span class="w">    </span>--all_arguments_of_the_script
</span></code></pre></div>
<p>As an example, here is how you would fine-tune the BERT large model (with whole word masking) on the text
classification MNLI task using the <code>run_glue</code> script, with 8 GPUs:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a>torchrun<span class="w"> </span><span class="se">\</span>
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a><span class="w">    </span>--nproc_per_node<span class="w"> </span><span class="m">8</span><span class="w"> </span>text-classification/run_glue.py<span class="w"> </span><span class="se">\</span>
</span><span id="__span-3-3"><a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a><span class="w">    </span>--model_name_or_path<span class="w"> </span>google-bert/bert-large-uncased-whole-word-masking<span class="w"> </span><span class="se">\</span>
</span><span id="__span-3-4"><a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a><span class="w">    </span>--task_name<span class="w"> </span>mnli<span class="w"> </span><span class="se">\</span>
</span><span id="__span-3-5"><a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a><span class="w">    </span>--do_train<span class="w"> </span><span class="se">\</span>
</span><span id="__span-3-6"><a id="__codelineno-3-6" name="__codelineno-3-6" href="#__codelineno-3-6"></a><span class="w">    </span>--do_eval<span class="w"> </span><span class="se">\</span>
</span><span id="__span-3-7"><a id="__codelineno-3-7" name="__codelineno-3-7" href="#__codelineno-3-7"></a><span class="w">    </span>--max_seq_length<span class="w"> </span><span class="m">128</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-3-8"><a id="__codelineno-3-8" name="__codelineno-3-8" href="#__codelineno-3-8"></a><span class="w">    </span>--per_device_train_batch_size<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-3-9"><a id="__codelineno-3-9" name="__codelineno-3-9" href="#__codelineno-3-9"></a><span class="w">    </span>--learning_rate<span class="w"> </span>2e-5<span class="w"> </span><span class="se">\</span>
</span><span id="__span-3-10"><a id="__codelineno-3-10" name="__codelineno-3-10" href="#__codelineno-3-10"></a><span class="w">    </span>--num_train_epochs<span class="w"> </span><span class="m">3</span>.0<span class="w"> </span><span class="se">\</span>
</span><span id="__span-3-11"><a id="__codelineno-3-11" name="__codelineno-3-11" href="#__codelineno-3-11"></a><span class="w">    </span>--output_dir<span class="w"> </span>/tmp/mnli_output/
</span></code></pre></div>
<p>If you have a GPU with mixed precision capabilities (architecture Pascal or more recent), you can use mixed precision
training with PyTorch 1.6.0 or latest. Just add the flag <code>--fp16</code> to your command launching one of the scripts mentioned above!</p>
<p>Using mixed precision training usually results in 2x-speedup for training with the same final results (as shown in
<a href="https://github.com/huggingface/transformers/tree/main/examples/text-classification#mixed-precision-training">this table</a>
for text classification).</p>
<h2 id="running-on-tpus">Running on TPUs</h2>
<p>When using Tensorflow, TPUs are supported out of the box as a <code>tf.distribute.Strategy</code>.</p>
<p>When using PyTorch, we support TPUs thanks to <code>pytorch/xla</code>. For more context and information on how to setup your TPU environment refer to Google's documentation and to the
very detailed <a href="https://github.com/pytorch/xla/blob/master/README.md">pytorch/xla README</a>.</p>
<p>In this repo, we provide a very simple launcher script named
<a href="https://github.com/huggingface/transformers/tree/main/examples/pytorch/xla_spawn.py">xla_spawn.py</a> that lets you run our
example scripts on multiple TPU cores without any boilerplate. Just pass a <code>--num_cores</code> flag to this script, then your
regular training script with its arguments (this is similar to the <code>torch.distributed.launch</code> helper for
<code>torch.distributed</code>):</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a>python<span class="w"> </span>xla_spawn.py<span class="w"> </span>--num_cores<span class="w"> </span>num_tpu_you_have<span class="w"> </span><span class="se">\</span>
</span><span id="__span-4-2"><a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a><span class="w">    </span>path_to_script.py<span class="w"> </span><span class="se">\</span>
</span><span id="__span-4-3"><a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a><span class="w">    </span>--all_arguments_of_the_script
</span></code></pre></div>
<p>As an example, here is how you would fine-tune the BERT large model (with whole word masking) on the text
classification MNLI task using the <code>run_glue</code> script, with 8 TPUs (from this folder):</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a>python<span class="w"> </span>xla_spawn.py<span class="w"> </span>--num_cores<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-5-2"><a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a><span class="w">    </span>text-classification/run_glue.py<span class="w"> </span><span class="se">\</span>
</span><span id="__span-5-3"><a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a><span class="w">    </span>--model_name_or_path<span class="w"> </span>google-bert/bert-large-uncased-whole-word-masking<span class="w"> </span><span class="se">\</span>
</span><span id="__span-5-4"><a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a><span class="w">    </span>--task_name<span class="w"> </span>mnli<span class="w"> </span><span class="se">\</span>
</span><span id="__span-5-5"><a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a><span class="w">    </span>--do_train<span class="w"> </span><span class="se">\</span>
</span><span id="__span-5-6"><a id="__codelineno-5-6" name="__codelineno-5-6" href="#__codelineno-5-6"></a><span class="w">    </span>--do_eval<span class="w"> </span><span class="se">\</span>
</span><span id="__span-5-7"><a id="__codelineno-5-7" name="__codelineno-5-7" href="#__codelineno-5-7"></a><span class="w">    </span>--max_seq_length<span class="w"> </span><span class="m">128</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-5-8"><a id="__codelineno-5-8" name="__codelineno-5-8" href="#__codelineno-5-8"></a><span class="w">    </span>--per_device_train_batch_size<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-5-9"><a id="__codelineno-5-9" name="__codelineno-5-9" href="#__codelineno-5-9"></a><span class="w">    </span>--learning_rate<span class="w"> </span>2e-5<span class="w"> </span><span class="se">\</span>
</span><span id="__span-5-10"><a id="__codelineno-5-10" name="__codelineno-5-10" href="#__codelineno-5-10"></a><span class="w">    </span>--num_train_epochs<span class="w"> </span><span class="m">3</span>.0<span class="w"> </span><span class="se">\</span>
</span><span id="__span-5-11"><a id="__codelineno-5-11" name="__codelineno-5-11" href="#__codelineno-5-11"></a><span class="w">    </span>--output_dir<span class="w"> </span>/tmp/mnli_output/
</span></code></pre></div>
<h2 id="using-accelerate">Using Accelerate</h2>
<p>Most PyTorch example scripts have a version using the <a href="https://github.com/huggingface/accelerate">ðŸ¤— Accelerate</a> library
that exposes the training loop so it's easy for you to customize or tweak them to your needs. They all require you to
install <code>accelerate</code> with the latest development version</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a>pip<span class="w"> </span>install<span class="w"> </span>git+https://github.com/huggingface/accelerate
</span></code></pre></div>
<p>Then you can easily launch any of the scripts by running</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-7-1"><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a>accelerate<span class="w"> </span>config
</span></code></pre></div>
<p>and reply to the questions asked. Then</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-8-1"><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a>accelerate<span class="w"> </span><span class="nb">test</span>
</span></code></pre></div>
<p>that will check everything is ready for training. Finally, you can launch training with</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-9-1"><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a>accelerate<span class="w"> </span>launch<span class="w"> </span>path_to_script.py<span class="w"> </span>--args_to_script
</span></code></pre></div>
<h2 id="logging-experiment-tracking">Logging &amp; Experiment tracking</h2>
<p>You can easily log and monitor your runs code. The following are currently supported:</p>
<ul>
<li><a href="https://www.tensorflow.org/tensorboard">TensorBoard</a></li>
<li><a href="https://docs.wandb.ai/integrations/huggingface">Weights &amp; Biases</a></li>
<li><a href="https://www.comet.com/docs/v2/integrations/ml-frameworks/transformers/">Comet ML</a></li>
<li><a href="https://docs.neptune.ai/integrations-and-supported-tools/model-training/hugging-face">Neptune</a></li>
<li><a href="https://clear.ml/docs/latest/docs/getting_started/ds/ds_first_steps">ClearML</a></li>
<li><a href="https://dvc.org/doc/dvclive/ml-frameworks/huggingface">DVCLive</a></li>
</ul>
<h3 id="weights-biases">Weights &amp; Biases</h3>
<p>To use Weights &amp; Biases, install the wandb package with:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-10-1"><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a>pip<span class="w"> </span>install<span class="w"> </span>wandb
</span></code></pre></div>
<p>Then log in the command line:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-11-1"><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a>wandb<span class="w"> </span>login
</span></code></pre></div>
<p>If you are in Jupyter or Colab, you should login with:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-12-1"><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">wandb</span>
</span><span id="__span-12-2"><a id="__codelineno-12-2" name="__codelineno-12-2" href="#__codelineno-12-2"></a><span class="n">wandb</span><span class="o">.</span><span class="n">login</span><span class="p">()</span>
</span></code></pre></div>
<p>To enable logging to W&amp;B, include <code>"wandb"</code> in the <code>report_to</code> of your <code>TrainingArguments</code> or script. Or just pass along <code>--report_to_all</code> if you have <code>wandb</code> installed.</p>
<p>Whenever you use the <code>Trainer</code> class, your losses, evaluation metrics, model topology and gradients will automatically be logged.</p>
<p>Advanced configuration is possible by setting environment variables:</p>
<table>
<thead>
<tr>
<th>Environment Variable</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>WANDB_LOG_MODEL</td>
<td>Log the model as artifact (log the model as artifact at the end of training) (<code>false</code> by default)</td>
</tr>
<tr>
<td>WANDB_WATCH</td>
<td>one of <code>gradients</code> (default) to log histograms of gradients, <code>all</code> to log histograms of both gradients and parameters, or <code>false</code> for no histogram logging</td>
</tr>
<tr>
<td>WANDB_PROJECT</td>
<td>Organize runs by project</td>
</tr>
</tbody>
</table>
<p>Set run names with <code>run_name</code> argument present in scripts or as part of <code>TrainingArguments</code>.</p>
<p>Additional configuration options are available through generic <a href="https://docs.wandb.com/library/environment-variables">wandb environment variables</a>.</p>
<p>Refer to related <a href="https://docs.wandb.ai/integrations/huggingface">documentation &amp; examples</a>.</p>
<h3 id="comet">Comet</h3>
<p>To use <code>comet_ml</code>, install the Python package with:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-13-1"><a id="__codelineno-13-1" name="__codelineno-13-1" href="#__codelineno-13-1"></a>pip<span class="w"> </span>install<span class="w"> </span>comet_ml
</span></code></pre></div>
<p>or if in a Conda environment:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-14-1"><a id="__codelineno-14-1" name="__codelineno-14-1" href="#__codelineno-14-1"></a>conda<span class="w"> </span>install<span class="w"> </span>-c<span class="w"> </span>comet_ml<span class="w"> </span>-c<span class="w"> </span>anaconda<span class="w"> </span>-c<span class="w"> </span>conda-forge<span class="w"> </span>comet_ml
</span></code></pre></div>
<h3 id="neptune">Neptune</h3>
<p>First, install the Neptune client library. You can do it with either <code>pip</code> or <code>conda</code>:</p>
<p><code>pip</code>:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-15-1"><a id="__codelineno-15-1" name="__codelineno-15-1" href="#__codelineno-15-1"></a>pip<span class="w"> </span>install<span class="w"> </span>neptune
</span></code></pre></div>
<p><code>conda</code>:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-16-1"><a id="__codelineno-16-1" name="__codelineno-16-1" href="#__codelineno-16-1"></a>conda<span class="w"> </span>install<span class="w"> </span>-c<span class="w"> </span>conda-forge<span class="w"> </span>neptune
</span></code></pre></div>
<p>Next, in your model training script, import <code>NeptuneCallback</code>:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-17-1"><a id="__codelineno-17-1" name="__codelineno-17-1" href="#__codelineno-17-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">transformers.integrations</span><span class="w"> </span><span class="kn">import</span> <span class="n">NeptuneCallback</span>
</span></code></pre></div>
<p>To enable Neptune logging, in your <code>TrainingArguments</code>, set the <code>report_to</code> argument to <code>"neptune"</code>:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-18-1"><a id="__codelineno-18-1" name="__codelineno-18-1" href="#__codelineno-18-1"></a><span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
</span><span id="__span-18-2"><a id="__codelineno-18-2" name="__codelineno-18-2" href="#__codelineno-18-2"></a>    <span class="s2">&quot;quick-training-distilbert-mrpc&quot;</span><span class="p">,</span>
</span><span id="__span-18-3"><a id="__codelineno-18-3" name="__codelineno-18-3" href="#__codelineno-18-3"></a>    <span class="n">eval_strategy</span><span class="o">=</span><span class="s2">&quot;steps&quot;</span><span class="p">,</span>
</span><span id="__span-18-4"><a id="__codelineno-18-4" name="__codelineno-18-4" href="#__codelineno-18-4"></a>    <span class="n">eval_steps</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
</span><span id="__span-18-5"><a id="__codelineno-18-5" name="__codelineno-18-5" href="#__codelineno-18-5"></a>    <span class="n">report_to</span><span class="o">=</span><span class="s2">&quot;neptune&quot;</span><span class="p">,</span>
</span><span id="__span-18-6"><a id="__codelineno-18-6" name="__codelineno-18-6" href="#__codelineno-18-6"></a><span class="p">)</span>
</span><span id="__span-18-7"><a id="__codelineno-18-7" name="__codelineno-18-7" href="#__codelineno-18-7"></a>
</span><span id="__span-18-8"><a id="__codelineno-18-8" name="__codelineno-18-8" href="#__codelineno-18-8"></a><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
</span><span id="__span-18-9"><a id="__codelineno-18-9" name="__codelineno-18-9" href="#__codelineno-18-9"></a>    <span class="n">model</span><span class="p">,</span>
</span><span id="__span-18-10"><a id="__codelineno-18-10" name="__codelineno-18-10" href="#__codelineno-18-10"></a>    <span class="n">training_args</span><span class="p">,</span>
</span><span id="__span-18-11"><a id="__codelineno-18-11" name="__codelineno-18-11" href="#__codelineno-18-11"></a>    <span class="o">...</span>
</span><span id="__span-18-12"><a id="__codelineno-18-12" name="__codelineno-18-12" href="#__codelineno-18-12"></a><span class="p">)</span>
</span></code></pre></div>
<p><strong>Note:</strong> This method requires saving your Neptune credentials as environment variables (see the bottom of the section).</p>
<p>Alternatively, for more logging options, create a Neptune callback:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-19-1"><a id="__codelineno-19-1" name="__codelineno-19-1" href="#__codelineno-19-1"></a><span class="n">neptune_callback</span> <span class="o">=</span> <span class="n">NeptuneCallback</span><span class="p">()</span>
</span></code></pre></div>
<p>To add more detail to the tracked run, you can supply optional arguments to <code>NeptuneCallback</code>.</p>
<p>Some examples:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-20-1"><a id="__codelineno-20-1" name="__codelineno-20-1" href="#__codelineno-20-1"></a><span class="n">neptune_callback</span> <span class="o">=</span> <span class="n">NeptuneCallback</span><span class="p">(</span>
</span><span id="__span-20-2"><a id="__codelineno-20-2" name="__codelineno-20-2" href="#__codelineno-20-2"></a>    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;DistilBERT&quot;</span><span class="p">,</span>
</span><span id="__span-20-3"><a id="__codelineno-20-3" name="__codelineno-20-3" href="#__codelineno-20-3"></a>    <span class="n">description</span> <span class="o">=</span> <span class="s2">&quot;DistilBERT fine-tuned on GLUE/MRPC&quot;</span><span class="p">,</span>
</span><span id="__span-20-4"><a id="__codelineno-20-4" name="__codelineno-20-4" href="#__codelineno-20-4"></a>    <span class="n">tags</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;args-callback&quot;</span><span class="p">,</span> <span class="s2">&quot;fine-tune&quot;</span><span class="p">,</span> <span class="s2">&quot;MRPC&quot;</span><span class="p">],</span>  <span class="c1"># tags help you manage runs in Neptune</span>
</span><span id="__span-20-5"><a id="__codelineno-20-5" name="__codelineno-20-5" href="#__codelineno-20-5"></a>    <span class="n">base_namespace</span><span class="o">=</span><span class="s2">&quot;callback&quot;</span><span class="p">,</span>  <span class="c1"># the default is &quot;finetuning&quot;</span>
</span><span id="__span-20-6"><a id="__codelineno-20-6" name="__codelineno-20-6" href="#__codelineno-20-6"></a>    <span class="n">log_checkpoints</span> <span class="o">=</span> <span class="s2">&quot;best&quot;</span><span class="p">,</span>  <span class="c1"># other options are &quot;last&quot;, &quot;same&quot;, and None</span>
</span><span id="__span-20-7"><a id="__codelineno-20-7" name="__codelineno-20-7" href="#__codelineno-20-7"></a>    <span class="n">capture_hardware_metrics</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>  <span class="c1"># additional keyword arguments for a Neptune run</span>
</span><span id="__span-20-8"><a id="__codelineno-20-8" name="__codelineno-20-8" href="#__codelineno-20-8"></a><span class="p">)</span>
</span></code></pre></div>
<p>Pass the callback to the Trainer:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-21-1"><a id="__codelineno-21-1" name="__codelineno-21-1" href="#__codelineno-21-1"></a><span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">report_to</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</span><span id="__span-21-2"><a id="__codelineno-21-2" name="__codelineno-21-2" href="#__codelineno-21-2"></a><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
</span><span id="__span-21-3"><a id="__codelineno-21-3" name="__codelineno-21-3" href="#__codelineno-21-3"></a>    <span class="n">model</span><span class="p">,</span>
</span><span id="__span-21-4"><a id="__codelineno-21-4" name="__codelineno-21-4" href="#__codelineno-21-4"></a>    <span class="n">training_args</span><span class="p">,</span>
</span><span id="__span-21-5"><a id="__codelineno-21-5" name="__codelineno-21-5" href="#__codelineno-21-5"></a>    <span class="o">...</span>
</span><span id="__span-21-6"><a id="__codelineno-21-6" name="__codelineno-21-6" href="#__codelineno-21-6"></a>    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">neptune_callback</span><span class="p">],</span>
</span><span id="__span-21-7"><a id="__codelineno-21-7" name="__codelineno-21-7" href="#__codelineno-21-7"></a><span class="p">)</span>
</span></code></pre></div>
<p>Now, when you start the training with <code>trainer.train()</code>, your metadata will be logged in Neptune.</p>
<p><strong>Note:</strong> Although you can pass your <strong>Neptune API token</strong> and <strong>project name</strong> as arguments when creating the callback, the recommended way is to save them as environment variables:</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Environment variable</th>
<th style="text-align: left;">Value</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><code>NEPTUNE_API_TOKEN</code></td>
<td style="text-align: left;">Your Neptune API token. To find and copy it, click your Neptune avatar and select <strong>Get your API token</strong>.</td>
</tr>
<tr>
<td style="text-align: left;"><code>NEPTUNE_PROJECT</code></td>
<td style="text-align: left;">The full name of your Neptune project (<code>workspace-name/project-name</code>). To find and copy it, head to <strong>project settings</strong> &rarr; <strong>Properties</strong>.</td>
</tr>
</tbody>
</table>
<p>For detailed instructions and examples, see the <a href="https://docs.neptune.ai/integrations/transformers/">Neptune docs</a>.</p>
<h3 id="clearml">ClearML</h3>
<p>To use ClearML, install the clearml package with:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-22-1"><a id="__codelineno-22-1" name="__codelineno-22-1" href="#__codelineno-22-1"></a>pip<span class="w"> </span>install<span class="w"> </span>clearml
</span></code></pre></div>
<p>Then <a href="">create new credentials</a> from the ClearML Server. You can get a free hosted server <a href="">here</a> or <a href="">self-host your own</a>!
After creating your new credentials, you can either copy the local snippet which you can paste after running:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-23-1"><a id="__codelineno-23-1" name="__codelineno-23-1" href="#__codelineno-23-1"></a>clearml-init
</span></code></pre></div>
<p>Or you can copy the jupyter snippet if you are in Jupyter or Colab:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-24-1"><a id="__codelineno-24-1" name="__codelineno-24-1" href="#__codelineno-24-1"></a><span class="o">%</span><span class="n">env</span> <span class="n">CLEARML_WEB_HOST</span><span class="o">=</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">app</span><span class="o">.</span><span class="n">clear</span><span class="o">.</span><span class="n">ml</span>
</span><span id="__span-24-2"><a id="__codelineno-24-2" name="__codelineno-24-2" href="#__codelineno-24-2"></a><span class="o">%</span><span class="n">env</span> <span class="n">CLEARML_API_HOST</span><span class="o">=</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">api</span><span class="o">.</span><span class="n">clear</span><span class="o">.</span><span class="n">ml</span>
</span><span id="__span-24-3"><a id="__codelineno-24-3" name="__codelineno-24-3" href="#__codelineno-24-3"></a><span class="o">%</span><span class="n">env</span> <span class="n">CLEARML_FILES_HOST</span><span class="o">=</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">files</span><span class="o">.</span><span class="n">clear</span><span class="o">.</span><span class="n">ml</span>
</span><span id="__span-24-4"><a id="__codelineno-24-4" name="__codelineno-24-4" href="#__codelineno-24-4"></a><span class="o">%</span><span class="n">env</span> <span class="n">CLEARML_API_ACCESS_KEY</span><span class="o">=***</span>
</span><span id="__span-24-5"><a id="__codelineno-24-5" name="__codelineno-24-5" href="#__codelineno-24-5"></a><span class="o">%</span><span class="n">env</span> <span class="n">CLEARML_API_SECRET_KEY</span><span class="o">=***</span>
</span></code></pre></div>
<p>To enable logging to ClearML, include <code>"clearml"</code> in the <code>report_to</code> of your <code>TrainingArguments</code> or script. Or just pass along <code>--report_to all</code> if you have <code>clearml</code> already installed.</p>
<p>Advanced configuration is possible by setting environment variables:</p>
<table>
<thead>
<tr>
<th>Environment Variable</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>CLEARML_PROJECT</td>
<td>Name of the project in ClearML. (default: <code>"HuggingFace Transformers"</code>)</td>
</tr>
<tr>
<td>CLEARML_TASK</td>
<td>Name of the task in ClearML. (default: <code>"Trainer"</code>)</td>
</tr>
</tbody>
</table>
<p>Additional configuration options are available through generic <a href="https://clear.ml/docs/latest/docs/configs/env_vars">clearml environment variables</a>.</p>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../../../..", "features": ["navigation.tabs", "navigation.indexes", "navigation.instant", "navigation.sections", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow", "content.tabs.link", "content.code.copy"], "search": "../../../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
    
  </body>
</html>