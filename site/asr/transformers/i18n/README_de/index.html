
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../../../../assets/favicon.ico">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.22">
    
    
      
        <title>README de - Ohayou</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.84d31ad4.min.css">
      
        
        <link rel="stylesheet" href="../../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../../assets/extra.css">
    
    <script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#online-demos" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../.." title="Ohayou" class="md-header__button md-logo" aria-label="Ohayou" data-md-component="logo">
      
  <img src="../../../../assets/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Ohayou
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              README de
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../ohayou/" class="md-tabs__link">
        
  
  
    
  
  Ohayou

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../vllm/open_ai_vllm_example_a_v_t/" class="md-tabs__link">
          
  
  
    
  
  vLLM

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../llm/speculative_decoding/" class="md-tabs__link">
          
  
  
    
  
  LLM

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../vlm/qwen3_vl_4B_object_detection/" class="md-tabs__link">
          
  
  
    
  
  VLM

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../md_format_helpers/" class="md-tabs__link">
        
  
  
    
  
  MD format helpers

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../docker/" class="md-tabs__link">
        
  
  
    
  
  Docker

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../linux/" class="md-tabs__link">
        
  
  
    
  
  Linux

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../moe/" class="md-tabs__link">
        
  
  
    
  
  Mixture of Experts

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../slurm/" class="md-tabs__link">
        
  
  
    
  
  Slurm

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../japanese-phrases/" class="md-tabs__link">
          
  
  
    
  
  Japanese Phrases

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../hackathon/index.md" class="md-tabs__link">
        
  
  
    
  
  Hack

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="Ohayou" class="md-nav__button md-logo" aria-label="Ohayou" data-md-component="logo">
      
  <img src="../../../../assets/logo.png" alt="logo">

    </a>
    Ohayou
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../ohayou/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Ohayou
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    vLLM
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            vLLM
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../vllm/open_ai_vllm_example_a_v_t/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Single Request
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../vllm/bash_vllm_serve/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Bash online serve
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../vllm/benchmarks/performance_eval/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Benchmarks
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    LLM
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            LLM
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../llm/speculative_decoding/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Speculative Decoding
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    VLM
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            VLM
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../vlm/qwen3_vl_4B_object_detection/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Qwen3VL
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../md_format_helpers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    MD format helpers
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../docker/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Docker
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../linux/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Linux
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../moe/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Mixture of Experts
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../slurm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Slurm
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_11" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../../japanese-phrases/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Japanese Phrases
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_11" id="__nav_11_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_11">
            <span class="md-nav__icon md-icon"></span>
            Japanese Phrases
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_11_2" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../../japanese-phrases/daily-life/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Daily Life
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_11_2" id="__nav_11_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_11_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_11_2">
            <span class="md-nav__icon md-icon"></span>
            Daily Life
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../japanese-phrases/daily-life/shopping/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Shopping
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_11_3" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../../japanese-phrases/greetings/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Greetings
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_11_3" id="__nav_11_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_11_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_11_3">
            <span class="md-nav__icon md-icon"></span>
            Greetings
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../japanese-phrases/greetings/casual/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Casual
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../japanese-phrases/emotions/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Emotions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../japanese-phrases/anime-manga/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Anime/Manga
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../hackathon/index.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Hack
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#online-demos" class="md-nav__link">
    <span class="md-ellipsis">
      Online-Demos
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#100-projekte-die-transformers-verwenden" class="md-nav__link">
    <span class="md-ellipsis">
      100 Projekte, die ü§ó Transformers verwenden
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#wenn-sie-individuelle-unterstutzung-vom-hugging-face-team-mochten" class="md-nav__link">
    <span class="md-ellipsis">
      Wenn Sie individuelle Unterst√ºtzung vom Hugging Face-Team m√∂chten
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#schnelleinstieg" class="md-nav__link">
    <span class="md-ellipsis">
      Schnelleinstieg
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#warum-sollten-sie-transformers-verwenden" class="md-nav__link">
    <span class="md-ellipsis">
      Warum sollten Sie ü§ó Transformers verwenden?
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#warum-sollten-sie-transformers-nicht-verwenden" class="md-nav__link">
    <span class="md-ellipsis">
      Warum sollten Sie ü§ó Transformers nicht verwenden?
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#installation" class="md-nav__link">
    <span class="md-ellipsis">
      Installation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Installation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mit-pip" class="md-nav__link">
    <span class="md-ellipsis">
      Mit pip
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mit-conda" class="md-nav__link">
    <span class="md-ellipsis">
      Mit conda
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



  <h1>README de</h1>

<!---
Copyright 2024 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->

<p align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-dark.svg">
    <source media="(prefers-color-scheme: light)" srcset="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-light.svg">
    <img alt="Hugging Face Transformers Library" src="https://huggingface.co/datasets/huggingface/documentation-images/raw/main/transformers-logo-light.svg" width="352" height="59" style="max-width: 100%;">
  </picture>
  <br/>
  <br/>
</p>

<p align="center">
    <a href="https://circleci.com/gh/huggingface/transformers"><img alt="Build" src="https://img.shields.io/circleci/build/github/huggingface/transformers/main"></a>
    <a href="https://github.com/huggingface/transformers/blob/main/LICENSE"><img alt="GitHub" src="https://img.shields.io/github/license/huggingface/transformers.svg?color=blue"></a>
    <a href="https://huggingface.co/docs/transformers/index"><img alt="Documentation" src="https://img.shields.io/website/http/huggingface.co/docs/transformers/index.svg?down_color=red&down_message=offline&up_message=online"></a>
    <a href="https://github.com/huggingface/transformers/releases"><img alt="GitHub release" src="https://img.shields.io/github/release/huggingface/transformers.svg"></a>
    <a href="https://github.com/huggingface/transformers/blob/main/CODE_OF_CONDUCT.md"><img alt="Contributor Covenant" src="https://img.shields.io/badge/Contributor%20Covenant-v2.0%20adopted-ff69b4.svg"></a>
    <a href="https://zenodo.org/badge/latestdoi/155220641"><img src="https://zenodo.org/badge/155220641.svg" alt="DOI"></a>
</p>

<h4 align="center">
    <p>
        <a href="https://github.com/huggingface/transformers/">English</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_zh-hans.md">ÁÆÄ‰Ωì‰∏≠Êñá</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_zh-hant.md">ÁπÅÈ´î‰∏≠Êñá</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ko.md">ÌïúÍµ≠Ïñ¥</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_es.md">Espa√±ol</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ja.md">Êó•Êú¨Ë™û</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_hd.md">‡§π‡§ø‡§®‡•ç‡§¶‡•Ä</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ru.md">–†—É—Å—Å–∫–∏–π</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_pt-br.md">–†ortugu√™s</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_te.md">‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_fr.md">Fran√ßais</a> |
        <b>Deutsch</b> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_it.md">Italiano</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_vi.md">Ti·∫øng Vi·ªát</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ar.md">ÿßŸÑÿπÿ±ÿ®Ÿäÿ©</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_ur.md">ÿßÿ±ÿØŸà</a> |
        <a href="https://github.com/huggingface/transformers/blob/main/i18n/README_bn.md">‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ</a> |
    </p>
</h4>

<h3 align="center">
    <p>Maschinelles Lernen auf dem neuesten Stand der Technik f√ºr JAX, PyTorch und TensorFlow</p>
</h3>

<h3 align="center">
    <a href="https://hf.co/course"><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/course_banner.png"></a>
</h3>

<p>ü§ó Transformers bietet Tausende von vortrainierten Modellen, um Aufgaben in verschiedenen Modalit√§ten wie Text, Bild und Audio durchzuf√ºhren.</p>
<p>Diese Modelle k√∂nnen angewendet werden, auf:</p>
<ul>
<li>üìù Text - f√ºr Aufgaben wie Textklassifizierung, Informationsextraktion, Question Answering, automatische Textzusammenfassung, maschinelle √úbersetzung und Textgenerierung in √ºber 100 Sprachen.</li>
<li>üñºÔ∏è Bilder - f√ºr Aufgaben wie Bildklassifizierung, Objekterkennung und Segmentierung.</li>
<li>üó£Ô∏è Audio - f√ºr Aufgaben wie Spracherkennung und Audioklassifizierung.</li>
</ul>
<p>Transformer-Modelle k√∂nnen auch Aufgaben f√ºr <strong>mehrere Modalit√§ten in Kombination</strong> durchf√ºhren, z. B. tabellenbasiertes Question Answering, optische Zeichenerkennung, Informationsextraktion aus gescannten Dokumenten, Videoklassifizierung und visuelles Question Answering.</p>
<p>ü§ó Transformers bietet APIs, um diese vortrainierten Modelle schnell herunterzuladen und f√ºr einen gegebenen Text zu verwenden, sie auf Ihren eigenen Datens√§tzen zu feintunen und dann mit der Community in unserem <a href="https://huggingface.co/models">Model Hub</a> zu teilen. Gleichzeitig ist jedes Python-Modul, das eine Architektur definiert, komplett eigenst√§ndig und kann modifiziert werden, um schnelle Forschungsexperimente zu erm√∂glichen.</p>
<p>ü§ó Transformers unterst√ºtzt die nahtlose Integration von drei der beliebtesten Deep-Learning-Bibliotheken: <a href="https://jax.readthedocs.io/en/latest/">Jax</a>, <a href="https://pytorch.org/">PyTorch</a> und <a href="https://www.tensorflow.org/">TensorFlow</a>. Trainieren Sie Ihr Modell in einem Framework und laden Sie es zur Inferenz unkompliziert mit einem anderen.</p>
<h2 id="online-demos">Online-Demos</h2>
<p>Sie k√∂nnen die meisten unserer Modelle direkt auf ihren Seiten im <a href="https://huggingface.co/models">Model Hub</a> testen. Wir bieten auch <a href="https://huggingface.co/pricing">privates Modell-Hosting, Versionierung, &amp; eine Inferenz-API</a> f√ºr √∂ffentliche und private Modelle an.</p>
<p>Hier sind einige Beispiele:</p>
<p>In der Computerlinguistik:</p>
<ul>
<li><a href="https://huggingface.co/google-bert/bert-base-uncased?text=Paris+is+the+%5BMASK%5D+of+France">Maskierte Wortvervollst√§ndigung mit BERT</a></li>
<li><a href="https://huggingface.co/dbmdz/electra-large-discriminator-finetuned-conll03-english?text=My+name+is+Sarah+and+I+live+in+London+city">Eigennamenerkennung mit Electra</a></li>
<li><a href="https://huggingface.co/openai-community/gpt2?text=A+long+time+ago%2C+">Textgenerierung mit GPT-2</a></li>
<li><a href="https://huggingface.co/FacebookAI/roberta-large-mnli?text=The+dog+was+lost.+Nobody+lost+any+animal">Natural Language Inference mit RoBERTa</a></li>
<li><a href="https://huggingface.co/facebook/bart-large-cnn?text=The+tower+is+324+metres+%281%2C063+ft%29+tall%2C+about+the+same+height+as+an+81-storey+building%2C+and+the+tallest+structure+in+Paris.+Its+base+is+square%2C+measuring+125+metres+%28410+ft%29+on+each+side.+During+its+construction%2C+the+Eiffel+Tower+surpassed+the+Washington+Monument+to+become+the+tallest+man-made+structure+in+the+world%2C+a+title+it+held+for+41+years+until+the+Chrysler+Building+in+New+York+City+was+finished+in+1930.+It+was+the+first+structure+to+reach+a+height+of+300+metres.+Due+to+the+addition+of+a+broadcasting+aerial+at+the+top+of+the+tower+in+1957%2C+it+is+now+taller+than+the+Chrysler+Building+by+5.2+metres+%2817+ft%29.+Excluding+transmitters%2C+the+Eiffel+Tower+is+the+second+tallest+free-standing+structure+in+France+after+the+Millau+Viaduct">Automatische Textzusammenfassung mit BART</a></li>
<li><a href="https://huggingface.co/distilbert/distilbert-base-uncased-distilled-squad?text=Which+name+is+also+used+to+describe+the+Amazon+rainforest+in+English%3F&amp;context=The+Amazon+rainforest+%28Portuguese%3A+Floresta+Amaz%C3%B4nica+or+Amaz%C3%B4nia%3B+Spanish%3A+Selva+Amaz%C3%B3nica%2C+Amazon%C3%ADa+or+usually+Amazonia%3B+French%3A+For%C3%AAt+amazonienne%3B+Dutch%3A+Amazoneregenwoud%29%2C+also+known+in+English+as+Amazonia+or+the+Amazon+Jungle%2C+is+a+moist+broadleaf+forest+that+covers+most+of+the+Amazon+basin+of+South+America.+This+basin+encompasses+7%2C000%2C000+square+kilometres+%282%2C700%2C000+sq+mi%29%2C+of+which+5%2C500%2C000+square+kilometres+%282%2C100%2C000+sq+mi%29+are+covered+by+the+rainforest.+This+region+includes+territory+belonging+to+nine+nations.+The+majority+of+the+forest+is+contained+within+Brazil%2C+with+60%25+of+the+rainforest%2C+followed+by+Peru+with+13%25%2C+Colombia+with+10%25%2C+and+with+minor+amounts+in+Venezuela%2C+Ecuador%2C+Bolivia%2C+Guyana%2C+Suriname+and+French+Guiana.+States+or+departments+in+four+nations+contain+%22Amazonas%22+in+their+names.+The+Amazon+represents+over+half+of+the+planet%27s+remaining+rainforests%2C+and+comprises+the+largest+and+most+biodiverse+tract+of+tropical+rainforest+in+the+world%2C+with+an+estimated+390+billion+individual+trees+divided+into+16%2C000+species">Question Answering mit DistilBERT</a></li>
<li><a href="https://huggingface.co/google-t5/t5-base?text=My+name+is+Wolfgang+and+I+live+in+Berlin">Maschinelle √úbersetzung mit T5</a></li>
</ul>
<p>In der Computer Vision:</p>
<ul>
<li><a href="https://huggingface.co/google/vit-base-patch16-224">Bildklassifizierung mit ViT</a></li>
<li><a href="https://huggingface.co/facebook/detr-resnet-50">Objekterkennung mit DETR</a></li>
<li><a href="https://huggingface.co/nvidia/segformer-b0-finetuned-ade-512-512">Semantische Segmentierung mit SegFormer</a></li>
<li><a href="https://huggingface.co/facebook/maskformer-swin-small-coco">Panoptische Segmentierung mit MaskFormer</a></li>
<li><a href="https://huggingface.co/docs/transformers/model_doc/dpt">Depth Estimation mit DPT</a></li>
<li><a href="https://huggingface.co/docs/transformers/model_doc/videomae">Videoklassifizierung mit VideoMAE</a></li>
<li><a href="https://huggingface.co/shi-labs/oneformer_ade20k_dinat_large">Universelle Segmentierung mit OneFormer</a></li>
</ul>
<p>Im Audio-Bereich:</p>
<ul>
<li><a href="https://huggingface.co/facebook/wav2vec2-base-960h">Automatische Spracherkennung mit Wav2Vec2</a></li>
<li><a href="https://huggingface.co/superb/wav2vec2-base-superb-ks">Keyword Spotting mit Wav2Vec2</a></li>
<li><a href="https://huggingface.co/MIT/ast-finetuned-audioset-10-10-0.4593">Audioklassifizierung mit Audio Spectrogram Transformer</a></li>
</ul>
<p>In multimodalen Aufgaben:</p>
<ul>
<li><a href="https://huggingface.co/google/tapas-base-finetuned-wtq">Tabellenbasiertes Question Answering mit TAPAS</a></li>
<li><a href="https://huggingface.co/dandelin/vilt-b32-finetuned-vqa">Visuelles Question Answering mit ViLT</a></li>
<li><a href="https://huggingface.co/openai/clip-vit-large-patch14">Zero-Shot-Bildklassifizierung mit CLIP</a></li>
<li><a href="https://huggingface.co/impira/layoutlm-document-qa">Dokumentenbasiertes Question Answering mit LayoutLM</a></li>
<li><a href="https://huggingface.co/docs/transformers/model_doc/xclip">Zero-Shot-Videoklassifizierung mit X-CLIP</a></li>
</ul>
<h2 id="100-projekte-die-transformers-verwenden">100 Projekte, die ü§ó Transformers verwenden</h2>
<p>ü§ó Transformers ist mehr als nur ein Toolkit zur Verwendung von vortrainierten Modellen: Es ist eine Gemeinschaft von Projekten, die darum herum und um den Hugging Face Hub aufgebaut sind. Wir m√∂chten, dass ü§ó Transformers es Entwicklern, Forschern, Studenten, Professoren, Ingenieuren und jedem anderen erm√∂glicht, ihre Traumprojekte zu realisieren.</p>
<p>Um die 100.000 Sterne von ü§ó Transformers zu feiern, haben wir beschlossen, die Gemeinschaft in den Mittelpunkt zu stellen und die Seite <a href="./awesome-transformers.md">awesome-transformers</a> erstellt, die 100 unglaubliche Projekte auflistet, die zusammen mit ü§ó Transformers realisiert wurden.</p>
<p>Wenn Sie ein Projekt besitzen oder nutzen, von dem Sie glauben, dass es Teil der Liste sein sollte, √∂ffnen Sie bitte einen PR, um es hinzuzuf√ºgen!</p>
<h2 id="wenn-sie-individuelle-unterstutzung-vom-hugging-face-team-mochten">Wenn Sie individuelle Unterst√ºtzung vom Hugging Face-Team m√∂chten</h2>
<p><a target="_blank" href="https://huggingface.co/support">
    <img alt="HuggingFace Expert Acceleration Program" src="https://cdn-media.huggingface.co/marketing/transformers/new-support-improved.png" style="max-width: 600px; border: 1px solid #eee; border-radius: 4px; box-shadow: 0 1px 2px 0 rgba(0, 0, 0, 0.05);">
</a><br></p>
<h2 id="schnelleinstieg">Schnelleinstieg</h2>
<p>Um sofort ein Modell mit einer bestimmten Eingabe (Text, Bild, Audio ...) zu verwenden, bieten wir die <code>pipeline</code>-API an. Pipelines kombinieren ein vortrainiertes Modell mit der jeweiligen Vorverarbeitung, die w√§hrend dessen Trainings verwendet wurde. Hier sehen Sie, wie man schnell eine Pipeline verwenden kann, um positive und negative Texte zu klassifizieren:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">pipeline</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="c1"># Zuweisung einer Pipeline f√ºr die Sentiment-Analyse</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">classifier</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s1">&#39;sentiment-analysis&#39;</span><span class="p">)</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">classifier</span><span class="p">(</span><span class="s1">&#39;We are very happy to introduce pipeline to the transformers repository.&#39;</span><span class="p">)</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="p">[{</span><span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;POSITIVE&#39;</span><span class="p">,</span> <span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="mf">0.9996980428695679</span><span class="p">}]</span>
</span></code></pre></div>
<p>Die zweite Codezeile l√§dt und cacht das vortrainierte Modell, das von der Pipeline verwendet wird, w√§hrend die dritte es an dem gegebenen Text evaluiert. Hier ist die Antwort "positiv" mit einer Konfidenz von 99,97 %.</p>
<p>Viele Aufgaben, sowohl in der Computerlinguistik als auch in der Computer Vision und Sprachverarbeitung, haben eine vortrainierte <code>pipeline</code>, die sofort einsatzbereit ist. Z. B. k√∂nnen wir leicht erkannte Objekte in einem Bild extrahieren:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span><span class="w"> </span><span class="nn">requests</span>
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">PIL</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">pipeline</span>
</span><span id="__span-1-4"><a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a>
</span><span id="__span-1-5"><a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a><span class="c1"># Download eines Bildes mit s√º√üen Katzen</span>
</span><span id="__span-1-6"><a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/coco_sample.png&quot;</span>
</span><span id="__span-1-7"><a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">image_data</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">raw</span>
</span><span id="__span-1-8"><a id="__codelineno-1-8" name="__codelineno-1-8" href="#__codelineno-1-8"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">image_data</span><span class="p">)</span>
</span><span id="__span-1-9"><a id="__codelineno-1-9" name="__codelineno-1-9" href="#__codelineno-1-9"></a>
</span><span id="__span-1-10"><a id="__codelineno-1-10" name="__codelineno-1-10" href="#__codelineno-1-10"></a><span class="c1"># Zuweisung einer Pipeline f√ºr die Objekterkennung</span>
</span><span id="__span-1-11"><a id="__codelineno-1-11" name="__codelineno-1-11" href="#__codelineno-1-11"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">object_detector</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s1">&#39;object-detection&#39;</span><span class="p">)</span>
</span><span id="__span-1-12"><a id="__codelineno-1-12" name="__codelineno-1-12" href="#__codelineno-1-12"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">object_detector</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</span><span id="__span-1-13"><a id="__codelineno-1-13" name="__codelineno-1-13" href="#__codelineno-1-13"></a><span class="p">[{</span><span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="mf">0.9982201457023621</span><span class="p">,</span>
</span><span id="__span-1-14"><a id="__codelineno-1-14" name="__codelineno-1-14" href="#__codelineno-1-14"></a>  <span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;remote&#39;</span><span class="p">,</span>
</span><span id="__span-1-15"><a id="__codelineno-1-15" name="__codelineno-1-15" href="#__codelineno-1-15"></a>  <span class="s1">&#39;box&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;xmin&#39;</span><span class="p">:</span> <span class="mi">40</span><span class="p">,</span> <span class="s1">&#39;ymin&#39;</span><span class="p">:</span> <span class="mi">70</span><span class="p">,</span> <span class="s1">&#39;xmax&#39;</span><span class="p">:</span> <span class="mi">175</span><span class="p">,</span> <span class="s1">&#39;ymax&#39;</span><span class="p">:</span> <span class="mi">117</span><span class="p">}},</span>
</span><span id="__span-1-16"><a id="__codelineno-1-16" name="__codelineno-1-16" href="#__codelineno-1-16"></a> <span class="p">{</span><span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="mf">0.9960021376609802</span><span class="p">,</span>
</span><span id="__span-1-17"><a id="__codelineno-1-17" name="__codelineno-1-17" href="#__codelineno-1-17"></a>  <span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;remote&#39;</span><span class="p">,</span>
</span><span id="__span-1-18"><a id="__codelineno-1-18" name="__codelineno-1-18" href="#__codelineno-1-18"></a>  <span class="s1">&#39;box&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;xmin&#39;</span><span class="p">:</span> <span class="mi">333</span><span class="p">,</span> <span class="s1">&#39;ymin&#39;</span><span class="p">:</span> <span class="mi">72</span><span class="p">,</span> <span class="s1">&#39;xmax&#39;</span><span class="p">:</span> <span class="mi">368</span><span class="p">,</span> <span class="s1">&#39;ymax&#39;</span><span class="p">:</span> <span class="mi">187</span><span class="p">}},</span>
</span><span id="__span-1-19"><a id="__codelineno-1-19" name="__codelineno-1-19" href="#__codelineno-1-19"></a> <span class="p">{</span><span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="mf">0.9954745173454285</span><span class="p">,</span>
</span><span id="__span-1-20"><a id="__codelineno-1-20" name="__codelineno-1-20" href="#__codelineno-1-20"></a>  <span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;couch&#39;</span><span class="p">,</span>
</span><span id="__span-1-21"><a id="__codelineno-1-21" name="__codelineno-1-21" href="#__codelineno-1-21"></a>  <span class="s1">&#39;box&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;xmin&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;ymin&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;xmax&#39;</span><span class="p">:</span> <span class="mi">639</span><span class="p">,</span> <span class="s1">&#39;ymax&#39;</span><span class="p">:</span> <span class="mi">473</span><span class="p">}},</span>
</span><span id="__span-1-22"><a id="__codelineno-1-22" name="__codelineno-1-22" href="#__codelineno-1-22"></a> <span class="p">{</span><span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="mf">0.9988006353378296</span><span class="p">,</span>
</span><span id="__span-1-23"><a id="__codelineno-1-23" name="__codelineno-1-23" href="#__codelineno-1-23"></a>  <span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;cat&#39;</span><span class="p">,</span>
</span><span id="__span-1-24"><a id="__codelineno-1-24" name="__codelineno-1-24" href="#__codelineno-1-24"></a>  <span class="s1">&#39;box&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;xmin&#39;</span><span class="p">:</span> <span class="mi">13</span><span class="p">,</span> <span class="s1">&#39;ymin&#39;</span><span class="p">:</span> <span class="mi">52</span><span class="p">,</span> <span class="s1">&#39;xmax&#39;</span><span class="p">:</span> <span class="mi">314</span><span class="p">,</span> <span class="s1">&#39;ymax&#39;</span><span class="p">:</span> <span class="mi">470</span><span class="p">}},</span>
</span><span id="__span-1-25"><a id="__codelineno-1-25" name="__codelineno-1-25" href="#__codelineno-1-25"></a> <span class="p">{</span><span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="mf">0.9986783862113953</span><span class="p">,</span>
</span><span id="__span-1-26"><a id="__codelineno-1-26" name="__codelineno-1-26" href="#__codelineno-1-26"></a>  <span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;cat&#39;</span><span class="p">,</span>
</span><span id="__span-1-27"><a id="__codelineno-1-27" name="__codelineno-1-27" href="#__codelineno-1-27"></a>  <span class="s1">&#39;box&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;xmin&#39;</span><span class="p">:</span> <span class="mi">345</span><span class="p">,</span> <span class="s1">&#39;ymin&#39;</span><span class="p">:</span> <span class="mi">23</span><span class="p">,</span> <span class="s1">&#39;xmax&#39;</span><span class="p">:</span> <span class="mi">640</span><span class="p">,</span> <span class="s1">&#39;ymax&#39;</span><span class="p">:</span> <span class="mi">368</span><span class="p">}}]</span>
</span></code></pre></div>
<p>Hier erhalten wir eine Liste von Objekten, die im Bild erkannt wurden, mit einer Markierung, die das Objekt eingrenzt, und einem zugeh√∂rigen Konfidenzwert. Folgend ist das Originalbild links und die Vorhersagen rechts dargestellt:</p>
<h3 align="center">
    <a><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/coco_sample.png" width="400"></a>
    <a><img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/coco_sample_post_processed.png" width="400"></a>
</h3>

<p>Sie k√∂nnen mehr √ºber die von der <code>pipeline</code>-API unterst√ºtzten Aufgaben in <a href="https://huggingface.co/docs/transformers/task_summary">diesem Tutorial</a> erfahren.</p>
<p>Zus√§tzlich zur <code>pipeline</code> ben√∂tigt es nur drei Zeilen Code, um eines der vortrainierten Modelle f√ºr Ihre Aufgabe herunterzuladen und zu verwenden. Hier ist der Code f√ºr die PyTorch-Version:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModel</span>
</span><span id="__span-2-2"><a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a>
</span><span id="__span-2-3"><a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;google-bert/bert-base-uncased&quot;</span><span class="p">)</span>
</span><span id="__span-2-4"><a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;google-bert/bert-base-uncased&quot;</span><span class="p">)</span>
</span><span id="__span-2-5"><a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a>
</span><span id="__span-2-6"><a id="__codelineno-2-6" name="__codelineno-2-6" href="#__codelineno-2-6"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;Hello world!&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
</span><span id="__span-2-7"><a id="__codelineno-2-7" name="__codelineno-2-7" href="#__codelineno-2-7"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>
</span></code></pre></div>
<p>Und hier ist der entsprechende Code f√ºr TensorFlow:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">TFAutoModel</span>
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a>
</span><span id="__span-3-3"><a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;google-bert/bert-base-uncased&quot;</span><span class="p">)</span>
</span><span id="__span-3-4"><a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">model</span> <span class="o">=</span> <span class="n">TFAutoModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;google-bert/bert-base-uncased&quot;</span><span class="p">)</span>
</span><span id="__span-3-5"><a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a>
</span><span id="__span-3-6"><a id="__codelineno-3-6" name="__codelineno-3-6" href="#__codelineno-3-6"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;Hello world!&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;tf&quot;</span><span class="p">)</span>
</span><span id="__span-3-7"><a id="__codelineno-3-7" name="__codelineno-3-7" href="#__codelineno-3-7"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>
</span></code></pre></div>
<p>Der Tokenizer ist f√ºr die gesamte Vorverarbeitung, die das vortrainierte Modell ben√∂tigt, verantwortlich und kann direkt auf einem einzelnen String (wie in den obigen Beispielen) oder einer Liste ausgef√ºhrt werden. Er gibt ein Dictionary aus, das Sie im darauffolgenden Code verwenden oder einfach direkt Ihrem Modell √ºbergeben k√∂nnen, indem Sie den ** Operator zum Entpacken von Argumenten einsetzen.</p>
<p>Das Modell selbst ist ein regul√§res <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module">PyTorch <code>nn.Module</code></a> oder ein <a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model">TensorFlow <code>tf.keras.Model</code></a> (abh√§ngig von Ihrem Backend), das Sie wie gewohnt verwenden k√∂nnen. <a href="https://huggingface.co/docs/transformers/training">Dieses Tutorial</a> erkl√§rt, wie man ein solches Modell in eine klassische PyTorch- oder TensorFlow-Trainingsschleife integrieren kann oder wie man unsere <code>Trainer</code>-API verwendet, um es schnell auf einem neuen Datensatz zu feintunen.</p>
<h2 id="warum-sollten-sie-transformers-verwenden">Warum sollten Sie ü§ó Transformers verwenden?</h2>
<ol>
<li>
<p>Benutzerfreundliche Modelle auf dem neuesten Stand der Technik:</p>
<ul>
<li>Hohe Leistung bei Aufgaben zu Natural Language Understanding &amp; Generation, Computer Vision und Audio.</li>
<li>Niedrige Einstiegsh√ºrde f√ºr Bildungskr√§fte und Praktiker.</li>
<li>Wenige benutzerseitige Abstraktionen mit nur drei zu lernenden Klassen.</li>
<li>Eine einheitliche API f√ºr die Verwendung aller unserer vortrainierten Modelle.</li>
</ul>
</li>
<li>
<p>Geringere Rechenkosten, kleinerer CO<sub>2</sub>-Fu√üabdruck:</p>
<ul>
<li>Forscher k√∂nnen trainierte Modelle teilen, anstatt sie immer wieder neu zu trainieren.</li>
<li>Praktiker k√∂nnen die Rechenzeit und Produktionskosten reduzieren.</li>
<li>Dutzende Architekturen mit √ºber 400.000 vortrainierten Modellen √ºber alle Modalit√§ten hinweg.</li>
</ul>
</li>
<li>
<p>W√§hlen Sie das richtige Framework f√ºr jeden Lebensabschnitt eines Modells:</p>
<ul>
<li>Trainieren Sie Modelle auf neustem Stand der Technik in nur drei Codezeilen.</li>
<li>Verwenden Sie ein einzelnes Modell nach Belieben mit TF2.0-/PyTorch-/JAX-Frameworks.</li>
<li>W√§hlen Sie nahtlos das richtige Framework f√ºr Training, Evaluation und Produktiveinsatz.</li>
</ul>
</li>
<li>
<p>Passen Sie ein Modell oder Beispiel leicht an Ihre Bed√ºrfnisse an:</p>
<ul>
<li>Wir bieten Beispiele f√ºr jede Architektur an, um die von ihren urspr√ºnglichen Autoren ver√∂ffentlichten Ergebnisse zu reproduzieren.</li>
<li>Modellinterna sind so einheitlich wie m√∂glich verf√ºgbar gemacht.</li>
<li>Modelldateien k√∂nnen unabh√§ngig von der Bibliothek f√ºr schnelle Experimente verwendet werden.</li>
</ul>
</li>
</ol>
<h2 id="warum-sollten-sie-transformers-nicht-verwenden">Warum sollten Sie ü§ó Transformers nicht verwenden?</h2>
<ul>
<li>Diese Bibliothek ist kein modularer Werkzeugkasten mit Bausteinen f√ºr neuronale Netze. Der Code in den Modelldateien ist absichtlich nicht mit zus√§tzlichen Abstraktionen refaktorisiert, sodass Forscher schnell mit jedem der Modelle iterieren k√∂nnen, ohne sich in zus√§tzliche Abstraktionen/Dateien vertiefen zu m√ºssen.</li>
<li>Die Trainings-API ist nicht daf√ºr gedacht, mit beliebigen Modellen zu funktionieren, sondern ist f√ºr die Verwendung mit den von der Bibliothek bereitgestellten Modellen optimiert. F√ºr generische Trainingsschleifen von maschinellem Lernen sollten Sie eine andere Bibliothek verwenden (m√∂glicherweise <a href="https://huggingface.co/docs/accelerate">Accelerate</a>).</li>
<li>Auch wenn wir bestrebt sind, so viele Anwendungsf√§lle wie m√∂glich zu veranschaulichen, sind die Beispielskripte in unserem <a href="./examples"><code>examples</code></a> Ordner genau das: Beispiele. Es ist davon auszugehen, dass sie nicht sofort auf Ihr spezielles Problem anwendbar sind und einige Codezeilen ge√§ndert werden m√ºssen, um sie f√ºr Ihre Bed√ºrfnisse anzupassen.</li>
</ul>
<h2 id="installation">Installation</h2>
<h3 id="mit-pip">Mit pip</h3>
<p>Dieses Repository wurde mit Python 3.9+, Flax 0.4.1+, PyTorch 2.1+ und TensorFlow 2.6+ getestet.</p>
<p>Sie sollten ü§ó Transformers in einer <a href="https://docs.python.org/3/library/venv.html">virtuellen Umgebung</a> installieren. Wenn Sie mit virtuellen Python-Umgebungen nicht vertraut sind, schauen Sie sich den <a href="https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/">Benutzerleitfaden</a> an.</p>
<p>Erstellen und aktivieren Sie zuerst eine virtuelle Umgebung mit der Python-Version, die Sie verwenden m√∂chten.</p>
<p>Dann m√ºssen Sie entweder Flax, PyTorch oder TensorFlow installieren. Bitte beziehe dich entsprechend auf die jeweiligen Installationsanleitungen f√ºr <a href="https://www.tensorflow.org/install/">TensorFlow</a>, <a href="https://pytorch.org/get-started/locally/#start-locally">PyTorch</a>, und/oder <a href="https://github.com/google/flax#quick-install">Flax</a> und <a href="https://github.com/google/jax#installation">Jax</a> f√ºr den spezifischen Installationsbefehl f√ºr Ihre Plattform.</p>
<p>Wenn eines dieser Backends installiert ist, kann ü§ó Transformers wie folgt mit pip installiert werden:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a>pip<span class="w"> </span>install<span class="w"> </span>transformers
</span></code></pre></div>
<p>Wenn Sie mit den Beispielen experimentieren m√∂chten oder die neueste Version des Codes ben√∂tigen und nicht auf eine neue Ver√∂ffentlichung warten k√∂nnen, m√ºssen Sie <a href="https://huggingface.co/docs/transformers/installation#installing-from-source">die Bibliothek von der Quelle installieren</a>.</p>
<h3 id="mit-conda">Mit conda</h3>
<p>ü§ó Transformers kann wie folgt mit conda installiert werden:</p>
<p>```shell script
conda install conda-forge::transformers
<div class="language-bash highlight"><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a>&gt;<span class="w"> </span>**_HINWEIS:_**<span class="w"> </span>Die<span class="w"> </span>Installation<span class="w"> </span>von<span class="w"> </span><span class="sb">`</span>transformers<span class="sb">`</span><span class="w"> </span>aus<span class="w"> </span>dem<span class="w"> </span><span class="sb">`</span>huggingface<span class="sb">`</span>-Kanal<span class="w"> </span>ist<span class="w"> </span>veraltet.
</span><span id="__span-5-2"><a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a>
</span><span id="__span-5-3"><a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a>Folgen<span class="w"> </span>Sie<span class="w"> </span>den<span class="w"> </span>Installationsanleitungen<span class="w"> </span>von<span class="w"> </span>Flax,<span class="w"> </span>PyTorch<span class="w"> </span>oder<span class="w"> </span>TensorFlow,<span class="w"> </span>um<span class="w"> </span>zu<span class="w"> </span>sehen,<span class="w"> </span>wie<span class="w"> </span>sie<span class="w"> </span>mit<span class="w"> </span>conda<span class="w"> </span>installiert<span class="w"> </span>werden<span class="w"> </span>k√∂nnen.
</span><span id="__span-5-4"><a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a>
</span><span id="__span-5-5"><a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a>&gt;<span class="w"> </span>**_HINWEIS:_**<span class="w"> </span>Auf<span class="w"> </span>Windows<span class="w"> </span>werden<span class="w"> </span>Sie<span class="w"> </span>m√∂glicherweise<span class="w"> </span>aufgefordert,<span class="w"> </span>den<span class="w"> </span>Entwicklermodus<span class="w"> </span>zu<span class="w"> </span>aktivieren,<span class="w"> </span>um<span class="w"> </span>von<span class="w"> </span>Caching<span class="w"> </span>zu<span class="w"> </span>profitieren.<span class="w"> </span>Wenn<span class="w"> </span>das<span class="w"> </span>f√ºr<span class="w"> </span>Sie<span class="w"> </span>keine<span class="w"> </span>Option<span class="w"> </span>ist,<span class="w"> </span>lassen<span class="w"> </span>Sie<span class="w"> </span>es<span class="w"> </span>uns<span class="w"> </span>bitte<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="o">[</span>diesem<span class="w"> </span>Issue<span class="o">](</span>https://github.com/huggingface/huggingface_hub/issues/1062<span class="o">)</span><span class="w"> </span>wissen.
</span><span id="__span-5-6"><a id="__codelineno-5-6" name="__codelineno-5-6" href="#__codelineno-5-6"></a>
</span><span id="__span-5-7"><a id="__codelineno-5-7" name="__codelineno-5-7" href="#__codelineno-5-7"></a><span class="c1">## Modellarchitekturen</span>
</span><span id="__span-5-8"><a id="__codelineno-5-8" name="__codelineno-5-8" href="#__codelineno-5-8"></a>
</span><span id="__span-5-9"><a id="__codelineno-5-9" name="__codelineno-5-9" href="#__codelineno-5-9"></a>**<span class="o">[</span>Alle<span class="w"> </span>Modell-Checkpoints<span class="o">](</span>https://huggingface.co/models<span class="o">)</span>**,<span class="w"> </span>die<span class="w"> </span>von<span class="w"> </span>ü§ó<span class="w"> </span>Transformers<span class="w"> </span>bereitgestellt<span class="w"> </span>werden,<span class="w"> </span>sind<span class="w"> </span>nahtlos<span class="w"> </span>aus<span class="w"> </span>dem<span class="w"> </span>huggingface.co<span class="w"> </span><span class="o">[</span>Model<span class="w"> </span>Hub<span class="o">](</span>https://huggingface.co/models<span class="o">)</span><span class="w"> </span>integriert,<span class="w"> </span>wo<span class="w"> </span>sie<span class="w"> </span>direkt<span class="w"> </span>von<span class="w"> </span><span class="o">[</span>Benutzern<span class="o">](</span>https://huggingface.co/users<span class="o">)</span><span class="w"> </span>und<span class="w"> </span><span class="o">[</span>Organisationen<span class="o">](</span>https://huggingface.co/organizations<span class="o">)</span><span class="w"> </span>hochgeladen<span class="w"> </span>werden.
</span><span id="__span-5-10"><a id="__codelineno-5-10" name="__codelineno-5-10" href="#__codelineno-5-10"></a>
</span><span id="__span-5-11"><a id="__codelineno-5-11" name="__codelineno-5-11" href="#__codelineno-5-11"></a>Aktuelle<span class="w"> </span>Anzahl<span class="w"> </span>der<span class="w"> </span>Checkpoints:<span class="w"> </span>!<span class="o">[](</span>https://img.shields.io/endpoint?url<span class="o">=</span>https://huggingface.co/api/shields/models<span class="p">&amp;</span><span class="nv">color</span><span class="o">=</span>brightgreen<span class="o">)</span>
</span><span id="__span-5-12"><a id="__codelineno-5-12" name="__codelineno-5-12" href="#__codelineno-5-12"></a>
</span><span id="__span-5-13"><a id="__codelineno-5-13" name="__codelineno-5-13" href="#__codelineno-5-13"></a>ü§ó<span class="w"> </span>Transformers<span class="w"> </span>bietet<span class="w"> </span>derzeit<span class="w"> </span>die<span class="w"> </span>folgenden<span class="w"> </span>Architekturen<span class="w"> </span>an:<span class="w"> </span>siehe<span class="w"> </span><span class="o">[</span>hier<span class="o">](</span>https://huggingface.co/docs/transformers/model_summary<span class="o">)</span><span class="w"> </span>f√ºr<span class="w"> </span>eine<span class="w"> </span>jeweilige<span class="w"> </span>√úbersicht.
</span><span id="__span-5-14"><a id="__codelineno-5-14" name="__codelineno-5-14" href="#__codelineno-5-14"></a>
</span><span id="__span-5-15"><a id="__codelineno-5-15" name="__codelineno-5-15" href="#__codelineno-5-15"></a>Um<span class="w"> </span>zu<span class="w"> </span>√ºberpr√ºfen,<span class="w"> </span>ob<span class="w"> </span>jedes<span class="w"> </span>Modell<span class="w"> </span>eine<span class="w"> </span>Implementierung<span class="w"> </span><span class="k">in</span><span class="w"> </span>Flax,<span class="w"> </span>PyTorch<span class="w"> </span>oder<span class="w"> </span>TensorFlow<span class="w"> </span>hat<span class="w"> </span>oder<span class="w"> </span>√ºber<span class="w"> </span>einen<span class="w"> </span>zugeh√∂rigen<span class="w"> </span>Tokenizer<span class="w"> </span>verf√ºgt,<span class="w"> </span>der<span class="w"> </span>von<span class="w"> </span>der<span class="w"> </span>ü§ó<span class="w"> </span>Tokenizers-Bibliothek<span class="w"> </span>unterst√ºtzt<span class="w"> </span>wird,<span class="w"> </span>schauen<span class="w"> </span>Sie<span class="w"> </span>auf<span class="w"> </span><span class="o">[</span>diese<span class="w"> </span>Tabelle<span class="o">](</span>https://huggingface.co/docs/transformers/index#supported-frameworks<span class="o">)</span>.
</span><span id="__span-5-16"><a id="__codelineno-5-16" name="__codelineno-5-16" href="#__codelineno-5-16"></a>
</span><span id="__span-5-17"><a id="__codelineno-5-17" name="__codelineno-5-17" href="#__codelineno-5-17"></a>Diese<span class="w"> </span>Implementierungen<span class="w"> </span>wurden<span class="w"> </span>mit<span class="w"> </span>mehreren<span class="w"> </span>Datens√§tzen<span class="w"> </span>getestet<span class="w"> </span><span class="o">(</span>siehe<span class="w"> </span>Beispielskripte<span class="o">)</span><span class="w"> </span>und<span class="w"> </span>sollten<span class="w"> </span>den<span class="w"> </span>Leistungen<span class="w"> </span>der<span class="w"> </span>urspr√ºnglichen<span class="w"> </span>Implementierungen<span class="w"> </span>entsprechen.<span class="w"> </span>Weitere<span class="w"> </span>Details<span class="w"> </span>zur<span class="w"> </span>Leistung<span class="w"> </span>finden<span class="w"> </span>Sie<span class="w"> </span>im<span class="w"> </span>Abschnitt<span class="w"> </span>der<span class="w"> </span>Beispiele<span class="w"> </span><span class="k">in</span><span class="w"> </span>der<span class="w"> </span><span class="o">[</span>Dokumentation<span class="o">](</span>https://github.com/huggingface/transformers/tree/main/examples<span class="o">)</span>.
</span><span id="__span-5-18"><a id="__codelineno-5-18" name="__codelineno-5-18" href="#__codelineno-5-18"></a>
</span><span id="__span-5-19"><a id="__codelineno-5-19" name="__codelineno-5-19" href="#__codelineno-5-19"></a><span class="c1">## Mehr erfahren</span>
</span><span id="__span-5-20"><a id="__codelineno-5-20" name="__codelineno-5-20" href="#__codelineno-5-20"></a>
</span><span id="__span-5-21"><a id="__codelineno-5-21" name="__codelineno-5-21" href="#__codelineno-5-21"></a><span class="p">|</span><span class="w"> </span>Abschnitt<span class="w"> </span><span class="p">|</span><span class="w"> </span>Beschreibung<span class="w"> </span><span class="p">|</span>
</span><span id="__span-5-22"><a id="__codelineno-5-22" name="__codelineno-5-22" href="#__codelineno-5-22"></a><span class="p">|</span>-<span class="p">|</span>-<span class="p">|</span>
</span><span id="__span-5-23"><a id="__codelineno-5-23" name="__codelineno-5-23" href="#__codelineno-5-23"></a><span class="p">|</span><span class="w"> </span><span class="o">[</span>Dokumentation<span class="o">](</span>https://huggingface.co/docs/transformers/<span class="o">)</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>Vollst√§ndige<span class="w"> </span>API-Dokumentation<span class="w"> </span>und<span class="w"> </span>Tutorials<span class="w"> </span><span class="p">|</span>
</span><span id="__span-5-24"><a id="__codelineno-5-24" name="__codelineno-5-24" href="#__codelineno-5-24"></a><span class="p">|</span><span class="w"> </span><span class="o">[</span>Zusammenfassung<span class="w"> </span>der<span class="w"> </span>Aufgaben<span class="o">](</span>https://huggingface.co/docs/transformers/task_summary<span class="o">)</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>Von<span class="w"> </span>ü§ó<span class="w"> </span>Transformers<span class="w"> </span>unterst√ºtzte<span class="w"> </span>Aufgaben<span class="w"> </span><span class="p">|</span>
</span><span id="__span-5-25"><a id="__codelineno-5-25" name="__codelineno-5-25" href="#__codelineno-5-25"></a><span class="p">|</span><span class="w"> </span><span class="o">[</span>Vorverarbeitungs-Tutorial<span class="o">](</span>https://huggingface.co/docs/transformers/preprocessing<span class="o">)</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>Verwendung<span class="w"> </span>der<span class="w"> </span><span class="sb">`</span>Tokenizer<span class="sb">`</span>-Klasse<span class="w"> </span>zur<span class="w"> </span>Vorverarbeitung<span class="w"> </span>der<span class="w"> </span>Daten<span class="w"> </span>f√ºr<span class="w"> </span>die<span class="w"> </span>Modelle<span class="w"> </span><span class="p">|</span>
</span><span id="__span-5-26"><a id="__codelineno-5-26" name="__codelineno-5-26" href="#__codelineno-5-26"></a><span class="p">|</span><span class="w"> </span><span class="o">[</span>Training<span class="w"> </span>und<span class="w"> </span>Feintuning<span class="o">](</span>https://huggingface.co/docs/transformers/training<span class="o">)</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>Verwendung<span class="w"> </span>der<span class="w"> </span>von<span class="w"> </span>ü§ó<span class="w"> </span>Transformers<span class="w"> </span>bereitgestellten<span class="w"> </span>Modelle<span class="w"> </span><span class="k">in</span><span class="w"> </span>einer<span class="w"> </span>PyTorch-/TensorFlow-Trainingsschleife<span class="w"> </span>und<span class="w"> </span>der<span class="w"> </span><span class="sb">`</span>Trainer<span class="sb">`</span>-API<span class="w"> </span><span class="p">|</span>
</span><span id="__span-5-27"><a id="__codelineno-5-27" name="__codelineno-5-27" href="#__codelineno-5-27"></a><span class="p">|</span><span class="w"> </span><span class="o">[</span>Schnelleinstieg:<span class="w"> </span>Feintuning/Anwendungsskripte<span class="o">](</span>https://github.com/huggingface/transformers/tree/main/examples<span class="o">)</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>Beispielskripte<span class="w"> </span>f√ºr<span class="w"> </span>das<span class="w"> </span>Feintuning<span class="w"> </span>von<span class="w"> </span>Modellen<span class="w"> </span>f√ºr<span class="w"> </span>eine<span class="w"> </span>breite<span class="w"> </span>Palette<span class="w"> </span>von<span class="w"> </span>Aufgaben<span class="w"> </span><span class="p">|</span>
</span><span id="__span-5-28"><a id="__codelineno-5-28" name="__codelineno-5-28" href="#__codelineno-5-28"></a><span class="p">|</span><span class="w"> </span><span class="o">[</span>Modellfreigabe<span class="w"> </span>und<span class="w"> </span>-upload<span class="o">](</span>https://huggingface.co/docs/transformers/model_sharing<span class="o">)</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>Laden<span class="w"> </span>Sie<span class="w"> </span>Ihre<span class="w"> </span>feingetunten<span class="w"> </span>Modelle<span class="w"> </span>hoch<span class="w"> </span>und<span class="w"> </span>teilen<span class="w"> </span>Sie<span class="w"> </span>sie<span class="w"> </span>mit<span class="w"> </span>der<span class="w"> </span>Community<span class="w"> </span><span class="p">|</span>
</span><span id="__span-5-29"><a id="__codelineno-5-29" name="__codelineno-5-29" href="#__codelineno-5-29"></a>
</span><span id="__span-5-30"><a id="__codelineno-5-30" name="__codelineno-5-30" href="#__codelineno-5-30"></a><span class="c1">## Zitation</span>
</span><span id="__span-5-31"><a id="__codelineno-5-31" name="__codelineno-5-31" href="#__codelineno-5-31"></a>
</span><span id="__span-5-32"><a id="__codelineno-5-32" name="__codelineno-5-32" href="#__codelineno-5-32"></a>Wir<span class="w"> </span>haben<span class="w"> </span>jetzt<span class="w"> </span>ein<span class="w"> </span><span class="o">[</span>Paper<span class="o">](</span>https://www.aclweb.org/anthology/2020.emnlp-demos.6/<span class="o">)</span>,<span class="w"> </span>das<span class="w"> </span>Sie<span class="w"> </span>f√ºr<span class="w"> </span>die<span class="w"> </span>ü§ó<span class="w"> </span>Transformers-Bibliothek<span class="w"> </span>zitieren<span class="w"> </span>k√∂nnen:
</span><span id="__span-5-33"><a id="__codelineno-5-33" name="__codelineno-5-33" href="#__codelineno-5-33"></a>
</span><span id="__span-5-34"><a id="__codelineno-5-34" name="__codelineno-5-34" href="#__codelineno-5-34"></a><span class="sb">```</span>bibtex
</span><span id="__span-5-35"><a id="__codelineno-5-35" name="__codelineno-5-35" href="#__codelineno-5-35"></a>@inproceedings<span class="o">{</span>wolf-etal-2020-transformers,
</span><span id="__span-5-36"><a id="__codelineno-5-36" name="__codelineno-5-36" href="#__codelineno-5-36"></a><span class="w">    </span><span class="nv">title</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;Transformers: State-of-the-Art Natural Language Processing&quot;</span>,
</span><span id="__span-5-37"><a id="__codelineno-5-37" name="__codelineno-5-37" href="#__codelineno-5-37"></a><span class="w">    </span><span class="nv">author</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and R√©mi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush&quot;</span>,
</span><span id="__span-5-38"><a id="__codelineno-5-38" name="__codelineno-5-38" href="#__codelineno-5-38"></a><span class="w">    </span><span class="nv">booktitle</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations&quot;</span>,
</span><span id="__span-5-39"><a id="__codelineno-5-39" name="__codelineno-5-39" href="#__codelineno-5-39"></a><span class="w">    </span><span class="nv">month</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>oct,
</span><span id="__span-5-40"><a id="__codelineno-5-40" name="__codelineno-5-40" href="#__codelineno-5-40"></a><span class="w">    </span><span class="nv">year</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;2020&quot;</span>,
</span><span id="__span-5-41"><a id="__codelineno-5-41" name="__codelineno-5-41" href="#__codelineno-5-41"></a><span class="w">    </span><span class="nv">address</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;Online&quot;</span>,
</span><span id="__span-5-42"><a id="__codelineno-5-42" name="__codelineno-5-42" href="#__codelineno-5-42"></a><span class="w">    </span><span class="nv">publisher</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;Association for Computational Linguistics&quot;</span>,
</span><span id="__span-5-43"><a id="__codelineno-5-43" name="__codelineno-5-43" href="#__codelineno-5-43"></a><span class="w">    </span><span class="nv">url</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;https://www.aclweb.org/anthology/2020.emnlp-demos.6&quot;</span>,
</span><span id="__span-5-44"><a id="__codelineno-5-44" name="__codelineno-5-44" href="#__codelineno-5-44"></a><span class="w">    </span><span class="nv">pages</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;38--45&quot;</span>
</span><span id="__span-5-45"><a id="__codelineno-5-45" name="__codelineno-5-45" href="#__codelineno-5-45"></a><span class="o">}</span>
</span></code></pre></div></p>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../../../..", "features": ["navigation.tabs", "navigation.indexes", "navigation.instant", "navigation.sections", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow", "content.tabs.link", "content.code.copy"], "search": "../../../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
    
  </body>
</html>