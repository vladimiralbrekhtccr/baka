
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../../../../../../assets/favicon.ico">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.22">
    
    
      
        <title>Glossary - Ohayou</title>
      
    
    
      <link rel="stylesheet" href="../../../../../../assets/stylesheets/main.84d31ad4.min.css">
      
        
        <link rel="stylesheet" href="../../../../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../../../../assets/extra.css">
    
    <script>__md_scope=new URL("../../../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#glossary" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../../../.." title="Ohayou" class="md-header__button md-logo" aria-label="Ohayou" data-md-component="logo">
      
  <img src="../../../../../../assets/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Ohayou
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Glossary
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../../ohayou/" class="md-tabs__link">
        
  
  
    
  
  Ohayou

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../../../vllm/open_ai_vllm_example_a_v_t/" class="md-tabs__link">
          
  
  
    
  
  vLLM

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../../../llm/speculative_decoding/" class="md-tabs__link">
          
  
  
    
  
  LLM

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../../../vlm/qwen3_vl_4B_object_detection/" class="md-tabs__link">
          
  
  
    
  
  VLM

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../../md_format_helpers/" class="md-tabs__link">
        
  
  
    
  
  MD format helpers

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../../docker/" class="md-tabs__link">
        
  
  
    
  
  Docker

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../../linux/" class="md-tabs__link">
        
  
  
    
  
  Linux

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../../moe/" class="md-tabs__link">
        
  
  
    
  
  Mixture of Experts

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../../slurm/" class="md-tabs__link">
        
  
  
    
  
  Slurm

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../../../japanese-phrases/" class="md-tabs__link">
          
  
  
    
  
  Japanese Phrases

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../../hackathon/index.md" class="md-tabs__link">
        
  
  
    
  
  Hack

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../../../.." title="Ohayou" class="md-nav__button md-logo" aria-label="Ohayou" data-md-component="logo">
      
  <img src="../../../../../../assets/logo.png" alt="logo">

    </a>
    Ohayou
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../ohayou/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Ohayou
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    vLLM
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            vLLM
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../vllm/open_ai_vllm_example_a_v_t/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Single Request
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../vllm/bash_vllm_serve/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Bash online serve
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../vllm/benchmarks/performance_eval/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Benchmarks
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    LLM
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            LLM
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../llm/speculative_decoding/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Speculative Decoding
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    VLM
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            VLM
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../vlm/qwen3_vl_4B_object_detection/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Qwen3VL
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../md_format_helpers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    MD format helpers
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../docker/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Docker
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../linux/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Linux
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../moe/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Mixture of Experts
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../slurm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Slurm
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_11" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../../../../japanese-phrases/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Japanese Phrases
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_11" id="__nav_11_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_11">
            <span class="md-nav__icon md-icon"></span>
            Japanese Phrases
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_11_2" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../../../../japanese-phrases/daily-life/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Daily Life
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_11_2" id="__nav_11_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_11_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_11_2">
            <span class="md-nav__icon md-icon"></span>
            Daily Life
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../japanese-phrases/daily-life/shopping/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Shopping
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_11_3" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../../../../japanese-phrases/greetings/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Greetings
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_11_3" id="__nav_11_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_11_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_11_3">
            <span class="md-nav__icon md-icon"></span>
            Greetings
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../japanese-phrases/greetings/casual/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Casual
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../japanese-phrases/emotions/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Emotions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../japanese-phrases/anime-manga/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Anime/Manga
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../hackathon/index.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Hack
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#a" class="md-nav__link">
    <span class="md-ellipsis">
      A
    </span>
  </a>
  
    <nav class="md-nav" aria-label="A">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#attention-mask" class="md-nav__link">
    <span class="md-ellipsis">
      attention mask
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#autoencoding-models" class="md-nav__link">
    <span class="md-ellipsis">
      autoencoding models
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#autoregressive-models" class="md-nav__link">
    <span class="md-ellipsis">
      autoregressive models
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#b" class="md-nav__link">
    <span class="md-ellipsis">
      B
    </span>
  </a>
  
    <nav class="md-nav" aria-label="B">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#backbone" class="md-nav__link">
    <span class="md-ellipsis">
      backbone
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#c" class="md-nav__link">
    <span class="md-ellipsis">
      C
    </span>
  </a>
  
    <nav class="md-nav" aria-label="C">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#causal-language-modeling" class="md-nav__link">
    <span class="md-ellipsis">
      causal language modeling
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#channel" class="md-nav__link">
    <span class="md-ellipsis">
      channel
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#connectionist-temporal-classification-ctc" class="md-nav__link">
    <span class="md-ellipsis">
      connectionist temporal classification (CTC)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#convolution" class="md-nav__link">
    <span class="md-ellipsis">
      convolution
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#d" class="md-nav__link">
    <span class="md-ellipsis">
      D
    </span>
  </a>
  
    <nav class="md-nav" aria-label="D">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dataparallel-dp" class="md-nav__link">
    <span class="md-ellipsis">
      DataParallel (DP)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decoder-input-ids" class="md-nav__link">
    <span class="md-ellipsis">
      decoder input IDs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decoder-models" class="md-nav__link">
    <span class="md-ellipsis">
      decoder models
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deep-learning-dl" class="md-nav__link">
    <span class="md-ellipsis">
      deep learning (DL)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#e" class="md-nav__link">
    <span class="md-ellipsis">
      E
    </span>
  </a>
  
    <nav class="md-nav" aria-label="E">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#encoder-models" class="md-nav__link">
    <span class="md-ellipsis">
      encoder models
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#f" class="md-nav__link">
    <span class="md-ellipsis">
      F
    </span>
  </a>
  
    <nav class="md-nav" aria-label="F">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#feature-extraction" class="md-nav__link">
    <span class="md-ellipsis">
      feature extraction
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#feed-forward-chunking" class="md-nav__link">
    <span class="md-ellipsis">
      feed forward chunking
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#finetuned-models" class="md-nav__link">
    <span class="md-ellipsis">
      finetuned models
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#h" class="md-nav__link">
    <span class="md-ellipsis">
      H
    </span>
  </a>
  
    <nav class="md-nav" aria-label="H">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#head" class="md-nav__link">
    <span class="md-ellipsis">
      head
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#i" class="md-nav__link">
    <span class="md-ellipsis">
      I
    </span>
  </a>
  
    <nav class="md-nav" aria-label="I">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#image-patch" class="md-nav__link">
    <span class="md-ellipsis">
      image patch
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference" class="md-nav__link">
    <span class="md-ellipsis">
      inference
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#input-ids" class="md-nav__link">
    <span class="md-ellipsis">
      input IDs
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#l" class="md-nav__link">
    <span class="md-ellipsis">
      L
    </span>
  </a>
  
    <nav class="md-nav" aria-label="L">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#labels" class="md-nav__link">
    <span class="md-ellipsis">
      labels
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#large-language-models-llm" class="md-nav__link">
    <span class="md-ellipsis">
      large language models (LLM)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#m" class="md-nav__link">
    <span class="md-ellipsis">
      M
    </span>
  </a>
  
    <nav class="md-nav" aria-label="M">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#masked-language-modeling-mlm" class="md-nav__link">
    <span class="md-ellipsis">
      masked language modeling (MLM)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multimodal" class="md-nav__link">
    <span class="md-ellipsis">
      multimodal
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#n" class="md-nav__link">
    <span class="md-ellipsis">
      N
    </span>
  </a>
  
    <nav class="md-nav" aria-label="N">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#natural-language-generation-nlg" class="md-nav__link">
    <span class="md-ellipsis">
      Natural language generation (NLG)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#natural-language-processing-nlp" class="md-nav__link">
    <span class="md-ellipsis">
      Natural language processing (NLP)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#natural-language-understanding-nlu" class="md-nav__link">
    <span class="md-ellipsis">
      Natural language understanding (NLU)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#p" class="md-nav__link">
    <span class="md-ellipsis">
      P
    </span>
  </a>
  
    <nav class="md-nav" aria-label="P">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pipeline" class="md-nav__link">
    <span class="md-ellipsis">
      pipeline
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pipelineparallel-pp" class="md-nav__link">
    <span class="md-ellipsis">
      PipelineParallel (PP)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pixel-values" class="md-nav__link">
    <span class="md-ellipsis">
      pixel values
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pooling" class="md-nav__link">
    <span class="md-ellipsis">
      pooling
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#position-ids" class="md-nav__link">
    <span class="md-ellipsis">
      position IDs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#preprocessing" class="md-nav__link">
    <span class="md-ellipsis">
      preprocessing
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pretrained-model" class="md-nav__link">
    <span class="md-ellipsis">
      pretrained model
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#r" class="md-nav__link">
    <span class="md-ellipsis">
      R
    </span>
  </a>
  
    <nav class="md-nav" aria-label="R">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#recurrent-neural-network-rnn" class="md-nav__link">
    <span class="md-ellipsis">
      recurrent neural network (RNN)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#representation-learning" class="md-nav__link">
    <span class="md-ellipsis">
      representation learning
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#s" class="md-nav__link">
    <span class="md-ellipsis">
      S
    </span>
  </a>
  
    <nav class="md-nav" aria-label="S">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sampling-rate" class="md-nav__link">
    <span class="md-ellipsis">
      sampling rate
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#self-attention" class="md-nav__link">
    <span class="md-ellipsis">
      self-attention
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#self-supervised-learning" class="md-nav__link">
    <span class="md-ellipsis">
      self-supervised learning
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#semi-supervised-learning" class="md-nav__link">
    <span class="md-ellipsis">
      semi-supervised learning
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sequence-to-sequence-seq2seq" class="md-nav__link">
    <span class="md-ellipsis">
      sequence-to-sequence (seq2seq)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sharded-ddp" class="md-nav__link">
    <span class="md-ellipsis">
      Sharded DDP
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stride" class="md-nav__link">
    <span class="md-ellipsis">
      stride
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#supervised-learning" class="md-nav__link">
    <span class="md-ellipsis">
      supervised learning
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#t" class="md-nav__link">
    <span class="md-ellipsis">
      T
    </span>
  </a>
  
    <nav class="md-nav" aria-label="T">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensor-parallelism-tp" class="md-nav__link">
    <span class="md-ellipsis">
      Tensor Parallelism (TP)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#token" class="md-nav__link">
    <span class="md-ellipsis">
      token
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#token-type-ids" class="md-nav__link">
    <span class="md-ellipsis">
      token Type IDs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transfer-learning" class="md-nav__link">
    <span class="md-ellipsis">
      transfer learning
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transformer" class="md-nav__link">
    <span class="md-ellipsis">
      transformer
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#u" class="md-nav__link">
    <span class="md-ellipsis">
      U
    </span>
  </a>
  
    <nav class="md-nav" aria-label="U">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#unsupervised-learning" class="md-nav__link">
    <span class="md-ellipsis">
      unsupervised learning
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#z" class="md-nav__link">
    <span class="md-ellipsis">
      Z
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Z">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#zero-redundancy-optimizer-zero" class="md-nav__link">
    <span class="md-ellipsis">
      Zero Redundancy Optimizer (ZeRO)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<!--Copyright 2020 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.

âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->

<h1 id="glossary">Glossary</h1>
<p>This glossary defines general machine learning and ðŸ¤— Transformers terms to help you better understand the
documentation.</p>
<h2 id="a">A</h2>
<h3 id="attention-mask">attention mask</h3>
<p>The attention mask is an optional argument used when batching sequences together.</p>
<p><Youtube id="M6adb1j2jPI"/></p>
<p>This argument indicates to the model which tokens should be attended to, and which should not.</p>
<p>For example, consider these two sequences:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">BertTokenizer</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">BertTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;google-bert/bert-base-cased&quot;</span><span class="p">)</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">sequence_a</span> <span class="o">=</span> <span class="s2">&quot;This is a short sequence.&quot;</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">sequence_b</span> <span class="o">=</span> <span class="s2">&quot;This is a rather long sequence. It is at least longer than the sequence A.&quot;</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">encoded_sequence_a</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">sequence_a</span><span class="p">)[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span>
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">encoded_sequence_b</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">sequence_b</span><span class="p">)[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span>
</span></code></pre></div>
<p>The encoded versions have different lengths:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">encoded_sequence_a</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">encoded_sequence_b</span><span class="p">)</span>
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">19</span><span class="p">)</span>
</span></code></pre></div>
<p>Therefore, we can't put them together in the same tensor as-is. The first sequence needs to be padded up to the length
of the second one, or the second one needs to be truncated down to the length of the first one.</p>
<p>In the first case, the list of IDs will be extended by the padding indices. We can pass a list to the tokenizer and ask
it to pad like this:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">padded_sequences</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">([</span><span class="n">sequence_a</span><span class="p">,</span> <span class="n">sequence_b</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></code></pre></div>
<p>We can see that 0s have been added on the right of the first sentence to make it the same length as the second one:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">padded_sequences</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span>
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a><span class="p">[[</span><span class="mi">101</span><span class="p">,</span> <span class="mi">1188</span><span class="p">,</span> <span class="mi">1110</span><span class="p">,</span> <span class="mi">170</span><span class="p">,</span> <span class="mi">1603</span><span class="p">,</span> <span class="mi">4954</span><span class="p">,</span> <span class="mi">119</span><span class="p">,</span> <span class="mi">102</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">101</span><span class="p">,</span> <span class="mi">1188</span><span class="p">,</span> <span class="mi">1110</span><span class="p">,</span> <span class="mi">170</span><span class="p">,</span> <span class="mi">1897</span><span class="p">,</span> <span class="mi">1263</span><span class="p">,</span> <span class="mi">4954</span><span class="p">,</span> <span class="mi">119</span><span class="p">,</span> <span class="mi">1135</span><span class="p">,</span> <span class="mi">1110</span><span class="p">,</span> <span class="mi">1120</span><span class="p">,</span> <span class="mi">1655</span><span class="p">,</span> <span class="mi">2039</span><span class="p">,</span> <span class="mi">1190</span><span class="p">,</span> <span class="mi">1103</span><span class="p">,</span> <span class="mi">4954</span><span class="p">,</span> <span class="mi">138</span><span class="p">,</span> <span class="mi">119</span><span class="p">,</span> <span class="mi">102</span><span class="p">]]</span>
</span></code></pre></div>
<p>This can then be converted into a tensor in PyTorch. The attention mask is a binary tensor indicating the
position of the padded indices so that the model does not attend to them. For the [<code>BertTokenizer</code>], <code>1</code> indicates a
value that should be attended to, while <code>0</code> indicates a padded value. This attention mask is in the dictionary returned
by the tokenizer under the key "attention_mask":</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">padded_sequences</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span>
</span><span id="__span-4-2"><a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a><span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
</span></code></pre></div>
<h3 id="autoencoding-models">autoencoding models</h3>
<p>See <a href="#encoder-models">encoder models</a> and <a href="#masked-language-modeling-mlm">masked language modeling</a></p>
<h3 id="autoregressive-models">autoregressive models</h3>
<p>See <a href="#causal-language-modeling">causal language modeling</a> and <a href="#decoder-models">decoder models</a></p>
<h2 id="b">B</h2>
<h3 id="backbone">backbone</h3>
<p>The backbone is the network (embeddings and layers) that outputs the raw hidden states or features. It is usually connected to a <a href="#head">head</a> which accepts the features as its input to make a prediction. For example, [<code>ViTModel</code>] is a backbone without a specific head on top. Other models can also use [<code>VitModel</code>] as a backbone such as <a href="model_doc/dpt">DPT</a>.</p>
<h2 id="c">C</h2>
<h3 id="causal-language-modeling">causal language modeling</h3>
<p>A pretraining task where the model reads the texts in order and has to predict the next word. It's usually done by
reading the whole sentence but using a mask inside the model to hide the future tokens at a certain timestep.</p>
<h3 id="channel">channel</h3>
<p>Color images are made up of some combination of values in three channels: red, green, and blue (RGB) and grayscale images only have one channel. In ðŸ¤— Transformers, the channel can be the first or last dimension of an image's tensor: [<code>n_channels</code>, <code>height</code>, <code>width</code>] or [<code>height</code>, <code>width</code>, <code>n_channels</code>].</p>
<h3 id="connectionist-temporal-classification-ctc">connectionist temporal classification (CTC)</h3>
<p>An algorithm which allows a model to learn without knowing exactly how the input and output are aligned; CTC calculates the distribution of all possible outputs for a given input and chooses the most likely output from it. CTC is commonly used in speech recognition tasks because speech doesn't always cleanly align with the transcript for a variety of reasons such as a speaker's different speech rates.</p>
<h3 id="convolution">convolution</h3>
<p>A type of layer in a neural network where the input matrix is multiplied element-wise by a smaller matrix (kernel or filter) and the values are summed up in a new matrix. This is known as a convolutional operation which is repeated over the entire input matrix. Each operation is applied to a different segment of the input matrix. Convolutional neural networks (CNNs) are commonly used in computer vision.</p>
<h2 id="d">D</h2>
<h3 id="dataparallel-dp">DataParallel (DP)</h3>
<p>Parallelism technique for training on multiple GPUs where the same setup is replicated multiple times, with each instance
receiving a distinct data slice. The processing is done in parallel and all setups are synchronized at the end of each training step.</p>
<p>Learn more about how DataParallel works <a href="perf_train_gpu_many#dataparallel-vs-distributeddataparallel">here</a>.</p>
<h3 id="decoder-input-ids">decoder input IDs</h3>
<p>This input is specific to encoder-decoder models, and contains the input IDs that will be fed to the decoder. These
inputs should be used for sequence to sequence tasks, such as translation or summarization, and are usually built in a
way specific to each model.</p>
<p>Most encoder-decoder models (BART, T5) create their <code>decoder_input_ids</code> on their own from the <code>labels</code>. In such models,
passing the <code>labels</code> is the preferred way to handle training.</p>
<p>Please check each model's docs to see how they handle these input IDs for sequence to sequence training.</p>
<h3 id="decoder-models">decoder models</h3>
<p>Also referred to as autoregressive models, decoder models involve a pretraining task (called causal language modeling) where the model reads the texts in order and has to predict the next word. It's usually done by
reading the whole sentence with a mask to hide future tokens at a certain timestep.</p>
<p><Youtube id="d_ixlCubqQw"/></p>
<h3 id="deep-learning-dl">deep learning (DL)</h3>
<p>Machine learning algorithms which use neural networks with several layers.</p>
<h2 id="e">E</h2>
<h3 id="encoder-models">encoder models</h3>
<p>Also known as autoencoding models, encoder models take an input (such as text or images) and transform them into a condensed numerical representation called an embedding. Oftentimes, encoder models are pretrained using techniques like <a href="#masked-language-modeling-mlm">masked language modeling</a>, which masks parts of the input sequence and forces the model to create more meaningful representations.</p>
<p><Youtube id="H39Z_720T5s"/></p>
<h2 id="f">F</h2>
<h3 id="feature-extraction">feature extraction</h3>
<p>The process of selecting and transforming raw data into a set of features that are more informative and useful for machine learning algorithms. Some examples of feature extraction include transforming raw text into word embeddings and extracting important features such as edges or shapes from image/video data.</p>
<h3 id="feed-forward-chunking">feed forward chunking</h3>
<p>In each residual attention block in transformers the self-attention layer is usually followed by 2 feed forward layers.
The intermediate embedding size of the feed forward layers is often bigger than the hidden size of the model (e.g., for
<code>google-bert/bert-base-uncased</code>).</p>
<p>For an input of size <code>[batch_size, sequence_length]</code>, the memory required to store the intermediate feed forward
embeddings <code>[batch_size, sequence_length, config.intermediate_size]</code> can account for a large fraction of the memory
use. The authors of <a href="https://huggingface.co/papers/2001.04451">Reformer: The Efficient Transformer</a> noticed that since the
computation is independent of the <code>sequence_length</code> dimension, it is mathematically equivalent to compute the output
embeddings of both feed forward layers <code>[batch_size, config.hidden_size]_0, ..., [batch_size, config.hidden_size]_n</code>
individually and concat them afterward to <code>[batch_size, sequence_length, config.hidden_size]</code> with <code>n = sequence_length</code>, which trades increased computation time against reduced memory use, but yields a mathematically
<strong>equivalent</strong> result.</p>
<p>For models employing the function [<code>apply_chunking_to_forward</code>], the <code>chunk_size</code> defines the number of output
embeddings that are computed in parallel and thus defines the trade-off between memory and time complexity. If
<code>chunk_size</code> is set to 0, no feed forward chunking is done.</p>
<h3 id="finetuned-models">finetuned models</h3>
<p>Finetuning is a form of transfer learning which involves taking a pretrained model, freezing its weights, and replacing the output layer with a newly added <a href="#head">model head</a>. The model head is trained on your target dataset.</p>
<p>See the <a href="https://huggingface.co/docs/transformers/training">Fine-tune a pretrained model</a> tutorial for more details, and learn how to fine-tune models with ðŸ¤— Transformers.</p>
<h2 id="h">H</h2>
<h3 id="head">head</h3>
<p>The model head refers to the last layer of a neural network that accepts the raw hidden states and projects them onto a different dimension. There is a different model head for each task. For example:</p>
<ul>
<li>[<code>GPT2ForSequenceClassification</code>] is a sequence classification head - a linear layer - on top of the base [<code>GPT2Model</code>].</li>
<li>[<code>ViTForImageClassification</code>] is an image classification head - a linear layer on top of the final hidden state of the <code>CLS</code> token - on top of the base [<code>ViTModel</code>].</li>
<li>[<code>Wav2Vec2ForCTC</code>] is a language modeling head with <a href="#connectionist-temporal-classification-ctc">CTC</a> on top of the base [<code>Wav2Vec2Model</code>].</li>
</ul>
<h2 id="i">I</h2>
<h3 id="image-patch">image patch</h3>
<p>Vision-based Transformers models split an image into smaller patches which are linearly embedded, and then passed as a sequence to the model. You can find the <code>patch_size</code> - or resolution - of the model in its configuration.</p>
<h3 id="inference">inference</h3>
<p>Inference is the process of evaluating a model on new data after training is complete. See the <a href="https://huggingface.co/docs/transformers/pipeline_tutorial">Pipeline for inference</a> tutorial to learn how to perform inference with ðŸ¤— Transformers.</p>
<h3 id="input-ids">input IDs</h3>
<p>The input ids are often the only required parameters to be passed to the model as input. They are token indices,
numerical representations of tokens building the sequences that will be used as input by the model.</p>
<p><Youtube id="VFp38yj8h3A"/></p>
<p>Each tokenizer works differently but the underlying mechanism remains the same. Here's an example using the BERT
tokenizer, which is a <a href="https://huggingface.co/papers/1609.08144">WordPiece</a> tokenizer:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">BertTokenizer</span>
</span><span id="__span-5-2"><a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a>
</span><span id="__span-5-3"><a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">BertTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;google-bert/bert-base-cased&quot;</span><span class="p">)</span>
</span><span id="__span-5-4"><a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a>
</span><span id="__span-5-5"><a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">sequence</span> <span class="o">=</span> <span class="s2">&quot;A Titan RTX has 24GB of VRAM&quot;</span>
</span></code></pre></div>
<p>The tokenizer takes care of splitting the sequence into tokens available in the tokenizer vocabulary.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">tokenized_sequence</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span>
</span></code></pre></div>
<p>The tokens are either words or subwords. Here for instance, "VRAM" wasn't in the model vocabulary, so it's been split
in "V", "RA" and "M". To indicate those tokens are not separate words but parts of the same word, a double-hash prefix
is added for "RA" and "M":</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-7-1"><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">tokenized_sequence</span><span class="p">)</span>
</span><span id="__span-7-2"><a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="s1">&#39;Titan&#39;</span><span class="p">,</span> <span class="s1">&#39;R&#39;</span><span class="p">,</span> <span class="s1">&#39;##T&#39;</span><span class="p">,</span> <span class="s1">&#39;##X&#39;</span><span class="p">,</span> <span class="s1">&#39;has&#39;</span><span class="p">,</span> <span class="s1">&#39;24&#39;</span><span class="p">,</span> <span class="s1">&#39;##GB&#39;</span><span class="p">,</span> <span class="s1">&#39;of&#39;</span><span class="p">,</span> <span class="s1">&#39;V&#39;</span><span class="p">,</span> <span class="s1">&#39;##RA&#39;</span><span class="p">,</span> <span class="s1">&#39;##M&#39;</span><span class="p">]</span>
</span></code></pre></div>
<p>These tokens can then be converted into IDs which are understandable by the model. This can be done by directly feeding the sentence to the tokenizer, which leverages the Rust implementation of <a href="https://github.com/huggingface/tokenizers">ðŸ¤— Tokenizers</a> for peak performance.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-8-1"><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span>
</span></code></pre></div>
<p>The tokenizer returns a dictionary with all the arguments necessary for its corresponding model to work properly. The
token indices are under the key <code>input_ids</code>:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-9-1"><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">encoded_sequence</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span>
</span><span id="__span-9-2"><a id="__codelineno-9-2" name="__codelineno-9-2" href="#__codelineno-9-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">encoded_sequence</span><span class="p">)</span>
</span><span id="__span-9-3"><a id="__codelineno-9-3" name="__codelineno-9-3" href="#__codelineno-9-3"></a><span class="p">[</span><span class="mi">101</span><span class="p">,</span> <span class="mi">138</span><span class="p">,</span> <span class="mi">18696</span><span class="p">,</span> <span class="mi">155</span><span class="p">,</span> <span class="mi">1942</span><span class="p">,</span> <span class="mi">3190</span><span class="p">,</span> <span class="mi">1144</span><span class="p">,</span> <span class="mi">1572</span><span class="p">,</span> <span class="mi">13745</span><span class="p">,</span> <span class="mi">1104</span><span class="p">,</span> <span class="mi">159</span><span class="p">,</span> <span class="mi">9664</span><span class="p">,</span> <span class="mi">2107</span><span class="p">,</span> <span class="mi">102</span><span class="p">]</span>
</span></code></pre></div>
<p>Note that the tokenizer automatically adds "special tokens" (if the associated model relies on them) which are special
IDs the model sometimes uses.</p>
<p>If we decode the previous sequence of ids,</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-10-1"><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">decoded_sequence</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">encoded_sequence</span><span class="p">)</span>
</span></code></pre></div>
<p>we will see</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-11-1"><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">decoded_sequence</span><span class="p">)</span>
</span><span id="__span-11-2"><a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a><span class="p">[</span><span class="n">CLS</span><span class="p">]</span> <span class="n">A</span> <span class="n">Titan</span> <span class="n">RTX</span> <span class="n">has</span> <span class="mi">24</span><span class="n">GB</span> <span class="n">of</span> <span class="n">VRAM</span> <span class="p">[</span><span class="n">SEP</span><span class="p">]</span>
</span></code></pre></div>
<p>because this is the way a [<code>BertModel</code>] is going to expect its inputs.</p>
<h2 id="l">L</h2>
<h3 id="labels">labels</h3>
<p>The labels are an optional argument which can be passed in order for the model to compute the loss itself. These labels
should be the expected prediction of the model: it will use the standard loss in order to compute the loss between its
predictions and the expected value (the label).</p>
<p>These labels are different according to the model head, for example:</p>
<ul>
<li>For sequence classification models, ([<code>BertForSequenceClassification</code>]), the model expects a tensor of dimension
  <code>(batch_size)</code> with each value of the batch corresponding to the expected label of the entire sequence.</li>
<li>For token classification models, ([<code>BertForTokenClassification</code>]), the model expects a tensor of dimension
  <code>(batch_size, seq_length)</code> with each value corresponding to the expected label of each individual token.</li>
<li>For masked language modeling, ([<code>BertForMaskedLM</code>]), the model expects a tensor of dimension <code>(batch_size,
  seq_length)</code> with each value corresponding to the expected label of each individual token: the labels being the token
  ID for the masked token, and values to be ignored for the rest (usually -100).</li>
<li>For sequence to sequence tasks, ([<code>BartForConditionalGeneration</code>], [<code>MBartForConditionalGeneration</code>]), the model
  expects a tensor of dimension <code>(batch_size, tgt_seq_length)</code> with each value corresponding to the target sequences
  associated with each input sequence. During training, both BART and T5 will make the appropriate
  <code>decoder_input_ids</code> and decoder attention masks internally. They usually do not need to be supplied. This does not
  apply to models leveraging the Encoder-Decoder framework.</li>
<li>For image classification models, ([<code>ViTForImageClassification</code>]), the model expects a tensor of dimension
  <code>(batch_size)</code> with each value of the batch corresponding to the expected label of each individual image.</li>
<li>For semantic segmentation models, ([<code>SegformerForSemanticSegmentation</code>]), the model expects a tensor of dimension
  <code>(batch_size, height, width)</code> with each value of the batch corresponding to the expected label of each individual pixel.</li>
<li>For object detection models, ([<code>DetrForObjectDetection</code>]), the model expects a list of dictionaries with a
  <code>class_labels</code> and <code>boxes</code> key where each value of the batch corresponds to the expected label and number of bounding boxes of each individual image.</li>
<li>For automatic speech recognition models, ([<code>Wav2Vec2ForCTC</code>]), the model expects a tensor of dimension <code>(batch_size,
  target_length)</code> with each value corresponding to the expected label of each individual token.</li>
</ul>
<p><Tip></p>
<p>Each model's labels may be different, so be sure to always check the documentation of each model for more information
about their specific labels!</p>
<p></Tip></p>
<p>The base models ([<code>BertModel</code>]) do not accept labels, as these are the base transformer models, simply outputting
features.</p>
<h3 id="large-language-models-llm">large language models (LLM)</h3>
<p>A generic term that refers to transformer language models (GPT-3, BLOOM, OPT) that were trained on a large quantity of data. These models also tend to have a large number of learnable parameters (e.g. 175 billion for GPT-3).</p>
<h2 id="m">M</h2>
<h3 id="masked-language-modeling-mlm">masked language modeling (MLM)</h3>
<p>A pretraining task where the model sees a corrupted version of the texts, usually done by
masking some tokens randomly, and has to predict the original text.</p>
<h3 id="multimodal">multimodal</h3>
<p>A task that combines texts with another kind of inputs (for instance images).</p>
<h2 id="n">N</h2>
<h3 id="natural-language-generation-nlg">Natural language generation (NLG)</h3>
<p>All tasks related to generating text (for instance, <a href="https://transformer.huggingface.co/">Write With Transformers</a>, translation).</p>
<h3 id="natural-language-processing-nlp">Natural language processing (NLP)</h3>
<p>A generic way to say "deal with texts".</p>
<h3 id="natural-language-understanding-nlu">Natural language understanding (NLU)</h3>
<p>All tasks related to understanding what is in a text (for instance classifying the
whole text, individual words).</p>
<h2 id="p">P</h2>
<h3 id="pipeline">pipeline</h3>
<p>A pipeline in ðŸ¤— Transformers is an abstraction referring to a series of steps that are executed in a specific order to preprocess and transform data and return a prediction from a model. Some example stages found in a pipeline might be data preprocessing, feature extraction, and normalization.</p>
<p>For more details, see <a href="https://huggingface.co/docs/transformers/pipeline_tutorial">Pipelines for inference</a>.</p>
<h3 id="pipelineparallel-pp">PipelineParallel (PP)</h3>
<p>Parallelism technique in which the model is split up vertically (layer-level) across multiple GPUs, so that only one or
several layers of the model are placed on a single GPU. Each GPU processes in parallel different stages of the pipeline
and working on a small chunk of the batch. Learn more about how PipelineParallel works <a href="perf_train_gpu_many#from-naive-model-parallelism-to-pipeline-parallelism">here</a>.</p>
<h3 id="pixel-values">pixel values</h3>
<p>A tensor of the numerical representations of an image that is passed to a model. The pixel values have a shape of [<code>batch_size</code>, <code>num_channels</code>, <code>height</code>, <code>width</code>], and are generated from an image processor.</p>
<h3 id="pooling">pooling</h3>
<p>An operation that reduces a matrix into a smaller matrix, either by taking the maximum or average of the pooled dimension(s). Pooling layers are commonly found between convolutional layers to downsample the feature representation.</p>
<h3 id="position-ids">position IDs</h3>
<p>Contrary to RNNs that have the position of each token embedded within them, transformers are unaware of the position of
each token. Therefore, the position IDs (<code>position_ids</code>) are used by the model to identify each token's position in the
list of tokens.</p>
<p>They are an optional parameter. If no <code>position_ids</code> are passed to the model, the IDs are automatically created as
absolute positional embeddings.</p>
<p>Absolute positional embeddings are selected in the range <code>[0, config.max_position_embeddings - 1]</code>. Some models use
other types of positional embeddings, such as sinusoidal position embeddings or relative position embeddings.</p>
<h3 id="preprocessing">preprocessing</h3>
<p>The task of preparing raw data into a format that can be easily consumed by machine learning models. For example, text is typically preprocessed by tokenization. To gain a better idea of what preprocessing looks like for other input types, check out the <a href="https://huggingface.co/docs/transformers/preprocessing">Preprocess</a> tutorial.</p>
<h3 id="pretrained-model">pretrained model</h3>
<p>A model that has been pretrained on some data (for instance all of Wikipedia). Pretraining methods involve a
self-supervised objective, which can be reading the text and trying to predict the next word (see <a href="#causal-language-modeling">causal language
modeling</a>) or masking some words and trying to predict them (see <a href="#masked-language-modeling-mlm">masked language
modeling</a>).</p>
<p>Speech and vision models have their own pretraining objectives. For example, Wav2Vec2 is a speech model pretrained on a contrastive task which requires the model to identify the "true" speech representation from a set of "false" speech representations. On the other hand, BEiT is a vision model pretrained on a masked image modeling task which masks some of the image patches and requires the model to predict the masked patches (similar to the masked language modeling objective).</p>
<h2 id="r">R</h2>
<h3 id="recurrent-neural-network-rnn">recurrent neural network (RNN)</h3>
<p>A type of model that uses a loop over a layer to process texts.</p>
<h3 id="representation-learning">representation learning</h3>
<p>A subfield of machine learning which focuses on learning meaningful representations of raw data. Some examples of representation learning techniques include word embeddings, autoencoders, and Generative Adversarial Networks (GANs).</p>
<h2 id="s">S</h2>
<h3 id="sampling-rate">sampling rate</h3>
<p>A measurement in hertz of the number of samples (the audio signal) taken per second. The sampling rate is a result of discretizing a continuous signal such as speech.</p>
<h3 id="self-attention">self-attention</h3>
<p>Each element of the input finds out which other elements of the input they should attend to.</p>
<h3 id="self-supervised-learning">self-supervised learning</h3>
<p>A category of machine learning techniques in which a model creates its own learning objective from unlabeled data. It differs from <a href="#unsupervised-learning">unsupervised learning</a> and <a href="#supervised-learning">supervised learning</a> in that the learning process is supervised, but not explicitly from the user.</p>
<p>One example of self-supervised learning is <a href="#masked-language-modeling-mlm">masked language modeling</a>, where a model is passed sentences with a proportion of its tokens removed and learns to predict the missing tokens.</p>
<h3 id="semi-supervised-learning">semi-supervised learning</h3>
<p>A broad category of machine learning training techniques that leverages a small amount of labeled data with a larger quantity of unlabeled data to improve the accuracy of a model, unlike <a href="#supervised-learning">supervised learning</a> and <a href="#unsupervised-learning">unsupervised learning</a>.</p>
<p>An example of a semi-supervised learning approach is "self-training", in which a model is trained on labeled data, and then used to make predictions on the unlabeled data. The portion of the unlabeled data that the model predicts with the most confidence gets added to the labeled dataset and used to retrain the model.</p>
<h3 id="sequence-to-sequence-seq2seq">sequence-to-sequence (seq2seq)</h3>
<p>Models that generate a new sequence from an input, like translation models, or summarization models (such as
<a href="model_doc/bart">Bart</a> or <a href="model_doc/t5">T5</a>).</p>
<h3 id="sharded-ddp">Sharded DDP</h3>
<p>Another name for the foundational <a href="#zero-redundancy-optimizer-zero">ZeRO</a> concept as used by various other implementations of ZeRO.</p>
<h3 id="stride">stride</h3>
<p>In <a href="#convolution">convolution</a> or <a href="#pooling">pooling</a>, the stride refers to the distance the kernel is moved over a matrix. A stride of 1 means the kernel is moved one pixel over at a time, and a stride of 2 means the kernel is moved two pixels over at a time.</p>
<h3 id="supervised-learning">supervised learning</h3>
<p>A form of model training that directly uses labeled data to correct and instruct model performance. Data is fed into the model being trained, and its predictions are compared to the known labels. The model updates its weights based on how incorrect its predictions were, and the process is repeated to optimize model performance.</p>
<h2 id="t">T</h2>
<h3 id="tensor-parallelism-tp">Tensor Parallelism (TP)</h3>
<p>Parallelism technique for training on multiple GPUs in which each tensor is split up into multiple chunks, so instead of
having the whole tensor reside on a single GPU, each shard of the tensor resides on its designated GPU. Shards gets
processed separately and in parallel on different GPUs and the results are synced at the end of the processing step.
This is what is sometimes called horizontal parallelism, as the splitting happens on horizontal level.
Learn more about Tensor Parallelism <a href="perf_train_gpu_many#tensor-parallelism">here</a>.</p>
<h3 id="token">token</h3>
<p>A part of a sentence, usually a word, but can also be a subword (non-common words are often split in subwords) or a
punctuation symbol.</p>
<h3 id="token-type-ids">token Type IDs</h3>
<p>Some models' purpose is to do classification on pairs of sentences or question answering.</p>
<p><Youtube id="0u3ioSwev3s"/></p>
<p>These require two different sequences to be joined in a single "input_ids" entry, which usually is performed with the
help of special tokens, such as the classifier (<code>[CLS]</code>) and separator (<code>[SEP]</code>) tokens. For example, the BERT model
builds its two sequence input as such:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-12-1"><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="c1"># [CLS] SEQUENCE_A [SEP] SEQUENCE_B [SEP]</span>
</span></code></pre></div>
<p>We can use our tokenizer to automatically generate such a sentence by passing the two sequences to <code>tokenizer</code> as two
arguments (and not a list, like before) like this:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-13-1"><a id="__codelineno-13-1" name="__codelineno-13-1" href="#__codelineno-13-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">BertTokenizer</span>
</span><span id="__span-13-2"><a id="__codelineno-13-2" name="__codelineno-13-2" href="#__codelineno-13-2"></a>
</span><span id="__span-13-3"><a id="__codelineno-13-3" name="__codelineno-13-3" href="#__codelineno-13-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">BertTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;google-bert/bert-base-cased&quot;</span><span class="p">)</span>
</span><span id="__span-13-4"><a id="__codelineno-13-4" name="__codelineno-13-4" href="#__codelineno-13-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">sequence_a</span> <span class="o">=</span> <span class="s2">&quot;HuggingFace is based in NYC&quot;</span>
</span><span id="__span-13-5"><a id="__codelineno-13-5" name="__codelineno-13-5" href="#__codelineno-13-5"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">sequence_b</span> <span class="o">=</span> <span class="s2">&quot;Where is HuggingFace based?&quot;</span>
</span><span id="__span-13-6"><a id="__codelineno-13-6" name="__codelineno-13-6" href="#__codelineno-13-6"></a>
</span><span id="__span-13-7"><a id="__codelineno-13-7" name="__codelineno-13-7" href="#__codelineno-13-7"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">encoded_dict</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">sequence_a</span><span class="p">,</span> <span class="n">sequence_b</span><span class="p">)</span>
</span><span id="__span-13-8"><a id="__codelineno-13-8" name="__codelineno-13-8" href="#__codelineno-13-8"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">decoded</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">encoded_dict</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">])</span>
</span></code></pre></div>
<p>which will return:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-14-1"><a id="__codelineno-14-1" name="__codelineno-14-1" href="#__codelineno-14-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">decoded</span><span class="p">)</span>
</span><span id="__span-14-2"><a id="__codelineno-14-2" name="__codelineno-14-2" href="#__codelineno-14-2"></a><span class="p">[</span><span class="n">CLS</span><span class="p">]</span> <span class="n">HuggingFace</span> <span class="ow">is</span> <span class="n">based</span> <span class="ow">in</span> <span class="n">NYC</span> <span class="p">[</span><span class="n">SEP</span><span class="p">]</span> <span class="n">Where</span> <span class="ow">is</span> <span class="n">HuggingFace</span> <span class="n">based</span><span class="err">?</span> <span class="p">[</span><span class="n">SEP</span><span class="p">]</span>
</span></code></pre></div>
<p>This is enough for some models to understand where one sequence ends and where another begins. However, other models,
such as BERT, also deploy token type IDs (also called segment IDs). They are represented as a binary mask identifying
the two types of sequence in the model.</p>
<p>The tokenizer returns this mask as the "token_type_ids" entry:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-15-1"><a id="__codelineno-15-1" name="__codelineno-15-1" href="#__codelineno-15-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">encoded_dict</span><span class="p">[</span><span class="s2">&quot;token_type_ids&quot;</span><span class="p">]</span>
</span><span id="__span-15-2"><a id="__codelineno-15-2" name="__codelineno-15-2" href="#__codelineno-15-2"></a><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
</span></code></pre></div>
<p>The first sequence, the "context" used for the question, has all its tokens represented by a <code>0</code>, whereas the second
sequence, corresponding to the "question", has all its tokens represented by a <code>1</code>.</p>
<p>Some models, like [<code>XLNetModel</code>] use an additional token represented by a <code>2</code>.</p>
<h3 id="transfer-learning">transfer learning</h3>
<p>A technique that involves taking a pretrained model and adapting it to a dataset specific to your task. Instead of training a model from scratch, you can leverage knowledge obtained from an existing model as a starting point. This speeds up the learning process and reduces the amount of training data needed.</p>
<h3 id="transformer">transformer</h3>
<p>Self-attention based deep learning model architecture.</p>
<h2 id="u">U</h2>
<h3 id="unsupervised-learning">unsupervised learning</h3>
<p>A form of model training in which data provided to the model is not labeled. Unsupervised learning techniques leverage statistical information of the data distribution to find patterns useful for the task at hand.</p>
<h2 id="z">Z</h2>
<h3 id="zero-redundancy-optimizer-zero">Zero Redundancy Optimizer (ZeRO)</h3>
<p>Parallelism technique which performs sharding of the tensors somewhat similar to <a href="#tensor-parallelism-tp">TensorParallel</a>,
except the whole tensor gets reconstructed in time for a forward or backward computation, therefore the model doesn't need
to be modified. This method also supports various offloading techniques to compensate for limited GPU memory.
Learn more about ZeRO <a href="perf_train_gpu_many#zero-data-parallelism">here</a>.</p>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../../../../../..", "features": ["navigation.tabs", "navigation.indexes", "navigation.instant", "navigation.sections", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow", "content.tabs.link", "content.code.copy"], "search": "../../../../../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../../../../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
    
  </body>
</html>