
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../../../../../../assets/favicon.ico">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.22">
    
    
      
        <title>Quicktour - Ohayou</title>
      
    
    
      <link rel="stylesheet" href="../../../../../../assets/stylesheets/main.84d31ad4.min.css">
      
        
        <link rel="stylesheet" href="../../../../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../../../../assets/extra.css">
    
    <script>__md_scope=new URL("../../../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#visite-rapide" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../../../.." title="Ohayou" class="md-header__button md-logo" aria-label="Ohayou" data-md-component="logo">
      
  <img src="../../../../../../assets/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Ohayou
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Quicktour
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../../ohayou/" class="md-tabs__link">
        
  
  
    
  
  Ohayou

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../../../vllm/open_ai_vllm_example_a_v_t/" class="md-tabs__link">
          
  
  
    
  
  vLLM

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../../../llm/speculative_decoding/" class="md-tabs__link">
          
  
  
    
  
  LLM

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../../../vlm/qwen3_vl_4B_object_detection/" class="md-tabs__link">
          
  
  
    
  
  VLM

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../../md_format_helpers/" class="md-tabs__link">
        
  
  
    
  
  MD format helpers

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../../docker/" class="md-tabs__link">
        
  
  
    
  
  Docker

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../../linux/" class="md-tabs__link">
        
  
  
    
  
  Linux

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../../moe/" class="md-tabs__link">
        
  
  
    
  
  Mixture of Experts

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../../slurm/" class="md-tabs__link">
        
  
  
    
  
  Slurm

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../../../japanese-phrases/" class="md-tabs__link">
          
  
  
    
  
  Japanese Phrases

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../../hackathon/index.md" class="md-tabs__link">
        
  
  
    
  
  Hack

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../../../.." title="Ohayou" class="md-nav__button md-logo" aria-label="Ohayou" data-md-component="logo">
      
  <img src="../../../../../../assets/logo.png" alt="logo">

    </a>
    Ohayou
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../ohayou/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Ohayou
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    vLLM
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            vLLM
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../vllm/open_ai_vllm_example_a_v_t/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Single Request
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../vllm/bash_vllm_serve/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Bash online serve
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../vllm/benchmarks/performance_eval/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Benchmarks
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    LLM
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            LLM
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../llm/speculative_decoding/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Speculative Decoding
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    VLM
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            VLM
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../vlm/qwen3_vl_4B_object_detection/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Qwen3VL
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../md_format_helpers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    MD format helpers
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../docker/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Docker
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../linux/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Linux
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../moe/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Mixture of Experts
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../slurm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Slurm
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_11" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../../../../japanese-phrases/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Japanese Phrases
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_11" id="__nav_11_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_11">
            <span class="md-nav__icon md-icon"></span>
            Japanese Phrases
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_11_2" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../../../../japanese-phrases/daily-life/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Daily Life
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_11_2" id="__nav_11_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_11_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_11_2">
            <span class="md-nav__icon md-icon"></span>
            Daily Life
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../japanese-phrases/daily-life/shopping/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Shopping
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_11_3" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../../../../japanese-phrases/greetings/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Greetings
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_11_3" id="__nav_11_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_11_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_11_3">
            <span class="md-nav__icon md-icon"></span>
            Greetings
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../japanese-phrases/greetings/casual/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Casual
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../japanese-phrases/emotions/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Emotions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../japanese-phrases/anime-manga/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Anime/Manga
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../hackathon/index.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Hack
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#pipeline" class="md-nav__link">
    <span class="md-ellipsis">
      Pipeline
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Pipeline">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#utiliser-une-autre-modele-et-tokenizer-dans-le-pipeline" class="md-nav__link">
    <span class="md-ellipsis">
      Utiliser une autre mod√®le et tokenizer dans le pipeline
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#autoclass" class="md-nav__link">
    <span class="md-ellipsis">
      AutoClass
    </span>
  </a>
  
    <nav class="md-nav" aria-label="AutoClass">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#autotokenizer" class="md-nav__link">
    <span class="md-ellipsis">
      AutoTokenizer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#automodel" class="md-nav__link">
    <span class="md-ellipsis">
      AutoModel
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sauvegarder-un-modele" class="md-nav__link">
    <span class="md-ellipsis">
      Sauvegarder un mod√®le
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#constructions-de-modeles-personnalises" class="md-nav__link">
    <span class="md-ellipsis">
      Constructions de mod√®les personnalis√©s
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#trainer-une-boucle-dentrainement-optimisee-par-pytorch" class="md-nav__link">
    <span class="md-ellipsis">
      Trainer - une boucle d'entra√Ænement optimis√©e par PyTorch
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#entrainement-avec-tensorflow" class="md-nav__link">
    <span class="md-ellipsis">
      Entra√Ænement avec TensorFlow
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#et-apres" class="md-nav__link">
    <span class="md-ellipsis">
      Et apr√®s ?
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<!--Copyright 2022 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.

‚ö†Ô∏è Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->

<h1 id="visite-rapide">Visite rapide</h1>
<p>[[open-in-colab]]</p>
<p>Soyez op√©rationnel avec ü§ó Transformers ! Que vous soyez un d√©veloppeur ou un utilisateur lambda, cette visite rapide vous aidera √† d√©marrer et vous montrera comment utiliser le [<code>pipeline</code>] pour l'inf√©rence, charger un mod√®le pr√©-entra√Æn√© et un pr√©processeur avec une <a href="./model_doc/auto">AutoClass</a>, et entra√Æner rapidement un mod√®le avec PyTorch ou TensorFlow. Si vous √™tes un d√©butant, nous vous recommandons de consulter nos tutoriels ou notre <a href="https://huggingface.co/course/chapter1/1">cours</a> suivant pour des explications plus approfondies des concepts pr√©sent√©s ici.</p>
<p>Avant de commencer, assurez-vous que vous avez install√© toutes les biblioth√®ques n√©cessaires :</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>!pip<span class="w"> </span>install<span class="w"> </span>transformers<span class="w"> </span>datasets<span class="w"> </span>evaluate<span class="w"> </span>accelerate
</span></code></pre></div>
<p>Vous aurez aussi besoin d'installer votre biblioth√®que d'apprentissage profond favorite :</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a>pip<span class="w"> </span>install<span class="w"> </span>torch
</span></code></pre></div>
<h2 id="pipeline">Pipeline</h2>
<p><Youtube id="tiZFewofSLM"/></p>
<p>Le [<code>pipeline</code>] est le moyen le plus simple d'utiliser un mod√®le pr√©-entra√Æn√© pour l'inf√©rence. Vous pouvez utiliser le [<code>pipeline</code>] pr√™t √† l'emploi pour de nombreuses t√¢ches dans diff√©rentes modalit√©s. Consultez le tableau ci-dessous pour conna√Ætre les t√¢ches prises en charge :</p>
<table>
<thead>
<tr>
<th><strong>T√¢che</strong></th>
<th><strong>Description</strong></th>
<th><strong>Modalit√©</strong></th>
<th><strong>Identifiant du pipeline</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>Classification de texte</td>
<td>Attribue une cat√©gorie √† une s√©quence de texte donn√©e</td>
<td>Texte</td>
<td>pipeline(task="sentiment-analysis")</td>
</tr>
<tr>
<td>G√©n√©ration de texte</td>
<td>G√©n√®re du texte √† partir d'une consigne donn√©e</td>
<td>Texte</td>
<td>pipeline(task="text-generation")</td>
</tr>
<tr>
<td>Reconnaissance de token nomm√©</td>
<td>Attribue une cat√©gorie √† chaque token dans une s√©quence (personnes, organisation, localisation, etc.)</td>
<td>Texte</td>
<td>pipeline(task="ner")</td>
</tr>
<tr>
<td>Question r√©ponse</td>
<td>Extrait une r√©ponse du texte en fonction du contexte et d'une question</td>
<td>Texte</td>
<td>pipeline(task="question-answering")</td>
</tr>
<tr>
<td>Pr√©diction de token masqu√©</td>
<td>Pr√©dit correctement le token masqu√© dans une s√©quence</td>
<td>Texte</td>
<td>pipeline(task="fill-mask")</td>
</tr>
<tr>
<td>G√©n√©ration de r√©sum√©</td>
<td>G√©n√®re un r√©sum√© d'une s√©quence de texte donn√©e ou d'un document</td>
<td>Texte</td>
<td>pipeline(task="summarization")</td>
</tr>
<tr>
<td>Traduction</td>
<td>Traduit du texte d'un langage √† un autre</td>
<td>Texte</td>
<td>pipeline(task="translation")</td>
</tr>
<tr>
<td>Classification d'image</td>
<td>Attribue une cat√©gorie √† une image</td>
<td>Image</td>
<td>pipeline(task="image-classification")</td>
</tr>
<tr>
<td>Segmentation d'image</td>
<td>Attribue une cat√©gorie √† chaque pixel d'une image (supporte la segmentation s√©mantique, panoptique et d'instance)</td>
<td>Image</td>
<td>pipeline(task="image-segmentation")</td>
</tr>
<tr>
<td>D√©tection d'objets</td>
<td>Pr√©dit les d√©limitations et cat√©gories d'objets dans une image</td>
<td>Image</td>
<td>pipeline(task="object-detection")</td>
</tr>
<tr>
<td>Classification d'audio</td>
<td>Attribue une cat√©gorie √† un fichier audio</td>
<td>Audio</td>
<td>pipeline(task="audio-classification")</td>
</tr>
<tr>
<td>Reconnaissance automatique de la parole</td>
<td>Extrait le discours d'un fichier audio en texte</td>
<td>Audio</td>
<td>pipeline(task="automatic-speech-recognition")</td>
</tr>
<tr>
<td>Question r√©ponse visuels</td>
<td>Etant donn√©es une image et une question, r√©pond correctement √† une question sur l'image</td>
<td>Modalit√©s multiples</td>
<td>pipeline(task="vqa")</td>
</tr>
</tbody>
</table>
<p>Commencez par cr√©er une instance de [<code>pipeline</code>] et sp√©cifiez la t√¢che pour laquelle vous souhaitez l'utiliser. Vous pouvez utiliser le [<code>pipeline</code>] pour n'importe laquelle des t√¢ches mentionn√©es dans le tableau pr√©c√©dent. Pour obtenir une liste compl√®te des t√¢ches prises en charge, consultez la documentation de l'<a href="./main_classes/pipelines">API pipeline</a>. Dans ce guide, nous utiliserons le [<code>pipeline</code>] pour l'analyse des sentiments √† titre d'exemple :</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">pipeline</span>
</span><span id="__span-2-2"><a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a>
</span><span id="__span-2-3"><a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">classifier</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s2">&quot;sentiment-analysis&quot;</span><span class="p">)</span>
</span></code></pre></div>
<p>Le [<code>pipeline</code>] t√©l√©charge et stocke en cache un <a href="https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english">mod√®le pr√©-entra√Æn√©</a> et un tokenizer par d√©faut pour l'analyse des sentiments. Vous pouvez maintenant utiliser le <code>classifier</code> sur le texte de votre choix :</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">classifier</span><span class="p">(</span><span class="s2">&quot;We are very happy to show you the ü§ó Transformers library.&quot;</span><span class="p">)</span>
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a><span class="p">[{</span><span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;POSITIVE&#39;</span><span class="p">,</span> <span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="mf">0.9998</span><span class="p">}]</span>
</span></code></pre></div>
<p>Si vous voulez classifier plus qu'un texte, donnez une liste de textes au [<code>pipeline</code>] pour obtenir une liste de dictionnaires en retour :</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">results</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">([</span><span class="s2">&quot;We are very happy to show you the ü§ó Transformers library.&quot;</span><span class="p">,</span> <span class="s2">&quot;We hope you don&#39;t hate it.&quot;</span><span class="p">])</span>
</span><span id="__span-4-2"><a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
</span><span id="__span-4-3"><a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a><span class="o">...</span>     <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;label: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">, avec le score de: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;score&#39;</span><span class="p">],</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="__span-4-4"><a id="__codelineno-4-4" name="__codelineno-4-4" href="#__codelineno-4-4"></a><span class="n">label</span><span class="p">:</span> <span class="n">POSITIVE</span><span class="p">,</span> <span class="n">avec</span> <span class="n">le</span> <span class="n">score</span> <span class="n">de</span><span class="p">:</span> <span class="mf">0.9998</span>
</span><span id="__span-4-5"><a id="__codelineno-4-5" name="__codelineno-4-5" href="#__codelineno-4-5"></a><span class="n">label</span><span class="p">:</span> <span class="n">NEGATIVE</span><span class="p">,</span> <span class="n">avec</span> <span class="n">le</span> <span class="n">score</span> <span class="n">de</span><span class="p">:</span> <span class="mf">0.5309</span>
</span></code></pre></div>
<p>Le [<code>pipeline</code>] peut aussi it√©rer sur un jeu de donn√©es entier pour n'importe quelle t√¢che. Prenons par exemple la reconnaissance automatique de la parole :</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="__span-5-2"><a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">pipeline</span>
</span><span id="__span-5-3"><a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a>
</span><span id="__span-5-4"><a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">speech_recognizer</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s2">&quot;automatic-speech-recognition&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s2">&quot;facebook/wav2vec2-base-960h&quot;</span><span class="p">)</span>
</span></code></pre></div>
<p>Chargez un jeu de donn√©es audio (voir le ü§ó Datasets <a href="https://huggingface.co/docs/datasets/quickstart#audio">Quick Start</a> pour plus de d√©tails) sur lequel vous souhaitez it√©rer. Pour cet exemple, nous chargeons le jeu de donn√©es <a href="https://huggingface.co/datasets/PolyAI/minds14">MInDS-14</a> :</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span><span class="p">,</span> <span class="n">Audio</span>
</span><span id="__span-6-2"><a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a>
</span><span id="__span-6-3"><a id="__codelineno-6-3" name="__codelineno-6-3" href="#__codelineno-6-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;PolyAI/minds14&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;en-US&quot;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>  <span class="c1"># doctest: +IGNORE_RESULT</span>
</span></code></pre></div>
<p>Vous devez vous assurer que le taux d'√©chantillonnage de l'ensemble de donn√©es correspond au taux d'√©chantillonnage sur lequel <a href="https://huggingface.co/facebook/wav2vec2-base-960h"><code>facebook/wav2vec2-base-960h</code></a> a √©t√© entra√Æn√© :</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-7-1"><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">cast_column</span><span class="p">(</span><span class="s2">&quot;audio&quot;</span><span class="p">,</span> <span class="n">Audio</span><span class="p">(</span><span class="n">sampling_rate</span><span class="o">=</span><span class="n">speech_recognizer</span><span class="o">.</span><span class="n">feature_extractor</span><span class="o">.</span><span class="n">sampling_rate</span><span class="p">))</span>
</span></code></pre></div>
<p>Les fichiers audio sont automatiquement charg√©s et r√©√©chantillonn√©s lors de l'appel de la colonne <code>"audio"</code>.
Extrayez les tableaux de formes d'ondes brutes des quatre premiers √©chantillons et passez-les comme une liste au pipeline :</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-8-1"><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">result</span> <span class="o">=</span> <span class="n">speech_recognizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[:</span><span class="mi">4</span><span class="p">][</span><span class="s2">&quot;audio&quot;</span><span class="p">])</span>
</span><span id="__span-8-2"><a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">([</span><span class="n">d</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">result</span><span class="p">])</span>
</span><span id="__span-8-3"><a id="__codelineno-8-3" name="__codelineno-8-3" href="#__codelineno-8-3"></a><span class="p">[</span><span class="s1">&#39;I WOULD LIKE TO SET UP A JOINT ACCOUNT WITH MY PARTNER HOW DO I PROCEED WITH DOING THAT&#39;</span><span class="p">,</span> <span class="s2">&quot;FODING HOW I&#39;D SET UP A JOIN TO HET WITH MY WIFE AND WHERE THE AP MIGHT BE&quot;</span><span class="p">,</span> <span class="s2">&quot;I I&#39;D LIKE TOY SET UP A JOINT ACCOUNT WITH MY PARTNER I&#39;M NOT SEEING THE OPTION TO DO IT ON THE AP SO I CALLED IN TO GET SOME HELP CAN I JUST DO IT OVER THE PHONE WITH YOU AND GIVE YOU THE INFORMATION OR SHOULD I DO IT IN THE AP AND I&#39;M MISSING SOMETHING UQUETTE HAD PREFERRED TO JUST DO IT OVER THE PHONE OF POSSIBLE THINGS&quot;</span><span class="p">,</span> <span class="s1">&#39;HOW DO I THURN A JOIN A COUNT&#39;</span><span class="p">]</span>
</span></code></pre></div>
<p>Pour les ensembles de donn√©es plus importants o√π les entr√©es sont volumineuses (comme dans les domaines de la parole ou de la vision), utilisez plut√¥t un g√©n√©rateur au lieu d'une liste pour charger toutes les entr√©es en m√©moire. Pour plus d'informations, consultez la documentation de l'<a href="./main_classes/pipelines">API pipeline</a>.</p>
<h3 id="utiliser-une-autre-modele-et-tokenizer-dans-le-pipeline">Utiliser une autre mod√®le et tokenizer dans le pipeline</h3>
<p>Le [<code>pipeline</code>] peut √™tre utilis√© avec n'importe quel mod√®le du <a href="https://huggingface.co/models">Hub</a>, ce qui permet d'adapter facilement le [<code>pipeline</code>] √† d'autres cas d'utilisation. Par exemple, si vous souhaitez un mod√®le capable de traiter du texte fran√ßais, utilisez les filtres du Hub pour trouver un mod√®le appropri√©. Le premier r√©sultat renvoie un <a href="https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment">mod√®le BERT</a> multilingue finetun√© pour l'analyse des sentiments que vous pouvez utiliser pour le texte fran√ßais :</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-9-1"><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
</span></code></pre></div>
<p>Utilisez [<code>AutoModelForSequenceClassification</code>] et [<code>AutoTokenizer</code>] pour charger le mod√®le pr√©-entra√Æn√© et le tokenizer adapt√© (plus de d√©tails sur une <code>AutoClass</code> dans la section suivante) :</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-10-1"><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>
</span><span id="__span-10-2"><a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a>
</span><span id="__span-10-3"><a id="__codelineno-10-3" name="__codelineno-10-3" href="#__codelineno-10-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
</span><span id="__span-10-4"><a id="__codelineno-10-4" name="__codelineno-10-4" href="#__codelineno-10-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
</span></code></pre></div>
<p>Sp√©cifiez le mod√®le et le tokenizer dans le [<code>pipeline</code>], et utilisez le <code>classifier</code> sur le texte en fran√ßais :</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-11-1"><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">classifier</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s2">&quot;sentiment-analysis&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">)</span>
</span><span id="__span-11-2"><a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">classifier</span><span class="p">(</span><span class="s2">&quot;Nous sommes tr√®s heureux de vous pr√©senter la biblioth√®que ü§ó Transformers.&quot;</span><span class="p">)</span>
</span><span id="__span-11-3"><a id="__codelineno-11-3" name="__codelineno-11-3" href="#__codelineno-11-3"></a><span class="p">[{</span><span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;5 stars&#39;</span><span class="p">,</span> <span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="mf">0.7273</span><span class="p">}]</span>
</span></code></pre></div>
<p>Si vous ne parvenez pas √† trouver un mod√®le adapt√© √† votre cas d'utilisation, vous devrez finetuner un mod√®le pr√©-entra√Æn√© sur vos donn√©es. Jetez un coup d'≈ìil √† notre <a href="./training">tutoriel sur le finetuning</a> pour apprendre comment faire. Enfin, apr√®s avoir finetun√© votre mod√®le pr√©-entra√Æn√©, pensez √† <a href="./model_sharing">partager</a> le mod√®le avec la communaut√© sur le Hub afin de d√©mocratiser l'apprentissage automatique pour tous ! ü§ó</p>
<h2 id="autoclass">AutoClass</h2>
<p><Youtube id="AhChOFRegn4"/></p>
<p>Les classes [<code>AutoModelForSequenceClassification</code>] et [<code>AutoTokenizer</code>] fonctionnent ensemble pour cr√©er un [<code>pipeline</code>] comme celui que vous avez utilis√© ci-dessus. Une <a href="./model_doc/auto">AutoClass</a> est un raccourci qui r√©cup√®re automatiquement l'architecture d'un mod√®le pr√©-entra√Æn√© √† partir de son nom ou de son emplacement. Il vous suffit de s√©lectionner l'<code>AutoClass</code> appropri√©e √† votre t√¢che et la classe de pr√©traitement qui lui est associ√©e.</p>
<p>Reprenons l'exemple de la section pr√©c√©dente et voyons comment vous pouvez utiliser l'<code>AutoClass</code> pour reproduire les r√©sultats du [<code>pipeline</code>].</p>
<h3 id="autotokenizer">AutoTokenizer</h3>
<p>Un tokenizer est charg√© de pr√©traiter le texte pour en faire un tableau de chiffres qui servira d'entr√©e √† un mod√®le. De nombreuses r√®gles r√©gissent le processus de tokenisation, notamment la mani√®re de diviser un mot et le niveau auquel les mots doivent √™tre divis√©s (pour en savoir plus sur la tokenisation, consultez le <a href="./tokenizer_summary">r√©sum√©</a>). La chose la plus importante √† retenir est que vous devez instancier un tokenizer avec le m√™me nom de mod√®le pour vous assurer que vous utilisez les m√™mes r√®gles de tokenisation que celles avec lesquelles un mod√®le a √©t√© pr√©-entra√Æn√©.</p>
<p>Chargez un tokenizer avec [<code>AutoTokenizer</code>] :</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-12-1"><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span>
</span><span id="__span-12-2"><a id="__codelineno-12-2" name="__codelineno-12-2" href="#__codelineno-12-2"></a>
</span><span id="__span-12-3"><a id="__codelineno-12-3" name="__codelineno-12-3" href="#__codelineno-12-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
</span><span id="__span-12-4"><a id="__codelineno-12-4" name="__codelineno-12-4" href="#__codelineno-12-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
</span></code></pre></div>
<p>Passez votre texte au tokenizer :</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-13-1"><a id="__codelineno-13-1" name="__codelineno-13-1" href="#__codelineno-13-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">encoding</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;We are very happy to show you the ü§ó Transformers library.&quot;</span><span class="p">)</span>
</span><span id="__span-13-2"><a id="__codelineno-13-2" name="__codelineno-13-2" href="#__codelineno-13-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">encoding</span><span class="p">)</span>
</span><span id="__span-13-3"><a id="__codelineno-13-3" name="__codelineno-13-3" href="#__codelineno-13-3"></a><span class="p">{</span><span class="s1">&#39;input_ids&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">101</span><span class="p">,</span> <span class="mi">11312</span><span class="p">,</span> <span class="mi">10320</span><span class="p">,</span> <span class="mi">12495</span><span class="p">,</span> <span class="mi">19308</span><span class="p">,</span> <span class="mi">10114</span><span class="p">,</span> <span class="mi">11391</span><span class="p">,</span> <span class="mi">10855</span><span class="p">,</span> <span class="mi">10103</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">58263</span><span class="p">,</span> <span class="mi">13299</span><span class="p">,</span> <span class="mi">119</span><span class="p">,</span> <span class="mi">102</span><span class="p">],</span>
</span><span id="__span-13-4"><a id="__codelineno-13-4" name="__codelineno-13-4" href="#__codelineno-13-4"></a> <span class="s1">&#39;token_type_ids&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
</span><span id="__span-13-5"><a id="__codelineno-13-5" name="__codelineno-13-5" href="#__codelineno-13-5"></a> <span class="s1">&#39;attention_mask&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]}</span>
</span></code></pre></div>
<p>Le tokenizer retourne un dictionnaire contenant :</p>
<ul>
<li><a href="./glossary#input-ids">input_ids</a>: la repr√©sentation num√©rique des tokens.</li>
<li><a href=".glossary#attention-mask">attention_mask</a>: indique quels tokens doivent faire l'objet d'une attention particuli√®re (plus particuli√®rement les tokens de remplissage).</li>
</ul>
<p>Un tokenizer peut √©galement accepter une liste de textes, et remplir et tronquer le texte pour retourner un √©chantillon de longueur uniforme :</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-14-1"><a id="__codelineno-14-1" name="__codelineno-14-1" href="#__codelineno-14-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">pt_batch</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
</span><span id="__span-14-2"><a id="__codelineno-14-2" name="__codelineno-14-2" href="#__codelineno-14-2"></a><span class="o">...</span>     <span class="p">[</span><span class="s2">&quot;We are very happy to show you the ü§ó Transformers library.&quot;</span><span class="p">,</span> <span class="s2">&quot;We hope you don&#39;t hate it.&quot;</span><span class="p">],</span>
</span><span id="__span-14-3"><a id="__codelineno-14-3" name="__codelineno-14-3" href="#__codelineno-14-3"></a><span class="o">...</span>     <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="__span-14-4"><a id="__codelineno-14-4" name="__codelineno-14-4" href="#__codelineno-14-4"></a><span class="o">...</span>     <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="__span-14-5"><a id="__codelineno-14-5" name="__codelineno-14-5" href="#__codelineno-14-5"></a><span class="o">...</span>     <span class="n">max_length</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
</span><span id="__span-14-6"><a id="__codelineno-14-6" name="__codelineno-14-6" href="#__codelineno-14-6"></a><span class="o">...</span>     <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span>
</span><span id="__span-14-7"><a id="__codelineno-14-7" name="__codelineno-14-7" href="#__codelineno-14-7"></a><span class="o">...</span> <span class="p">)</span>
</span></code></pre></div>
<p><Tip></p>
<p>Consultez le tutoriel <a href="./preprocessing">pr√©traitement</a> pour plus de d√©tails sur la tokenisation, et sur la mani√®re d'utiliser un [<code>AutoImageProcessor</code>], un [<code>AutoFeatureExtractor</code>] et un [<code>AutoProcessor</code>] pour pr√©traiter les images, l'audio et les contenus multimodaux.</p>
<p></Tip></p>
<h3 id="automodel">AutoModel</h3>
<p>ü§ó Transformers fournit un moyen simple et unifi√© de charger des instances pr√©-entra√Æn√©es. Cela signifie que vous pouvez charger un [<code>AutoModel</code>] comme vous chargeriez un [<code>AutoTokenizer</code>]. La seule diff√©rence est de s√©lectionner l'[<code>AutoModel</code>] appropri√© pour la t√¢che. Pour une classification de texte (ou de s√©quence de textes), vous devez charger [<code>AutoModelForSequenceClassification</code>] :</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-15-1"><a id="__codelineno-15-1" name="__codelineno-15-1" href="#__codelineno-15-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span>
</span><span id="__span-15-2"><a id="__codelineno-15-2" name="__codelineno-15-2" href="#__codelineno-15-2"></a>
</span><span id="__span-15-3"><a id="__codelineno-15-3" name="__codelineno-15-3" href="#__codelineno-15-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
</span><span id="__span-15-4"><a id="__codelineno-15-4" name="__codelineno-15-4" href="#__codelineno-15-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">pt_model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
</span></code></pre></div>
<p><Tip></p>
<p>Voir le <a href="./task_summary">r√©sum√© de la t√¢che</a> pour v√©rifier si elle est prise en charge par une classe [<code>AutoModel</code>].</p>
<p></Tip></p>
<p>Maintenant, passez votre √©chantillon d'entr√©es pr√©trait√©es directement au mod√®le. Il vous suffit de d√©compresser le dictionnaire en ajoutant <code>**</code> :</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-16-1"><a id="__codelineno-16-1" name="__codelineno-16-1" href="#__codelineno-16-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">pt_outputs</span> <span class="o">=</span> <span class="n">pt_model</span><span class="p">(</span><span class="o">**</span><span class="n">pt_batch</span><span class="p">)</span>
</span></code></pre></div>
<p>Le mod√®le produit les activations finales dans l'attribut <code>logits</code>. Appliquez la fonction softmax aux <code>logits</code> pour r√©cup√©rer les probabilit√©s :</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-17-1"><a id="__codelineno-17-1" name="__codelineno-17-1" href="#__codelineno-17-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span>
</span><span id="__span-17-2"><a id="__codelineno-17-2" name="__codelineno-17-2" href="#__codelineno-17-2"></a>
</span><span id="__span-17-3"><a id="__codelineno-17-3" name="__codelineno-17-3" href="#__codelineno-17-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">pt_predictions</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">pt_outputs</span><span class="o">.</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-17-4"><a id="__codelineno-17-4" name="__codelineno-17-4" href="#__codelineno-17-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">pt_predictions</span><span class="p">)</span>
</span><span id="__span-17-5"><a id="__codelineno-17-5" name="__codelineno-17-5" href="#__codelineno-17-5"></a><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.0021</span><span class="p">,</span> <span class="mf">0.0018</span><span class="p">,</span> <span class="mf">0.0115</span><span class="p">,</span> <span class="mf">0.2121</span><span class="p">,</span> <span class="mf">0.7725</span><span class="p">],</span>
</span><span id="__span-17-6"><a id="__codelineno-17-6" name="__codelineno-17-6" href="#__codelineno-17-6"></a>        <span class="p">[</span><span class="mf">0.2084</span><span class="p">,</span> <span class="mf">0.1826</span><span class="p">,</span> <span class="mf">0.1969</span><span class="p">,</span> <span class="mf">0.1755</span><span class="p">,</span> <span class="mf">0.2365</span><span class="p">]],</span> <span class="n">grad_fn</span><span class="o">=&lt;</span><span class="n">SoftmaxBackward0</span><span class="o">&gt;</span><span class="p">)</span>
</span></code></pre></div>
<p><Tip></p>
<p>Tous les mod√®les ü§ó Transformers (PyTorch ou TensorFlow) produisent les tensors <em>avant</em> la fonction d'activation finale (comme softmax) car la fonction d'activation finale est souvent fusionn√©e avec le calcul de la perte. Les structures produites par le mod√®le sont des classes de donn√©es sp√©ciales, de sorte que leurs attributs sont autocompl√©t√©s dans un environnement de d√©veloppement. Les structures produites par le mod√®le se comportent comme un tuple ou un dictionnaire (vous pouvez les indexer avec un entier, une tranche ou une cha√Æne), auquel cas les attributs qui sont None sont ignor√©s.</p>
<p></Tip></p>
<h3 id="sauvegarder-un-modele">Sauvegarder un mod√®le</h3>
<p>Une fois que votre mod√®le est finetun√©, vous pouvez le sauvegarder avec son tokenizer en utilisant [<code>PreTrainedModel.save_pretrained</code>] :</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-18-1"><a id="__codelineno-18-1" name="__codelineno-18-1" href="#__codelineno-18-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">pt_save_directory</span> <span class="o">=</span> <span class="s2">&quot;./pt_save_pretrained&quot;</span>
</span><span id="__span-18-2"><a id="__codelineno-18-2" name="__codelineno-18-2" href="#__codelineno-18-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">pt_save_directory</span><span class="p">)</span>  <span class="c1"># doctest: +IGNORE_RESULT</span>
</span><span id="__span-18-3"><a id="__codelineno-18-3" name="__codelineno-18-3" href="#__codelineno-18-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">pt_model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">pt_save_directory</span><span class="p">)</span>
</span></code></pre></div>
<p>Lorsque vous voulez r√©utiliser le mod√®le, rechargez-le avec [<code>PreTrainedModel.from_pretrained</code>] :</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-19-1"><a id="__codelineno-19-1" name="__codelineno-19-1" href="#__codelineno-19-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">pt_model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;./pt_save_pretrained&quot;</span><span class="p">)</span>
</span></code></pre></div>
<p>Une fonctionnalit√© particuli√®rement cool ü§ó Transformers est la possibilit√© d'enregistrer un mod√®le et de le recharger en tant que mod√®le PyTorch ou TensorFlow. Le param√®tre <code>from_pt</code> ou <code>from_tf</code> permet de convertir le mod√®le d'un framework √† l'autre :</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-20-1"><a id="__codelineno-20-1" name="__codelineno-20-1" href="#__codelineno-20-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModel</span>
</span><span id="__span-20-2"><a id="__codelineno-20-2" name="__codelineno-20-2" href="#__codelineno-20-2"></a>
</span><span id="__span-20-3"><a id="__codelineno-20-3" name="__codelineno-20-3" href="#__codelineno-20-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">pt_save_directory</span><span class="p">)</span>
</span><span id="__span-20-4"><a id="__codelineno-20-4" name="__codelineno-20-4" href="#__codelineno-20-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">pt_model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">pt_save_directory</span><span class="p">,</span> <span class="n">from_pt</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></code></pre></div>
<h2 id="constructions-de-modeles-personnalises">Constructions de mod√®les personnalis√©s</h2>
<p>Vous pouvez modifier la configuration du mod√®le pour changer la fa√ßon dont un mod√®le est construit. La configuration sp√©cifie les attributs d'un mod√®le, tels que le nombre de couches ou de t√™tes d'attention. Vous partez de z√©ro lorsque vous initialisez un mod√®le √† partir d'une configuration personnalis√©e. Les attributs du mod√®le sont initialis√©s de mani√®re al√©atoire et vous devrez entra√Æner le mod√®le avant de pouvoir l'utiliser pour obtenir des r√©sultats significatifs.</p>
<p>Commencez par importer [<code>AutoConfig</code>], puis chargez le mod√®le pr√©-entra√Æn√© que vous voulez modifier. Dans [<code>AutoConfig.from_pretrained</code>], vous pouvez sp√©cifier l'attribut que vous souhaitez modifier, tel que le nombre de t√™tes d'attention :</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-21-1"><a id="__codelineno-21-1" name="__codelineno-21-1" href="#__codelineno-21-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoConfig</span>
</span><span id="__span-21-2"><a id="__codelineno-21-2" name="__codelineno-21-2" href="#__codelineno-21-2"></a>
</span><span id="__span-21-3"><a id="__codelineno-21-3" name="__codelineno-21-3" href="#__codelineno-21-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">my_config</span> <span class="o">=</span> <span class="n">AutoConfig</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;distilbert/distilbert-base-uncased&quot;</span><span class="p">,</span> <span class="n">n_heads</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
</span></code></pre></div>
<p>Cr√©ez un mod√®le personnalis√© √† partir de votre configuration avec [<code>AutoModel.from_config</code>] :</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-22-1"><a id="__codelineno-22-1" name="__codelineno-22-1" href="#__codelineno-22-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModel</span>
</span><span id="__span-22-2"><a id="__codelineno-22-2" name="__codelineno-22-2" href="#__codelineno-22-2"></a>
</span><span id="__span-22-3"><a id="__codelineno-22-3" name="__codelineno-22-3" href="#__codelineno-22-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">my_model</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">my_config</span><span class="p">)</span>
</span></code></pre></div>
<p>Consultez le guide <a href="./create_a_model">Cr√©er une architecture personnalis√©e</a> pour plus d'informations sur la cr√©ation de configurations personnalis√©es.</p>
<h2 id="trainer-une-boucle-dentrainement-optimisee-par-pytorch">Trainer - une boucle d'entra√Ænement optimis√©e par PyTorch</h2>
<p>Tous les mod√®les sont des <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module"><code>torch.nn.Module</code></a> standard, vous pouvez donc les utiliser dans n'importe quelle boucle d'entra√Ænement typique. Bien que vous puissiez √©crire votre propre boucle d'entra√Ænement, ü§ó Transformers fournit une classe [<code>Trainer</code>] pour PyTorch, qui contient la boucle d'entra√Ænement de base et ajoute des fonctionnalit√©s suppl√©mentaires comme l'entra√Ænement distribu√©, la pr√©cision mixte, et plus encore.</p>
<p>En fonction de votre t√¢che, vous passerez g√©n√©ralement les param√®tres suivants √† [<code>Trainer</code>] :</p>
<ol>
<li>Un [<code>PreTrainedModel</code>] ou un <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module"><code>torch.nn.Module</code></a>:</li>
</ol>
<div class="language-py highlight"><pre><span></span><code><span id="__span-23-1"><a id="__codelineno-23-1" name="__codelineno-23-1" href="#__codelineno-23-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span>
</span><span id="__span-23-2"><a id="__codelineno-23-2" name="__codelineno-23-2" href="#__codelineno-23-2"></a>
</span><span id="__span-23-3"><a id="__codelineno-23-3" name="__codelineno-23-3" href="#__codelineno-23-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;distilbert/distilbert-base-uncased&quot;</span><span class="p">)</span>
</span></code></pre></div>
<ol>
<li>[<code>TrainingArguments</code>] contient les hyperparam√®tres du mod√®le que vous pouvez changer comme le taux d'apprentissage, la taille de l'√©chantillon, et le nombre d'√©poques pour s'entra√Æner. Les valeurs par d√©faut sont utilis√©es si vous ne sp√©cifiez pas d'hyperparam√®tres d'apprentissage :</li>
</ol>
<div class="language-py highlight"><pre><span></span><code><span id="__span-24-1"><a id="__codelineno-24-1" name="__codelineno-24-1" href="#__codelineno-24-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">TrainingArguments</span>
</span><span id="__span-24-2"><a id="__codelineno-24-2" name="__codelineno-24-2" href="#__codelineno-24-2"></a>
</span><span id="__span-24-3"><a id="__codelineno-24-3" name="__codelineno-24-3" href="#__codelineno-24-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
</span><span id="__span-24-4"><a id="__codelineno-24-4" name="__codelineno-24-4" href="#__codelineno-24-4"></a><span class="o">...</span>     <span class="n">output_dir</span><span class="o">=</span><span class="s2">&quot;path/to/save/folder/&quot;</span><span class="p">,</span>
</span><span id="__span-24-5"><a id="__codelineno-24-5" name="__codelineno-24-5" href="#__codelineno-24-5"></a><span class="o">...</span>     <span class="n">learning_rate</span><span class="o">=</span><span class="mf">2e-5</span><span class="p">,</span>
</span><span id="__span-24-6"><a id="__codelineno-24-6" name="__codelineno-24-6" href="#__codelineno-24-6"></a><span class="o">...</span>     <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
</span><span id="__span-24-7"><a id="__codelineno-24-7" name="__codelineno-24-7" href="#__codelineno-24-7"></a><span class="o">...</span>     <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
</span><span id="__span-24-8"><a id="__codelineno-24-8" name="__codelineno-24-8" href="#__codelineno-24-8"></a><span class="o">...</span>     <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
</span><span id="__span-24-9"><a id="__codelineno-24-9" name="__codelineno-24-9" href="#__codelineno-24-9"></a><span class="o">...</span> <span class="p">)</span>
</span></code></pre></div>
<ol>
<li>Une classe de pr√©traitement comme un tokenizer, un processeur d'images ou un extracteur de caract√©ristiques :</li>
</ol>
<div class="language-py highlight"><pre><span></span><code><span id="__span-25-1"><a id="__codelineno-25-1" name="__codelineno-25-1" href="#__codelineno-25-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span>
</span><span id="__span-25-2"><a id="__codelineno-25-2" name="__codelineno-25-2" href="#__codelineno-25-2"></a>
</span><span id="__span-25-3"><a id="__codelineno-25-3" name="__codelineno-25-3" href="#__codelineno-25-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;distilbert/distilbert-base-uncased&quot;</span><span class="p">)</span>
</span></code></pre></div>
<ol>
<li>Chargez un jeu de donn√©es :</li>
</ol>
<div class="language-py highlight"><pre><span></span><code><span id="__span-26-1"><a id="__codelineno-26-1" name="__codelineno-26-1" href="#__codelineno-26-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
</span><span id="__span-26-2"><a id="__codelineno-26-2" name="__codelineno-26-2" href="#__codelineno-26-2"></a>
</span><span id="__span-26-3"><a id="__codelineno-26-3" name="__codelineno-26-3" href="#__codelineno-26-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;rotten_tomatoes&quot;</span><span class="p">)</span>  <span class="c1"># doctest: +IGNORE_RESULT</span>
</span></code></pre></div>
<ol>
<li>Cr√©ez une fonction qui transforme le texte du jeu de donn√©es en token :</li>
</ol>
<div class="language-py highlight"><pre><span></span><code><span id="__span-27-1"><a id="__codelineno-27-1" name="__codelineno-27-1" href="#__codelineno-27-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="k">def</span><span class="w"> </span><span class="nf">tokenize_dataset</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
</span><span id="__span-27-2"><a id="__codelineno-27-2" name="__codelineno-27-2" href="#__codelineno-27-2"></a><span class="o">...</span>     <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">])</span>
</span></code></pre></div>
<p>Puis appliquez-la √† l'int√©gralit√© du jeu de donn√©es avec [<code>~datasets.Dataset.map</code>]:</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-28-1"><a id="__codelineno-28-1" name="__codelineno-28-1" href="#__codelineno-28-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_dataset</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></code></pre></div>
<ol>
<li>Un [<code>DataCollatorWithPadding</code>] pour cr√©er un √©chantillon d'exemples √† partir de votre jeu de donn√©es :</li>
</ol>
<div class="language-py highlight"><pre><span></span><code><span id="__span-29-1"><a id="__codelineno-29-1" name="__codelineno-29-1" href="#__codelineno-29-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataCollatorWithPadding</span>
</span><span id="__span-29-2"><a id="__codelineno-29-2" name="__codelineno-29-2" href="#__codelineno-29-2"></a>
</span><span id="__span-29-3"><a id="__codelineno-29-3" name="__codelineno-29-3" href="#__codelineno-29-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">data_collator</span> <span class="o">=</span> <span class="n">DataCollatorWithPadding</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">)</span>
</span></code></pre></div>
<p>Maintenant, rassemblez tous ces √©l√©ments dans un [<code>Trainer</code>] :</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-30-1"><a id="__codelineno-30-1" name="__codelineno-30-1" href="#__codelineno-30-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Trainer</span>
</span><span id="__span-30-2"><a id="__codelineno-30-2" name="__codelineno-30-2" href="#__codelineno-30-2"></a>
</span><span id="__span-30-3"><a id="__codelineno-30-3" name="__codelineno-30-3" href="#__codelineno-30-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
</span><span id="__span-30-4"><a id="__codelineno-30-4" name="__codelineno-30-4" href="#__codelineno-30-4"></a><span class="o">...</span>     <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
</span><span id="__span-30-5"><a id="__codelineno-30-5" name="__codelineno-30-5" href="#__codelineno-30-5"></a><span class="o">...</span>     <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
</span><span id="__span-30-6"><a id="__codelineno-30-6" name="__codelineno-30-6" href="#__codelineno-30-6"></a><span class="o">...</span>     <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span>
</span><span id="__span-30-7"><a id="__codelineno-30-7" name="__codelineno-30-7" href="#__codelineno-30-7"></a><span class="o">...</span>     <span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span>
</span><span id="__span-30-8"><a id="__codelineno-30-8" name="__codelineno-30-8" href="#__codelineno-30-8"></a><span class="o">...</span>     <span class="n">processing_class</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
</span><span id="__span-30-9"><a id="__codelineno-30-9" name="__codelineno-30-9" href="#__codelineno-30-9"></a><span class="o">...</span>     <span class="n">data_collator</span><span class="o">=</span><span class="n">data_collator</span><span class="p">,</span>
</span><span id="__span-30-10"><a id="__codelineno-30-10" name="__codelineno-30-10" href="#__codelineno-30-10"></a><span class="o">...</span> <span class="p">)</span>  <span class="c1"># doctest: +SKIP</span>
</span></code></pre></div>
<p>Une fois que vous √™tes pr√™t, appelez la fonction [<code>~Trainer.train</code>] pour commencer l'entra√Ænement :</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-31-1"><a id="__codelineno-31-1" name="__codelineno-31-1" href="#__codelineno-31-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>  <span class="c1"># doctest: +SKIP</span>
</span></code></pre></div>
<p><Tip></p>
<p>Pour les t√¢ches - comme la traduction ou la g√©n√©ration de r√©sum√© - qui utilisent un mod√®le s√©quence √† s√©quence, utilisez plut√¥t les classes [<code>Seq2SeqTrainer</code>] et [<code>Seq2SeqTrainingArguments</code>].</p>
<p></Tip></p>
<p>Vous pouvez personnaliser le comportement de la boucle d'apprentissage en red√©finissant les m√©thodes √† l'int√©rieur de [<code>Trainer</code>]. Cela vous permet de personnaliser des caract√©ristiques telles que la fonction de perte, l'optimiseur et le planificateur. Consultez la documentation de [<code>Trainer</code>] pour savoir quelles m√©thodes peuvent √™tre red√©finies.</p>
<p>L'autre moyen de personnaliser la boucle d'apprentissage est d'utiliser les <a href="./main_classes/callback">Callbacks</a>. Vous pouvez utiliser les callbacks pour int√©grer d'autres biblioth√®ques et inspecter la boucle d'apprentissage afin de suivre la progression ou d'arr√™ter l'apprentissage plus t√¥t. Les callbacks ne modifient rien dans la boucle d'apprentissage elle-m√™me. Pour personnaliser quelque chose comme la fonction de perte, vous devez red√©finir le [<code>Trainer</code>] √† la place.</p>
<h2 id="entrainement-avec-tensorflow">Entra√Ænement avec TensorFlow</h2>
<p>Tous les mod√®les sont des mod√®les standard <a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model"><code>tf.keras.Model</code></a> afin qu'ils puissent √™tre entra√Æn√©s avec TensorFlow avec l'API <a href="https://keras.io/">Keras</a>. ü§ó Transformers fournit la fonction [<code>~TFPreTrainedModel.prepare_tf_dataset</code>] pour charger facilement votre jeu de donn√©es comme un <code>tf.data.Dataset</code> afin que vous puissiez commencer l'entra√Ænement imm√©diatement avec les fonctions <a href="https://keras.io/api/models/model_training_apis/#compile-method"><code>compile</code></a> et <a href="https://keras.io/api/models/model_training_apis/#fit-method"><code>fit</code></a> de Keras.</p>
<ol>
<li>Vous commencez avec un mod√®le [<code>TFPreTrainedModel</code>] ou <a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model"><code>tf.keras.Model</code></a> :</li>
</ol>
<div class="language-py highlight"><pre><span></span><code><span id="__span-32-1"><a id="__codelineno-32-1" name="__codelineno-32-1" href="#__codelineno-32-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">TFAutoModelForSequenceClassification</span>
</span><span id="__span-32-2"><a id="__codelineno-32-2" name="__codelineno-32-2" href="#__codelineno-32-2"></a>
</span><span id="__span-32-3"><a id="__codelineno-32-3" name="__codelineno-32-3" href="#__codelineno-32-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">model</span> <span class="o">=</span> <span class="n">TFAutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;distilbert/distilbert-base-uncased&quot;</span><span class="p">)</span>
</span></code></pre></div>
<ol>
<li>Une classe de pr√©traitement comme un tokenizer, un processeur d'images ou un extracteur de caract√©ristiques :</li>
</ol>
<div class="language-py highlight"><pre><span></span><code><span id="__span-33-1"><a id="__codelineno-33-1" name="__codelineno-33-1" href="#__codelineno-33-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span>
</span><span id="__span-33-2"><a id="__codelineno-33-2" name="__codelineno-33-2" href="#__codelineno-33-2"></a>
</span><span id="__span-33-3"><a id="__codelineno-33-3" name="__codelineno-33-3" href="#__codelineno-33-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;distilbert/distilbert-base-uncased&quot;</span><span class="p">)</span>
</span></code></pre></div>
<ol>
<li>Cr√©ez une fonction qui transforme le texte du jeu de donn√©es en token :</li>
</ol>
<div class="language-py highlight"><pre><span></span><code><span id="__span-34-1"><a id="__codelineno-34-1" name="__codelineno-34-1" href="#__codelineno-34-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="k">def</span><span class="w"> </span><span class="nf">tokenize_dataset</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
</span><span id="__span-34-2"><a id="__codelineno-34-2" name="__codelineno-34-2" href="#__codelineno-34-2"></a><span class="o">...</span>     <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">])</span>  <span class="c1"># doctest: +SKIP</span>
</span></code></pre></div>
<ol>
<li>Appliquez le tokenizer √† l'ensemble du jeu de donn√©es avec [<code>~datasets.Dataset.map</code>] et passez ensuite le jeu de donn√©es et le tokenizer √† [<code>~TFPreTrainedModel.prepare_tf_dataset</code>]. Vous pouvez √©galement modifier la taille de l'√©chantillon et m√©langer le jeu de donn√©es ici si vous le souhaitez :</li>
</ol>
<div class="language-py highlight"><pre><span></span><code><span id="__span-35-1"><a id="__codelineno-35-1" name="__codelineno-35-1" href="#__codelineno-35-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_dataset</span><span class="p">)</span>  <span class="c1"># doctest: +SKIP</span>
</span><span id="__span-35-2"><a id="__codelineno-35-2" name="__codelineno-35-2" href="#__codelineno-35-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">tf_dataset</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">prepare_tf_dataset</span><span class="p">(</span>
</span><span id="__span-35-3"><a id="__codelineno-35-3" name="__codelineno-35-3" href="#__codelineno-35-3"></a><span class="o">...</span>     <span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span>
</span><span id="__span-35-4"><a id="__codelineno-35-4" name="__codelineno-35-4" href="#__codelineno-35-4"></a><span class="o">...</span> <span class="p">)</span>  <span class="c1"># doctest: +SKIP</span>
</span></code></pre></div>
<ol>
<li>Une fois que vous √™tes pr√™t, appelez les fonctions <code>compile</code> et <code>fit</code> pour commencer l'entra√Ænement :</li>
</ol>
<div class="language-py highlight"><pre><span></span><code><span id="__span-36-1"><a id="__codelineno-36-1" name="__codelineno-36-1" href="#__codelineno-36-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.optimizers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>
</span><span id="__span-36-2"><a id="__codelineno-36-2" name="__codelineno-36-2" href="#__codelineno-36-2"></a>
</span><span id="__span-36-3"><a id="__codelineno-36-3" name="__codelineno-36-3" href="#__codelineno-36-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">Adam</span><span class="p">(</span><span class="mf">3e-5</span><span class="p">))</span>
</span><span id="__span-36-4"><a id="__codelineno-36-4" name="__codelineno-36-4" href="#__codelineno-36-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>  <span class="c1"># doctest: +SKIP</span>
</span></code></pre></div>
<h2 id="et-apres">Et apr√®s ?</h2>
<p>Maintenant que vous avez termin√© la visite rapide de ü§ó Transformers, consultez nos guides et apprenez √† faire des choses plus sp√©cifiques comme cr√©er un mod√®le personnalis√©, finetuner un mod√®le pour une t√¢che, et comment entra√Æner un mod√®le avec un script. Si vous souhaitez en savoir plus sur les concepts fondamentaux de ü§ó Transformers, jetez un ≈ìil √† nos guides conceptuels !</p>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../../../../../..", "features": ["navigation.tabs", "navigation.indexes", "navigation.instant", "navigation.sections", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow", "content.tabs.link", "content.code.copy"], "search": "../../../../../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../../../../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
    
  </body>
</html>