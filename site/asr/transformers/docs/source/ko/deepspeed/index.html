
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../../../../../../assets/favicon.ico">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.22">
    
    
      
        <title>Deepspeed - Ohayou</title>
      
    
    
      <link rel="stylesheet" href="../../../../../../assets/stylesheets/main.84d31ad4.min.css">
      
        
        <link rel="stylesheet" href="../../../../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../../../../assets/extra.css">
    
    <script>__md_scope=new URL("../../../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#deepspeeddeepspeed" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../../../.." title="Ohayou" class="md-header__button md-logo" aria-label="Ohayou" data-md-component="logo">
      
  <img src="../../../../../../assets/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Ohayou
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Deepspeed
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../../ohayou/" class="md-tabs__link">
        
  
  
    
  
  Ohayou

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../../../vllm/open_ai_vllm_example_a_v_t/" class="md-tabs__link">
          
  
  
    
  
  vLLM

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../../../llm/speculative_decoding/" class="md-tabs__link">
          
  
  
    
  
  LLM

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../../../vlm/qwen3_vl_4B_object_detection/" class="md-tabs__link">
          
  
  
    
  
  VLM

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../../md_format_helpers/" class="md-tabs__link">
        
  
  
    
  
  MD format helpers

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../../docker/" class="md-tabs__link">
        
  
  
    
  
  Docker

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../../linux/" class="md-tabs__link">
        
  
  
    
  
  Linux

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../../moe/" class="md-tabs__link">
        
  
  
    
  
  Mixture of Experts

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../../slurm/" class="md-tabs__link">
        
  
  
    
  
  Slurm

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../../../japanese-phrases/" class="md-tabs__link">
          
  
  
    
  
  Japanese Phrases

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../../hackathon/index.md" class="md-tabs__link">
        
  
  
    
  
  Hack

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../../../.." title="Ohayou" class="md-nav__button md-logo" aria-label="Ohayou" data-md-component="logo">
      
  <img src="../../../../../../assets/logo.png" alt="logo">

    </a>
    Ohayou
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../ohayou/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Ohayou
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    vLLM
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            vLLM
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../vllm/open_ai_vllm_example_a_v_t/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Single Request
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../vllm/bash_vllm_serve/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Bash online serve
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../vllm/benchmarks/performance_eval/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Benchmarks
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    LLM
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            LLM
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../llm/speculative_decoding/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Speculative Decoding
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    VLM
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            VLM
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../vlm/qwen3_vl_4B_object_detection/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Qwen3VL
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../md_format_helpers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    MD format helpers
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../docker/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Docker
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../linux/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Linux
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../moe/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Mixture of Experts
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../slurm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Slurm
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_11" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../../../../japanese-phrases/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Japanese Phrases
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_11" id="__nav_11_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_11">
            <span class="md-nav__icon md-icon"></span>
            Japanese Phrases
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_11_2" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../../../../japanese-phrases/daily-life/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Daily Life
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_11_2" id="__nav_11_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_11_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_11_2">
            <span class="md-nav__icon md-icon"></span>
            Daily Life
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../japanese-phrases/daily-life/shopping/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Shopping
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_11_3" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../../../../japanese-phrases/greetings/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Greetings
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_11_3" id="__nav_11_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_11_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_11_3">
            <span class="md-nav__icon md-icon"></span>
            Greetings
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../japanese-phrases/greetings/casual/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Casual
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../japanese-phrases/emotions/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Emotions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../japanese-phrases/anime-manga/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Anime/Manga
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../hackathon/index.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Hack
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#installation" class="md-nav__link">
    <span class="md-ellipsis">
      설치[[installation]]
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#memory-requirements" class="md-nav__link">
    <span class="md-ellipsis">
      메모리 요구량[[memory-requirements]]
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#zero-select-a-zero-stage" class="md-nav__link">
    <span class="md-ellipsis">
      ZeRO 단계 설정하기[[select-a-zero-stage]]
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#deepspeed-deepspeed-configuration-file" class="md-nav__link">
    <span class="md-ellipsis">
      DeepSpeed 구성 파일[[deepspeed-configuration-file]]
    </span>
  </a>
  
    <nav class="md-nav" aria-label="DeepSpeed 구성 파일[[deepspeed-configuration-file]]">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#deepspeed-trainer-deepspeed-and-trainer-parameters" class="md-nav__link">
    <span class="md-ellipsis">
      DeepSpeed와 Trainer 매개변수[[deepspeed-and-trainer-parameters]]
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zero-zero-configuration" class="md-nav__link">
    <span class="md-ellipsis">
      ZeRO 구성[[zero-configuration]]
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nvme-nvme-configuration" class="md-nav__link">
    <span class="md-ellipsis">
      NVMe 설정[[nvme-configuration]]
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#deepspeed-deepspeed-features" class="md-nav__link">
    <span class="md-ellipsis">
      DeepSpeed 구성[[deepspeed-features]]
    </span>
  </a>
  
    <nav class="md-nav" aria-label="DeepSpeed 구성[[deepspeed-features]]">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#activationgradient-checkpointing" class="md-nav__link">
    <span class="md-ellipsis">
      활성화/그레이디언트 체크포인팅[[activationgradient-checkpointing]]
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#optimizer-and-scheduler" class="md-nav__link">
    <span class="md-ellipsis">
      옵티마이저와 스케줄러[[optimizer-and-scheduler]]
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#precision" class="md-nav__link">
    <span class="md-ellipsis">
      정밀도[[precision]]
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#batch-size" class="md-nav__link">
    <span class="md-ellipsis">
      배치 크기[[batch-size]]
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gradient-accumulation" class="md-nav__link">
    <span class="md-ellipsis">
      그레이디언트 누적[[gradient-accumulation]]
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gradient-clipping" class="md-nav__link">
    <span class="md-ellipsis">
      그레이디언트 클리핑[[gradient-clipping]]
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#communication-data-typecommunication-data-type" class="md-nav__link">
    <span class="md-ellipsis">
      통신 데이터 유형(Communication data type)[[communication-data-type]]
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#deployment" class="md-nav__link">
    <span class="md-ellipsis">
      모델 배포[[deployment]]
    </span>
  </a>
  
    <nav class="md-nav" aria-label="모델 배포[[deployment]]">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#multi-node-deployment" class="md-nav__link">
    <span class="md-ellipsis">
      다중 노드 환경에서의 모델 배포[[multi-node-deployment]]
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slurmslurm" class="md-nav__link">
    <span class="md-ellipsis">
      SLURM[[slurm]]
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#notebook" class="md-nav__link">
    <span class="md-ellipsis">
      노트북[[notebook]]
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#save-model-weights" class="md-nav__link">
    <span class="md-ellipsis">
      모델 가중치 저장하기[[save-model-weights]]
    </span>
  </a>
  
    <nav class="md-nav" aria-label="모델 가중치 저장하기[[save-model-weights]]">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#online" class="md-nav__link">
    <span class="md-ellipsis">
      온라인 환경[[online]]
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#offline" class="md-nav__link">
    <span class="md-ellipsis">
      오프라인 환경[[offline]]
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#zero-inferencezero-inference" class="md-nav__link">
    <span class="md-ellipsis">
      ZeRO Inference[[zero-inference]]
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#trainer-deepspeed-non-trainer-deepspeed-integration" class="md-nav__link">
    <span class="md-ellipsis">
      Trainer 없이 DeepSpeed 사용하기[[non-trainer-deepspeed-integration]]
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Trainer 없이 DeepSpeed 사용하기[[non-trainer-deepspeed-integration]]">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#trainer-zero-inference-non-trainer-zero-inference" class="md-nav__link">
    <span class="md-ellipsis">
      Trainer 없이 ZeRO Inference 사용하기[[non-trainer-zero-inference]]
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#generate" class="md-nav__link">
    <span class="md-ellipsis">
      생성[[generate]]
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#troubleshoot" class="md-nav__link">
    <span class="md-ellipsis">
      트러블슈팅[[troubleshoot]]
    </span>
  </a>
  
    <nav class="md-nav" aria-label="트러블슈팅[[troubleshoot]]">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#deepspeed-deepspeed-process-killed-at-startup" class="md-nav__link">
    <span class="md-ellipsis">
      DeepSpeed 프로세스가 시작 단계에서 종료되었을 경우[[deepspeed-process-killed-at-startup]]
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nan-nan-loss" class="md-nav__link">
    <span class="md-ellipsis">
      NaN 손실[[nan-loss]]
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#resources" class="md-nav__link">
    <span class="md-ellipsis">
      리소스[[resources]]
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<!--Copyright 2024 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.

⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->

<h1 id="deepspeeddeepspeed">DeepSpeed[[deepspeed]]</h1>
<p><a href="https://www.deepspeed.ai/">DeepSpeed</a>는 분산 학습 메모리를 효율적이고 빠르게 만드는 PyTorch 최적화 라이브러리입니다. 그 핵심은 대규모 모델을 규모에 맞게 훈련할 수 있는 <a href="https://hf.co/papers/1910.02054">Zero Redundancy Optimizer(ZeRO)</a>입니다. ZeRO는 여러 단계로 작동합니다:</p>
<ul>
<li>ZeRO-1, GPU 간 최적화 상태 분할</li>
<li>ZeRO-2, GPU 간 그레이디언트 분할</li>
<li>ZeRO-3, GPU 간 매개변수 분할</li>
</ul>
<p>GPU가 제한된 환경에서 ZeRO는 최적화 메모리와 계산을 GPU에서 CPU로 오프로드하여 단일 GPU에 대규모 모델을 장착하고 훈련할 수 있습니다. DeepSpeed는 모든 ZeRO 단계 및 오프로딩을 위해 Transformers [<code>Trainer</code>] 클래스와 통합되어 있습니다. 구성 파일을 제공하거나 제공된 템플릿을 사용하기만 하면 됩니다. 추론의 경우, Transformers는 대용량 모델을 가져올 수 있으므로 ZeRO-3 및 오프로딩을 지원합니다.</p>
<p>이 가이드에서는 DeepSpeed 트레이닝을 배포하는 방법, 활성화할 수 있는 기능, 다양한 ZeRO 단계에 대한 구성 파일 설정 방법, 오프로딩, 추론 및 [<code>Trainer</code>] 없이 DeepSpeed를 사용하는 방법을 안내해 드립니다.</p>
<h2 id="installation">설치[[installation]]</h2>
<p>DeepSpeed는 PyPI 또는 Transformers에서 설치할 수 있습니다(자세한 설치 옵션은 DeepSpeed <a href="https://www.deepspeed.ai/tutorials/advanced-install/">설치 상세사항</a> 또는 GitHub <a href="https://github.com/deepspeedai/DeepSpeed#installation">README</a>를 참조하세요).</p>
<p><Tip></p>
<p>DeepSpeed를 설치하는 데 문제가 있는 경우 <a href="../debugging#deepspeed-cuda-installation">DeepSpeed CUDA 설치</a> 가이드를 확인하세요. DeepSpeed에는 pip 설치 가능한 PyPI 패키지로 설치할 수 있지만, 하드웨어에 가장 잘 맞고 PyPI 배포판에서는 제공되지 않는 1비트 Adam과 같은 특정 기능을 지원하려면 <a href="https://www.deepspeed.ai/tutorials/advanced-install/#install-deepspeed-from-source">소스에서 설치하기</a>를 적극 권장합니다.</p>
<p></Tip></p>
<p><hfoptions id="install">
<hfoption id="PyPI"></p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>pip<span class="w"> </span>install<span class="w"> </span>deepspeed
</span></code></pre></div>
<p></hfoption>
<hfoption id="Transformers"></p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a>pip<span class="w"> </span>install<span class="w"> </span>transformers<span class="o">[</span>deepspeed<span class="o">]</span>
</span></code></pre></div>
<p></hfoption>
</hfoptions></p>
<h2 id="memory-requirements">메모리 요구량[[memory-requirements]]</h2>
<p>시작하기 전에 모델에 맞는 충분한 GPU 및 CPU 메모리가 있는지 확인하는 것이 좋습니다. DeepSpeed는 필요한 CPU/GPU 메모리를 추정할 수 있는 도구를 제공합니다. 예를 들어, 단일 GPU에서 <a href="bigscience/T0_3B">bigscience/T0_3B</a> 모델의 메모리 요구 사항을 추정할 수 있습니다:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a>$<span class="w"> </span>python<span class="w"> </span>-c<span class="w"> </span><span class="s1">&#39;from transformers import AutoModel; \</span>
</span><span id="__span-2-2"><a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a><span class="s1">from deepspeed.runtime.zero.stage3 import estimate_zero3_model_states_mem_needs_all_live; \</span>
</span><span id="__span-2-3"><a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a><span class="s1">model = AutoModel.from_pretrained(&quot;bigscience/T0_3B&quot;); \</span>
</span><span id="__span-2-4"><a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a><span class="s1">estimate_zero3_model_states_mem_needs_all_live(model, num_gpus_per_node=1, num_nodes=1)&#39;</span>
</span><span id="__span-2-5"><a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a><span class="o">[</span>...<span class="o">]</span>
</span><span id="__span-2-6"><a id="__codelineno-2-6" name="__codelineno-2-6" href="#__codelineno-2-6"></a>Estimated<span class="w"> </span>memory<span class="w"> </span>needed<span class="w"> </span><span class="k">for</span><span class="w"> </span>params,<span class="w"> </span>optim<span class="w"> </span>states<span class="w"> </span>and<span class="w"> </span>gradients<span class="w"> </span><span class="k">for</span><span class="w"> </span>a:
</span><span id="__span-2-7"><a id="__codelineno-2-7" name="__codelineno-2-7" href="#__codelineno-2-7"></a>HW:<span class="w"> </span>Setup<span class="w"> </span>with<span class="w"> </span><span class="m">1</span><span class="w"> </span>node,<span class="w"> </span><span class="m">1</span><span class="w"> </span>GPU<span class="w"> </span>per<span class="w"> </span>node.
</span><span id="__span-2-8"><a id="__codelineno-2-8" name="__codelineno-2-8" href="#__codelineno-2-8"></a>SW:<span class="w"> </span>Model<span class="w"> </span>with<span class="w"> </span>2783M<span class="w"> </span>total<span class="w"> </span>params,<span class="w"> </span>65M<span class="w"> </span>largest<span class="w"> </span>layer<span class="w"> </span>params.
</span><span id="__span-2-9"><a id="__codelineno-2-9" name="__codelineno-2-9" href="#__codelineno-2-9"></a><span class="w">  </span>per<span class="w"> </span>CPU<span class="w">  </span><span class="p">|</span><span class="w">  </span>per<span class="w"> </span>GPU<span class="w"> </span><span class="p">|</span><span class="w">   </span>Options
</span><span id="__span-2-10"><a id="__codelineno-2-10" name="__codelineno-2-10" href="#__codelineno-2-10"></a><span class="w">   </span><span class="m">70</span>.00GB<span class="w"> </span><span class="p">|</span><span class="w">   </span><span class="m">0</span>.25GB<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="nv">offload_param</span><span class="o">=</span>cpu<span class="w"> </span>,<span class="w"> </span><span class="nv">offload_optimizer</span><span class="o">=</span>cpu<span class="w"> </span>,<span class="w"> </span><span class="nv">zero_init</span><span class="o">=</span><span class="m">1</span>
</span><span id="__span-2-11"><a id="__codelineno-2-11" name="__codelineno-2-11" href="#__codelineno-2-11"></a><span class="w">   </span><span class="m">70</span>.00GB<span class="w"> </span><span class="p">|</span><span class="w">   </span><span class="m">0</span>.25GB<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="nv">offload_param</span><span class="o">=</span>cpu<span class="w"> </span>,<span class="w"> </span><span class="nv">offload_optimizer</span><span class="o">=</span>cpu<span class="w"> </span>,<span class="w"> </span><span class="nv">zero_init</span><span class="o">=</span><span class="m">0</span>
</span><span id="__span-2-12"><a id="__codelineno-2-12" name="__codelineno-2-12" href="#__codelineno-2-12"></a><span class="w">   </span><span class="m">62</span>.23GB<span class="w"> </span><span class="p">|</span><span class="w">   </span><span class="m">5</span>.43GB<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="nv">offload_param</span><span class="o">=</span>none,<span class="w"> </span><span class="nv">offload_optimizer</span><span class="o">=</span>cpu<span class="w"> </span>,<span class="w"> </span><span class="nv">zero_init</span><span class="o">=</span><span class="m">1</span>
</span><span id="__span-2-13"><a id="__codelineno-2-13" name="__codelineno-2-13" href="#__codelineno-2-13"></a><span class="w">   </span><span class="m">62</span>.23GB<span class="w"> </span><span class="p">|</span><span class="w">   </span><span class="m">5</span>.43GB<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="nv">offload_param</span><span class="o">=</span>none,<span class="w"> </span><span class="nv">offload_optimizer</span><span class="o">=</span>cpu<span class="w"> </span>,<span class="w"> </span><span class="nv">zero_init</span><span class="o">=</span><span class="m">0</span>
</span><span id="__span-2-14"><a id="__codelineno-2-14" name="__codelineno-2-14" href="#__codelineno-2-14"></a><span class="w">    </span><span class="m">0</span>.37GB<span class="w"> </span><span class="p">|</span><span class="w">  </span><span class="m">46</span>.91GB<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="nv">offload_param</span><span class="o">=</span>none,<span class="w"> </span><span class="nv">offload_optimizer</span><span class="o">=</span>none,<span class="w"> </span><span class="nv">zero_init</span><span class="o">=</span><span class="m">1</span>
</span><span id="__span-2-15"><a id="__codelineno-2-15" name="__codelineno-2-15" href="#__codelineno-2-15"></a><span class="w">   </span><span class="m">15</span>.56GB<span class="w"> </span><span class="p">|</span><span class="w">  </span><span class="m">46</span>.91GB<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="nv">offload_param</span><span class="o">=</span>none,<span class="w"> </span><span class="nv">offload_optimizer</span><span class="o">=</span>none,<span class="w"> </span><span class="nv">zero_init</span><span class="o">=</span><span class="m">0</span>
</span></code></pre></div>
<p>즉, CPU 오프로드가 없는 단일 80GB GPU 또는 오프로드 할 8GB GPU와 최대 60GB CPU가 필요합니다 (이는 매개변수, 최적화 상태 및 그레이디언트에 대한 메모리 요구 사항일 뿐이며 CUDA 커널 및 활성화에는 조금 더 필요합니다). 또한 더 작은 GPU를 대여하거나 구입하는 것이 더 저렴하지만 모델을 훈련하는 데 시간이 더 오래 걸리므로 비용과 속도 간의 균형을 고려해야 합니다.</p>
<p>GPU 메모리가 충분하다면 CPU/NVMe 오프로드를 비활성화하여 모든 작업을 더 빠르게 처리하세요.</p>
<h2 id="zero-select-a-zero-stage">ZeRO 단계 설정하기[[select-a-zero-stage]]</h2>
<p>DeepSpeed를 설치하고 메모리 요구 사항을 더 잘 파악했다면 다음 단계는 사용할 ZeRO 스테이지를 선택하는 것입니다. 가장 빠르고 메모리 효율이 높은 순서대로 정렬하면 다음과 같습니다:</p>
<table>
<thead>
<tr>
<th>속도</th>
<th>메모리 효율</th>
</tr>
</thead>
<tbody>
<tr>
<td>ZeRO-1</td>
<td>ZeRO-3 + offload</td>
</tr>
<tr>
<td>ZeRO-2</td>
<td>ZeRO-3</td>
</tr>
<tr>
<td>ZeRO-2 + offload</td>
<td>ZeRO-2 + offload</td>
</tr>
<tr>
<td>ZeRO-3</td>
<td>ZeRO-2</td>
</tr>
<tr>
<td>ZeRO-3 + offload</td>
<td>ZeRO-1</td>
</tr>
</tbody>
</table>
<p>자신에게 가장 적합한 방법을 찾으려면 가장 빠른 방법부터 시작하고 메모리가 부족하면 더 느리지만 메모리 효율이 높은 다음 단계를 시도하세요. 속도와 메모리 사용량 사이의 적절한 균형을 찾기 위해 (가장 메모리 효율적이거나 가장 빠른 것부터 시작하여) 원하는 방향으로 자유롭게 작업하세요.</p>
<p>일반적으로 사용할 수 있는 프로세스는 다음과 같습니다(배치 크기 1로 시작):</p>
<ol>
<li>그레이디언트 체크포인팅 활성화</li>
<li>ZeRO-2 시도</li>
<li>ZeRO-2와 매개변수 오프로드 시도</li>
<li>ZeRO-3 시도</li>
<li>ZeRO-3과 매개변수 CPU 오프로드 시도</li>
<li>ZeRO-3, 매개변수와 옵티마이저 CPU 오프로드 시도</li>
<li>[<code>~GenerationMixin.generate</code>] 메소드를 사용하는 경우 더 좁은 빔 서치 검색 범위와 같은 다양한 기본값을 낮춰보기</li>
<li>전체 정밀도 가중치보다 반정밀도(구형 GPU 구조의 경우 fp16, 암페어 이후 GPU의 경우 bf16)를 혼합해보기</li>
<li>가능하면 하드웨어를 더 추가하거나 Infinity가 매개변수와 옵티마이저를 NVMe로 오프로드하도록 활성화</li>
<li>메모리가 부족하지 않으면 유효 처리량을 측정한 다음 배치 크기를 최대한 크게 늘려 GPU 효율성을 극대화</li>
<li>마지막으로 일부 오프로드 기능을 비활성화하거나 더 빠른 ZeRO 스테이지를 사용하고 배치 크기를 늘리거나 줄여 속도와 메모리 사용량 간의 최적의 균형을 찾아 트레이닝 설정을 최적화</li>
</ol>
<h2 id="deepspeed-deepspeed-configuration-file">DeepSpeed 구성 파일[[deepspeed-configuration-file]]</h2>
<p>DeepSpeed는 트레이닝 실행 방법을 구성하는 모든 매개변수가 포함된 구성 파일을 통해 [<code>Trainer</code>] 클래스와 함께 작동합니다. 트레이닝 스크립트를 실행하면 DeepSpeed는 [<code>Trainer</code>]로부터 받은 구성을 콘솔에 기록하므로 어떤 구성이 사용되었는지 정확히 확인할 수 있습니다.</p>
<p><Tip></p>
<p>DeepSpeed 구성 옵션의 전체 목록은 <a href="https://www.deepspeed.ai/docs/config-json/">DeepSpeed Configuration JSON</a>에서 확인할 수 있습니다. 또한 <a href="https://github.com/deepspeedai/DeepSpeedExamples">DeepSpeedExamples</a> 리포지토리 또는 기본 <a href="https://github.com/deepspeedai/DeepSpeed">DeepSpeed</a> 리포지토리에서 다양한 DeepSpeed 구성 예제에 대한 보다 실용적인 예제를 찾을 수 있습니다. 구체적인 예제를 빠르게 찾으려면 다음과 같이 하세요:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/deepspeedai/DeepSpeedExamples
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a><span class="nb">cd</span><span class="w"> </span>DeepSpeedExamples
</span><span id="__span-3-3"><a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a>find<span class="w"> </span>.<span class="w"> </span>-name<span class="w"> </span><span class="s1">&#39;*json&#39;</span>
</span><span id="__span-3-4"><a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a><span class="c1"># Lamb 옵티마이저 샘플 찾기</span>
</span><span id="__span-3-5"><a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a>grep<span class="w"> </span>-i<span class="w"> </span>Lamb<span class="w"> </span><span class="k">$(</span>find<span class="w"> </span>.<span class="w"> </span>-name<span class="w"> </span><span class="s1">&#39;*json&#39;</span><span class="k">)</span>
</span></code></pre></div>
<p></Tip></p>
<p>명령줄 인터페이스에서 트레이닝하는 경우 DeepSpeed 구성 파일은 JSON 파일의 경로로 전달되거나 노트북 설정에서 [<code>Trainer</code>]를 사용하는 경우 중첩된 <code>dict</code> 객체로 전달됩니다.</p>
<p><hfoptions id="pass-config">
<hfoption id="path to file"></p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a><span class="n">TrainingArguments</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">deepspeed</span><span class="o">=</span><span class="s2">&quot;path/to/deepspeed_config.json&quot;</span><span class="p">)</span>
</span></code></pre></div>
<p></hfoption>
<hfoption id="nested dict"></p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a><span class="n">ds_config_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">scheduler</span><span class="o">=</span><span class="n">scheduler_params</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer_params</span><span class="p">)</span>
</span><span id="__span-5-2"><a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a><span class="n">args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">deepspeed</span><span class="o">=</span><span class="n">ds_config_dict</span><span class="p">)</span>
</span><span id="__span-5-3"><a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
</span></code></pre></div>
<p></hfoption>
</hfoptions></p>
<h3 id="deepspeed-trainer-deepspeed-and-trainer-parameters">DeepSpeed와 Trainer 매개변수[[deepspeed-and-trainer-parameters]]</h3>
<p>구성 매개변수에는 세 가지 유형이 있습니다:</p>
<ol>
<li>
<p>일부 구성 매개변수는 [<code>Trainer</code>]와 DeepSpeed가 공유하며, 정의가 충돌하는 경우 오류를 식별하기 어려울 수 있습니다. 이러한 공유 구성 매개변수는 [<code>Trainer</code>] 명령줄 인수에서 쉽게 설정할 수 있습니다.</p>
</li>
<li>
<p>모델 설정에서 자동으로 도출되는 일부 설정 매개변수는 수동으로 값을 조정할 필요가 없습니다. [<code>Trainer</code>]는 구성 값 <code>auto</code>를 사용하여 가장 정확하거나 효율적인 값을 설정합니다. 직접 구성 매개변수를 명시적으로 설정할 수도 있지만, [<code>Trainer</code>] 인수와 DeepSpeed 설정 매개변수가 일치하도록 주의해야 합니다. 일치하지 않으면 감지하기 매우 어려운 방식으로 훈련이 실패할 수 있습니다!</p>
</li>
<li>
<p>교육 요구 사항에 따라 수동으로 설정해야 하는 일부 설정 매개변수는 DeepSpeed에만 해당됩니다.</p>
</li>
</ol>
<p>DeepSpeed 구성을 수정하고 [<code>TrainingArguments</code>]를 편집할 수도 있습니다:</p>
<ol>
<li>기본 구성으로 사용할 DeepSpeed 구성 파일을 생성하거나 로드합니다.</li>
<li>다음 DeepSpeed 구성을 기반으로 [<code>TrainingArguments</code>] 객체를 생성합니다.</li>
</ol>
<p><code>scheduler.params.total_num_steps</code>와 같은 일부 값은 트레이닝 중 [<code>Trainer</code>]에 의해 계산됩니다.</p>
<h3 id="zero-zero-configuration">ZeRO 구성[[zero-configuration]]</h3>
<p>세 가지 구성이 있으며, 각 구성은 서로 다른 ZeRO 단계에 해당합니다. 1단계는 확장성 측면에서 그다지 눈여겨볼만하지 않으므로 이 가이드에서는 2단계와 3단계에 중점을 둡니다. <code>zero_optimization</code> 구성에는 활성화할 항목과 구성 방법에 대한 모든 옵션이 포함되어 있습니다. 각 매개변수에 대한 자세한 설명은 <a href="https://www.deepspeed.ai/docs/config-json/">DeepSpeed 구성 JSON</a> 참조를 참조하세요.</p>
<p><Tip warning={true}>
DeepSpeed는 매개변수 이름의 유효성을 검사하지 않으며 오타가 있으면 매개변수의 기본 설정으로 대체합니다. DeepSpeed 엔진 시작 로그 메시지를 보고 어떤 값을 사용할지 확인할 수 있습니다.</p>
<p></Tip></p>
<p>[<code>Trainer</code>]는 동등한 명령줄 인수를 제공하지 않으므로 다음 구성은 DeepSpeed로 설정해야 합니다.</p>
<p><hfoptions id="zero-config">
<hfoption id="ZeRO-1"></p>
<p>ZeRO-1은 옵티마이저 상태를 GPU에 분할하여 약간의 속도 향상을 기대할 수 있습니다. ZeRO-1 구성은 다음과 같이 설정할 수 있습니다:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a><span class="o">{</span>
</span><span id="__span-6-2"><a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a><span class="w">    </span><span class="s2">&quot;zero_optimization&quot;</span>:<span class="w"> </span><span class="o">{</span>
</span><span id="__span-6-3"><a id="__codelineno-6-3" name="__codelineno-6-3" href="#__codelineno-6-3"></a><span class="w">        </span><span class="s2">&quot;stage&quot;</span>:<span class="w"> </span><span class="m">1</span>
</span><span id="__span-6-4"><a id="__codelineno-6-4" name="__codelineno-6-4" href="#__codelineno-6-4"></a><span class="w">    </span><span class="o">}</span>
</span><span id="__span-6-5"><a id="__codelineno-6-5" name="__codelineno-6-5" href="#__codelineno-6-5"></a><span class="o">}</span>
</span></code></pre></div>
<p></hfoption>
<hfoption id="ZeRO-2"></p>
<p>ZeRO-2는 GPU에서 옵티마이저와 그레이디언트를 분할합니다. 이 단계는 추론과 관련이 없는 기능이기 때문에 주로 훈련에 사용됩니다. 더 나은 성능을 위해 구성해야 할 몇 가지 중요한 매개변수는 다음과 같습니다:</p>
<ul>
<li>GPU 메모리 사용량을 줄이려면 <code>offload_optimizer</code>를 활성화해야 합니다.</li>
<li><code>true</code>로 설정된 경우 <code>overlap_comm</code>은 GPU 메모리 사용량 증가를 상쇄하여 지연 시간을 줄입니다. 이 기능은 4.5배의 <code>allgather_bucket_size</code> 및 <code>reduce_bucket_size</code>값을 사용합니다. 이 예에서는 <code>5e8</code>로 설정되어 있으므로 9GB의 GPU 메모리가 필요합니다. GPU 메모리가 8GB 이하인 경우, 메모리 요구량을 낮추고 메모리 부족(OOM) 오류를 방지하기 위해 <code>overlap_comm</code>을 줄여야 합니다.</li>
<li><code>allgather_bucket_size</code>와 <code>reduce_bucket_size</code>는 사용 가능한 GPU 메모리와 통신 속도를 절충합니다. 값이 작을수록 통신 속도가 느려지고 더 많은 GPU 메모리를 사용할 수 있습니다. 예를 들어, 배치 크기가 큰 것이 약간 느린 훈련 시간보다 더 중요한지 균형을 맞출 수 있습니다.</li>
<li>DeepSpeed 0.4.4에서는 CPU 오프로딩을 위해 <code>round_robin_gradients</code>를 사용할 수 있습니다. 이 기능은 세분화된 그레이디언트 파티셔닝을 통해 등급 간 그레이디언트 복사를 CPU 메모리로 병렬화합니다. 성능 이점은 그레이디언트 누적 단계(최적화 단계 간 복사 횟수 증가) 또는 GPU 수(병렬 처리 증가)에 따라 증가합니다.</li>
</ul>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-7-1"><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a><span class="o">{</span>
</span><span id="__span-7-2"><a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a><span class="w">    </span><span class="s2">&quot;zero_optimization&quot;</span>:<span class="w"> </span><span class="o">{</span>
</span><span id="__span-7-3"><a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a><span class="w">        </span><span class="s2">&quot;stage&quot;</span>:<span class="w"> </span><span class="m">2</span>,
</span><span id="__span-7-4"><a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a><span class="w">        </span><span class="s2">&quot;offload_optimizer&quot;</span>:<span class="w"> </span><span class="o">{</span>
</span><span id="__span-7-5"><a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a><span class="w">            </span><span class="s2">&quot;device&quot;</span>:<span class="w"> </span><span class="s2">&quot;cpu&quot;</span>,
</span><span id="__span-7-6"><a id="__codelineno-7-6" name="__codelineno-7-6" href="#__codelineno-7-6"></a><span class="w">            </span><span class="s2">&quot;pin_memory&quot;</span>:<span class="w"> </span><span class="nb">true</span>
</span><span id="__span-7-7"><a id="__codelineno-7-7" name="__codelineno-7-7" href="#__codelineno-7-7"></a><span class="w">        </span><span class="o">}</span>,
</span><span id="__span-7-8"><a id="__codelineno-7-8" name="__codelineno-7-8" href="#__codelineno-7-8"></a><span class="w">        </span><span class="s2">&quot;allgather_partitions&quot;</span>:<span class="w"> </span>true,
</span><span id="__span-7-9"><a id="__codelineno-7-9" name="__codelineno-7-9" href="#__codelineno-7-9"></a><span class="w">        </span><span class="s2">&quot;allgather_bucket_size&quot;</span>:<span class="w"> </span>5e8,
</span><span id="__span-7-10"><a id="__codelineno-7-10" name="__codelineno-7-10" href="#__codelineno-7-10"></a><span class="w">        </span><span class="s2">&quot;overlap_comm&quot;</span>:<span class="w"> </span>true,
</span><span id="__span-7-11"><a id="__codelineno-7-11" name="__codelineno-7-11" href="#__codelineno-7-11"></a><span class="w">        </span><span class="s2">&quot;reduce_scatter&quot;</span>:<span class="w"> </span>true,
</span><span id="__span-7-12"><a id="__codelineno-7-12" name="__codelineno-7-12" href="#__codelineno-7-12"></a><span class="w">        </span><span class="s2">&quot;reduce_bucket_size&quot;</span>:<span class="w"> </span>5e8,
</span><span id="__span-7-13"><a id="__codelineno-7-13" name="__codelineno-7-13" href="#__codelineno-7-13"></a><span class="w">        </span><span class="s2">&quot;contiguous_gradients&quot;</span>:<span class="w"> </span><span class="nb">true</span>
</span><span id="__span-7-14"><a id="__codelineno-7-14" name="__codelineno-7-14" href="#__codelineno-7-14"></a><span class="w">        </span><span class="s2">&quot;round_robin_gradients&quot;</span>:<span class="w"> </span><span class="nb">true</span>
</span><span id="__span-7-15"><a id="__codelineno-7-15" name="__codelineno-7-15" href="#__codelineno-7-15"></a><span class="w">    </span><span class="o">}</span>
</span><span id="__span-7-16"><a id="__codelineno-7-16" name="__codelineno-7-16" href="#__codelineno-7-16"></a><span class="o">}</span>
</span></code></pre></div>
<p></hfoption>
<hfoption id="ZeRO-3"></p>
<p>ZeRO-3는 옵티마이저, 그래디언트, 매개변수를 여러 GPU에 걸쳐 분할합니다. ZeRO-2와 달리 ZeRO-3는 여러 GPU에 대규모 모델을 가져올 수 있기 때문에 훈련 외에도 추론에도 사용할 수 있습니다. 구성해야 할 몇 가지 중요한 매개변수는 다음과 같습니다:</p>
<ul>
<li><code>device: "cpu"</code> 는 GPU 메모리가 부족하고 사용 가능한 CPU 메모리가 있는 경우 도움이 될 수 있습니다. 이를 통해 모델 매개변수를 CPU로 오프로드할 수 있습니다.</li>
<li><code>pin_memory: true</code> 는 처리량을 향상시킬 수 있지만, 핀 메모리는 메모리를 요청한 특정 프로세스를 위해 예약되어 있고 일반적으로 일반 CPU 메모리보다 훨씬 빠르게 액세스되기 때문에 다른 프로세스에서 사용할 수 있는 메모리가 줄어듭니다.</li>
<li><code>stage3_max_live_parameters</code> 는 특정 시간에 GPU에 유지하려는 전체 매개변수의 상한값입니다. OOM 오류가 발생하면 이 값을 줄이세요.</li>
<li><code>stage3_max_reuse_distance</code> 는 향후 매개변수를 다시 사용할 시기를 결정하는 값으로, 매개변수를 버릴지 유지할지 결정하는 데 도움이 됩니다. 매개변수를 재사용할 경우(<code>stage3_max_reuse_distance</code>보다 작은 값인 경우) 통신 오버헤드를 줄이기 위해 매개변수를 유지합니다. 이 기능은 활성화 체크포인팅이 활성화되어 있고 역전파 계산시까지 순전파 시점의 매개변수를 유지하려는 경우에 매우 유용합니다. 그러나 OOM 오류가 발생하면 이 값을 줄이세요.</li>
<li>모델 저장 시 <code>stage3_gather_16bit_weights_on_model_save</code>는 fp16 가중치를 통합합니다. 대규모 모델을 학습하거나 여러 GPU를 사용할 경우 메모리와 속도 측면에서 비용이 많이 듭니다. 훈련을 재개할 계획이라면 이 옵션을 활성화해야 합니다.</li>
<li>
<p><code>sub_group_size</code> 는 최적화 단계에서 업데이트되는 매개변수를 제어합니다. 매개변수는 <code>sub_group_size</code>의 버킷으로 그룹화되며 각 버킷은 한 번에 하나씩 업데이트됩니다. NVMe 오프로드와 함께 사용하는 경우 <code>sub_group_size</code>는 최적화 단계 중 모델 상태가 CPU 메모리로 이동하는 시점을 결정합니다. 이렇게 하면 매우 큰 모델의 CPU 메모리 부족을 방지할 수 있습니다. NVMe 오프로드를 사용하지 않는 경우 <code>sub_group_size</code>를 기본값으로 둘 수 있지만, 사용하는 경우 변경하는 것이 좋습니다:</p>
<ol>
<li>옵티마이저 단계에서 OOM 오류가 발생합니다. 이 경우, 임시 버퍼의 메모리 사용량을 줄이려면 <code>sub_group_size</code>를 줄이세요.</li>
<li>옵티마이저 단계에서 시간이 너무 오래 걸립니다. 이 경우 데이터 버퍼 증가로 인한 대역폭 사용률을 개선하기 위해 <code>sub_group_size</code>를 늘리세요.</li>
</ol>
</li>
<li>
<p><code>reduce_bucket_size</code>, <code>stage3_prefetch_bucket_size</code>, <code>stage3_param_persistence_threshold</code>는 모델의 숨겨진 크기에 따라 달라집니다. 이 값들을 <code>auto</code>으로 설정하고 [<code>Trainer</code>]가 자동으로 값을 할당하도록 허용하는 것이 좋습니다.</p>
</li>
</ul>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-8-1"><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a><span class="o">{</span>
</span><span id="__span-8-2"><a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a><span class="w">    </span><span class="s2">&quot;zero_optimization&quot;</span>:<span class="w"> </span><span class="o">{</span>
</span><span id="__span-8-3"><a id="__codelineno-8-3" name="__codelineno-8-3" href="#__codelineno-8-3"></a><span class="w">        </span><span class="s2">&quot;stage&quot;</span>:<span class="w"> </span><span class="m">3</span>,
</span><span id="__span-8-4"><a id="__codelineno-8-4" name="__codelineno-8-4" href="#__codelineno-8-4"></a><span class="w">        </span><span class="s2">&quot;offload_optimizer&quot;</span>:<span class="w"> </span><span class="o">{</span>
</span><span id="__span-8-5"><a id="__codelineno-8-5" name="__codelineno-8-5" href="#__codelineno-8-5"></a><span class="w">            </span><span class="s2">&quot;device&quot;</span>:<span class="w"> </span><span class="s2">&quot;cpu&quot;</span>,
</span><span id="__span-8-6"><a id="__codelineno-8-6" name="__codelineno-8-6" href="#__codelineno-8-6"></a><span class="w">            </span><span class="s2">&quot;pin_memory&quot;</span>:<span class="w"> </span><span class="nb">true</span>
</span><span id="__span-8-7"><a id="__codelineno-8-7" name="__codelineno-8-7" href="#__codelineno-8-7"></a><span class="w">        </span><span class="o">}</span>,
</span><span id="__span-8-8"><a id="__codelineno-8-8" name="__codelineno-8-8" href="#__codelineno-8-8"></a><span class="w">        </span><span class="s2">&quot;offload_param&quot;</span>:<span class="w"> </span><span class="o">{</span>
</span><span id="__span-8-9"><a id="__codelineno-8-9" name="__codelineno-8-9" href="#__codelineno-8-9"></a><span class="w">            </span><span class="s2">&quot;device&quot;</span>:<span class="w"> </span><span class="s2">&quot;cpu&quot;</span>,
</span><span id="__span-8-10"><a id="__codelineno-8-10" name="__codelineno-8-10" href="#__codelineno-8-10"></a><span class="w">            </span><span class="s2">&quot;pin_memory&quot;</span>:<span class="w"> </span><span class="nb">true</span>
</span><span id="__span-8-11"><a id="__codelineno-8-11" name="__codelineno-8-11" href="#__codelineno-8-11"></a><span class="w">        </span><span class="o">}</span>,
</span><span id="__span-8-12"><a id="__codelineno-8-12" name="__codelineno-8-12" href="#__codelineno-8-12"></a><span class="w">        </span><span class="s2">&quot;overlap_comm&quot;</span>:<span class="w"> </span>true,
</span><span id="__span-8-13"><a id="__codelineno-8-13" name="__codelineno-8-13" href="#__codelineno-8-13"></a><span class="w">        </span><span class="s2">&quot;contiguous_gradients&quot;</span>:<span class="w"> </span>true,
</span><span id="__span-8-14"><a id="__codelineno-8-14" name="__codelineno-8-14" href="#__codelineno-8-14"></a><span class="w">        </span><span class="s2">&quot;sub_group_size&quot;</span>:<span class="w"> </span>1e9,
</span><span id="__span-8-15"><a id="__codelineno-8-15" name="__codelineno-8-15" href="#__codelineno-8-15"></a><span class="w">        </span><span class="s2">&quot;reduce_bucket_size&quot;</span>:<span class="w"> </span><span class="s2">&quot;auto&quot;</span>,
</span><span id="__span-8-16"><a id="__codelineno-8-16" name="__codelineno-8-16" href="#__codelineno-8-16"></a><span class="w">        </span><span class="s2">&quot;stage3_prefetch_bucket_size&quot;</span>:<span class="w"> </span><span class="s2">&quot;auto&quot;</span>,
</span><span id="__span-8-17"><a id="__codelineno-8-17" name="__codelineno-8-17" href="#__codelineno-8-17"></a><span class="w">        </span><span class="s2">&quot;stage3_param_persistence_threshold&quot;</span>:<span class="w"> </span><span class="s2">&quot;auto&quot;</span>,
</span><span id="__span-8-18"><a id="__codelineno-8-18" name="__codelineno-8-18" href="#__codelineno-8-18"></a><span class="w">        </span><span class="s2">&quot;stage3_max_live_parameters&quot;</span>:<span class="w"> </span>1e9,
</span><span id="__span-8-19"><a id="__codelineno-8-19" name="__codelineno-8-19" href="#__codelineno-8-19"></a><span class="w">        </span><span class="s2">&quot;stage3_max_reuse_distance&quot;</span>:<span class="w"> </span>1e9,
</span><span id="__span-8-20"><a id="__codelineno-8-20" name="__codelineno-8-20" href="#__codelineno-8-20"></a><span class="w">        </span><span class="s2">&quot;stage3_gather_16bit_weights_on_model_save&quot;</span>:<span class="w"> </span><span class="nb">true</span>
</span><span id="__span-8-21"><a id="__codelineno-8-21" name="__codelineno-8-21" href="#__codelineno-8-21"></a><span class="w">    </span><span class="o">}</span>
</span><span id="__span-8-22"><a id="__codelineno-8-22" name="__codelineno-8-22" href="#__codelineno-8-22"></a><span class="o">}</span>
</span></code></pre></div>
<p><a href="https://deepspeed.readthedocs.io/en/latest/zero3.html#deepspeed.zero.Init"><code>deepspeed.zero.Init</code></a> 컨텍스트 매니저를 사용하면 모델을 더 빠르게 초기화할 수 있습니다:</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-9-1"><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">T5ForConditionalGeneration</span><span class="p">,</span> <span class="n">T5Config</span>
</span><span id="__span-9-2"><a id="__codelineno-9-2" name="__codelineno-9-2" href="#__codelineno-9-2"></a><span class="kn">import</span><span class="w"> </span><span class="nn">deepspeed</span>
</span><span id="__span-9-3"><a id="__codelineno-9-3" name="__codelineno-9-3" href="#__codelineno-9-3"></a>
</span><span id="__span-9-4"><a id="__codelineno-9-4" name="__codelineno-9-4" href="#__codelineno-9-4"></a><span class="k">with</span> <span class="n">deepspeed</span><span class="o">.</span><span class="n">zero</span><span class="o">.</span><span class="n">Init</span><span class="p">():</span>
</span><span id="__span-9-5"><a id="__codelineno-9-5" name="__codelineno-9-5" href="#__codelineno-9-5"></a>    <span class="n">config</span> <span class="o">=</span> <span class="n">T5Config</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;google-t5/t5-small&quot;</span><span class="p">)</span>
</span><span id="__span-9-6"><a id="__codelineno-9-6" name="__codelineno-9-6" href="#__codelineno-9-6"></a>    <span class="n">model</span> <span class="o">=</span> <span class="n">T5ForConditionalGeneration</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span></code></pre></div>
<p>사전 학습된 모델의 경우, 딥스피드 구성 파일에 <code>is_deepspeed_zero3_enabled: true</code>가 [<code>TrainingArguments</code>]에 설정되어 있어야 하며, ZeRO 구성이 활성화되어 있어야 합니다. 훈련된 모델 [<code>~PreTrainedModel.from_pretrained</code>]을 호출하기 <strong>전에</strong> [<code>TrainingArguments</code>] 객체를 생성해야 합니다.</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-10-1"><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModel</span><span class="p">,</span> <span class="n">Trainer</span><span class="p">,</span> <span class="n">TrainingArguments</span>
</span><span id="__span-10-2"><a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a>
</span><span id="__span-10-3"><a id="__codelineno-10-3" name="__codelineno-10-3" href="#__codelineno-10-3"></a><span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">deepspeed</span><span class="o">=</span><span class="n">ds_config</span><span class="p">)</span>
</span><span id="__span-10-4"><a id="__codelineno-10-4" name="__codelineno-10-4" href="#__codelineno-10-4"></a><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;google-t5/t5-small&quot;</span><span class="p">)</span>
</span><span id="__span-10-5"><a id="__codelineno-10-5" name="__codelineno-10-5" href="#__codelineno-10-5"></a><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
</span></code></pre></div>
<p>fp16 가중치가 단일 GPU에 맞지 않는 경우 ZeRO-3이 필요합니다. fp16 가중치를 로드할 수 있는 경우, [<code>~PreTrainedModel.from_pretrained</code>]에 <code>dtype=torch.float16</code>을 지정해야 합니다.</p>
<p>ZeRO-3의 또 다른 고려 사항은 여러 개의 GPU를 사용하는 경우 현재 실행 중인 레이어의 매개변수가 아닌 한 단일 GPU에 모든 매개변수가 없다는 것입니다. 사전 훈련된 모델 가중치를 [<code>~PreTrainedModel.from_pretrained</code>]에 로드하는 등 모든 레이어의 모든 매개변수에 한 번에 액세스하려면 한 번에 하나의 레이어를 로드하고 즉시 모든 GPU에 파티셔닝합니다. 이는 매우 큰 모델의 경우 메모리 제한으로 인해 하나의 GPU에 가중치를 로드한 다음 다른 GPU에 분산할 수 없기 때문입니다.</p>
<p>다음과 같이 보이는 모델 매개변수 가중치(여기서 <code>tensor([1.])</code>) 또는 매개변수 크기가 더 큰 다차원 형태 대신 1인 경우, 이는 매개변수가 분할되어 있으며 이것이 ZeRO-3 플레이스홀더인 것을 의미합니다.</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-11-1"><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></code></pre></div>
<p><Tip></p>
<p>ZeRO-3로 대규모 모델을 초기화하고 매개변수에 액세스하는 방법에 대한 자세한 내용은 <a href="https://deepspeed.readthedocs.io/en/latest/zero3.html#constructing-massive-models">Constructing Massive Models</a> 및 <a href="https://deepspeed.readthedocs.io/en/latest/zero3.html#gathering-parameters">Gathering Parameters</a> 가이드를 참조하세요.</p>
<p></Tip></p>
<p></hfoption>
</hfoptions></p>
<h3 id="nvme-nvme-configuration">NVMe 설정[[nvme-configuration]]</h3>
<p><a href="https://hf.co/papers/2104.07857">ZeRO-Infinity</a>를 사용하면 모델 상태를 CPU 및/또는 NVMe로 오프로드하여 더 많은 메모리를 절약할 수 있습니다. 스마트 파티셔닝 및 타일링 알고리즘을 통해 각 GPU는 오프로딩 중에 매우 적은 양의 데이터를 주고받을 수 있으므로 최신 NVMe는 훈련 프로세스에 사용할 수 있는 것보다 훨씬 더 큰 총 메모리 풀에 맞출 수 있습니다. ZeRO-Infinity에는 ZeRO-3가 필요합니다.</p>
<p>사용 가능한 CPU 및/또는 NVMe 메모리에 따라 <a href="https://www.deepspeed.ai/docs/config-json/#optimizer-offloading">옵티마이저</a>와 <a href="https://www.deepspeed.ai/docs/config-json/#parameter-offloading">매개변수</a> 중 하나만 오프로드하거나 아무것도 오프로드하지 않을 수 있습니다. 또한 일반 하드 드라이브나 솔리드 스테이트 드라이브에서도 작동하지만 속도가 현저히 느려지므로 <code>nvme_path</code>가 NVMe 장치를 가리키고 있는지 확인해야 합니다. 최신 NVMe를 사용하면 읽기 작업의 경우 최대 3.5GB/s, 쓰기 작업의 경우 최대 3GB/s의 전송 속도를 기대할 수 있습니다. 마지막으로, 트레이닝 설정에서 <a href="https://github.com/deepspeedai/DeepSpeed/issues/998">벤치마크 실행하기</a>을 통해 최적의 'aio' 구성을 결정합니다.</p>
<p>아래 예제 ZeRO-3/Infinity 구성 파일은 대부분의 매개변수 값을 <code>auto</code>으로 설정하고 있지만, 수동으로 값을 추가할 수도 있습니다.</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-12-1"><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a><span class="o">{</span>
</span><span id="__span-12-2"><a id="__codelineno-12-2" name="__codelineno-12-2" href="#__codelineno-12-2"></a><span class="w">    </span><span class="s2">&quot;fp16&quot;</span>:<span class="w"> </span><span class="o">{</span>
</span><span id="__span-12-3"><a id="__codelineno-12-3" name="__codelineno-12-3" href="#__codelineno-12-3"></a><span class="w">        </span><span class="s2">&quot;enabled&quot;</span>:<span class="w"> </span><span class="s2">&quot;auto&quot;</span>,
</span><span id="__span-12-4"><a id="__codelineno-12-4" name="__codelineno-12-4" href="#__codelineno-12-4"></a><span class="w">        </span><span class="s2">&quot;loss_scale&quot;</span>:<span class="w"> </span><span class="m">0</span>,
</span><span id="__span-12-5"><a id="__codelineno-12-5" name="__codelineno-12-5" href="#__codelineno-12-5"></a><span class="w">        </span><span class="s2">&quot;loss_scale_window&quot;</span>:<span class="w"> </span><span class="m">1000</span>,
</span><span id="__span-12-6"><a id="__codelineno-12-6" name="__codelineno-12-6" href="#__codelineno-12-6"></a><span class="w">        </span><span class="s2">&quot;initial_scale_power&quot;</span>:<span class="w"> </span><span class="m">16</span>,
</span><span id="__span-12-7"><a id="__codelineno-12-7" name="__codelineno-12-7" href="#__codelineno-12-7"></a><span class="w">        </span><span class="s2">&quot;hysteresis&quot;</span>:<span class="w"> </span><span class="m">2</span>,
</span><span id="__span-12-8"><a id="__codelineno-12-8" name="__codelineno-12-8" href="#__codelineno-12-8"></a><span class="w">        </span><span class="s2">&quot;min_loss_scale&quot;</span>:<span class="w"> </span><span class="m">1</span>
</span><span id="__span-12-9"><a id="__codelineno-12-9" name="__codelineno-12-9" href="#__codelineno-12-9"></a><span class="w">    </span><span class="o">}</span>,
</span><span id="__span-12-10"><a id="__codelineno-12-10" name="__codelineno-12-10" href="#__codelineno-12-10"></a>
</span><span id="__span-12-11"><a id="__codelineno-12-11" name="__codelineno-12-11" href="#__codelineno-12-11"></a><span class="w">    </span><span class="s2">&quot;optimizer&quot;</span>:<span class="w"> </span><span class="o">{</span>
</span><span id="__span-12-12"><a id="__codelineno-12-12" name="__codelineno-12-12" href="#__codelineno-12-12"></a><span class="w">        </span><span class="s2">&quot;type&quot;</span>:<span class="w"> </span><span class="s2">&quot;AdamW&quot;</span>,
</span><span id="__span-12-13"><a id="__codelineno-12-13" name="__codelineno-12-13" href="#__codelineno-12-13"></a><span class="w">        </span><span class="s2">&quot;params&quot;</span>:<span class="w"> </span><span class="o">{</span>
</span><span id="__span-12-14"><a id="__codelineno-12-14" name="__codelineno-12-14" href="#__codelineno-12-14"></a><span class="w">            </span><span class="s2">&quot;lr&quot;</span>:<span class="w"> </span><span class="s2">&quot;auto&quot;</span>,
</span><span id="__span-12-15"><a id="__codelineno-12-15" name="__codelineno-12-15" href="#__codelineno-12-15"></a><span class="w">            </span><span class="s2">&quot;betas&quot;</span>:<span class="w"> </span><span class="s2">&quot;auto&quot;</span>,
</span><span id="__span-12-16"><a id="__codelineno-12-16" name="__codelineno-12-16" href="#__codelineno-12-16"></a><span class="w">            </span><span class="s2">&quot;eps&quot;</span>:<span class="w"> </span><span class="s2">&quot;auto&quot;</span>,
</span><span id="__span-12-17"><a id="__codelineno-12-17" name="__codelineno-12-17" href="#__codelineno-12-17"></a><span class="w">            </span><span class="s2">&quot;weight_decay&quot;</span>:<span class="w"> </span><span class="s2">&quot;auto&quot;</span>
</span><span id="__span-12-18"><a id="__codelineno-12-18" name="__codelineno-12-18" href="#__codelineno-12-18"></a><span class="w">        </span><span class="o">}</span>
</span><span id="__span-12-19"><a id="__codelineno-12-19" name="__codelineno-12-19" href="#__codelineno-12-19"></a><span class="w">    </span><span class="o">}</span>,
</span><span id="__span-12-20"><a id="__codelineno-12-20" name="__codelineno-12-20" href="#__codelineno-12-20"></a>
</span><span id="__span-12-21"><a id="__codelineno-12-21" name="__codelineno-12-21" href="#__codelineno-12-21"></a><span class="w">    </span><span class="s2">&quot;scheduler&quot;</span>:<span class="w"> </span><span class="o">{</span>
</span><span id="__span-12-22"><a id="__codelineno-12-22" name="__codelineno-12-22" href="#__codelineno-12-22"></a><span class="w">        </span><span class="s2">&quot;type&quot;</span>:<span class="w"> </span><span class="s2">&quot;WarmupLR&quot;</span>,
</span><span id="__span-12-23"><a id="__codelineno-12-23" name="__codelineno-12-23" href="#__codelineno-12-23"></a><span class="w">        </span><span class="s2">&quot;params&quot;</span>:<span class="w"> </span><span class="o">{</span>
</span><span id="__span-12-24"><a id="__codelineno-12-24" name="__codelineno-12-24" href="#__codelineno-12-24"></a><span class="w">            </span><span class="s2">&quot;warmup_min_lr&quot;</span>:<span class="w"> </span><span class="s2">&quot;auto&quot;</span>,
</span><span id="__span-12-25"><a id="__codelineno-12-25" name="__codelineno-12-25" href="#__codelineno-12-25"></a><span class="w">            </span><span class="s2">&quot;warmup_max_lr&quot;</span>:<span class="w"> </span><span class="s2">&quot;auto&quot;</span>,
</span><span id="__span-12-26"><a id="__codelineno-12-26" name="__codelineno-12-26" href="#__codelineno-12-26"></a><span class="w">            </span><span class="s2">&quot;warmup_num_steps&quot;</span>:<span class="w"> </span><span class="s2">&quot;auto&quot;</span>
</span><span id="__span-12-27"><a id="__codelineno-12-27" name="__codelineno-12-27" href="#__codelineno-12-27"></a><span class="w">        </span><span class="o">}</span>
</span><span id="__span-12-28"><a id="__codelineno-12-28" name="__codelineno-12-28" href="#__codelineno-12-28"></a><span class="w">    </span><span class="o">}</span>,
</span><span id="__span-12-29"><a id="__codelineno-12-29" name="__codelineno-12-29" href="#__codelineno-12-29"></a>
</span><span id="__span-12-30"><a id="__codelineno-12-30" name="__codelineno-12-30" href="#__codelineno-12-30"></a><span class="w">    </span><span class="s2">&quot;zero_optimization&quot;</span>:<span class="w"> </span><span class="o">{</span>
</span><span id="__span-12-31"><a id="__codelineno-12-31" name="__codelineno-12-31" href="#__codelineno-12-31"></a><span class="w">        </span><span class="s2">&quot;stage&quot;</span>:<span class="w"> </span><span class="m">3</span>,
</span><span id="__span-12-32"><a id="__codelineno-12-32" name="__codelineno-12-32" href="#__codelineno-12-32"></a><span class="w">        </span><span class="s2">&quot;offload_optimizer&quot;</span>:<span class="w"> </span><span class="o">{</span>
</span><span id="__span-12-33"><a id="__codelineno-12-33" name="__codelineno-12-33" href="#__codelineno-12-33"></a><span class="w">            </span><span class="s2">&quot;device&quot;</span>:<span class="w"> </span><span class="s2">&quot;nvme&quot;</span>,
</span><span id="__span-12-34"><a id="__codelineno-12-34" name="__codelineno-12-34" href="#__codelineno-12-34"></a><span class="w">            </span><span class="s2">&quot;nvme_path&quot;</span>:<span class="w"> </span><span class="s2">&quot;/local_nvme&quot;</span>,
</span><span id="__span-12-35"><a id="__codelineno-12-35" name="__codelineno-12-35" href="#__codelineno-12-35"></a><span class="w">            </span><span class="s2">&quot;pin_memory&quot;</span>:<span class="w"> </span>true,
</span><span id="__span-12-36"><a id="__codelineno-12-36" name="__codelineno-12-36" href="#__codelineno-12-36"></a><span class="w">            </span><span class="s2">&quot;buffer_count&quot;</span>:<span class="w"> </span><span class="m">4</span>,
</span><span id="__span-12-37"><a id="__codelineno-12-37" name="__codelineno-12-37" href="#__codelineno-12-37"></a><span class="w">            </span><span class="s2">&quot;fast_init&quot;</span>:<span class="w"> </span><span class="nb">false</span>
</span><span id="__span-12-38"><a id="__codelineno-12-38" name="__codelineno-12-38" href="#__codelineno-12-38"></a><span class="w">        </span><span class="o">}</span>,
</span><span id="__span-12-39"><a id="__codelineno-12-39" name="__codelineno-12-39" href="#__codelineno-12-39"></a><span class="w">        </span><span class="s2">&quot;offload_param&quot;</span>:<span class="w"> </span><span class="o">{</span>
</span><span id="__span-12-40"><a id="__codelineno-12-40" name="__codelineno-12-40" href="#__codelineno-12-40"></a><span class="w">            </span><span class="s2">&quot;device&quot;</span>:<span class="w"> </span><span class="s2">&quot;nvme&quot;</span>,
</span><span id="__span-12-41"><a id="__codelineno-12-41" name="__codelineno-12-41" href="#__codelineno-12-41"></a><span class="w">            </span><span class="s2">&quot;nvme_path&quot;</span>:<span class="w"> </span><span class="s2">&quot;/local_nvme&quot;</span>,
</span><span id="__span-12-42"><a id="__codelineno-12-42" name="__codelineno-12-42" href="#__codelineno-12-42"></a><span class="w">            </span><span class="s2">&quot;pin_memory&quot;</span>:<span class="w"> </span>true,
</span><span id="__span-12-43"><a id="__codelineno-12-43" name="__codelineno-12-43" href="#__codelineno-12-43"></a><span class="w">            </span><span class="s2">&quot;buffer_count&quot;</span>:<span class="w"> </span><span class="m">5</span>,
</span><span id="__span-12-44"><a id="__codelineno-12-44" name="__codelineno-12-44" href="#__codelineno-12-44"></a><span class="w">            </span><span class="s2">&quot;buffer_size&quot;</span>:<span class="w"> </span>1e8,
</span><span id="__span-12-45"><a id="__codelineno-12-45" name="__codelineno-12-45" href="#__codelineno-12-45"></a><span class="w">            </span><span class="s2">&quot;max_in_cpu&quot;</span>:<span class="w"> </span>1e9
</span><span id="__span-12-46"><a id="__codelineno-12-46" name="__codelineno-12-46" href="#__codelineno-12-46"></a><span class="w">        </span><span class="o">}</span>,
</span><span id="__span-12-47"><a id="__codelineno-12-47" name="__codelineno-12-47" href="#__codelineno-12-47"></a><span class="w">        </span><span class="s2">&quot;aio&quot;</span>:<span class="w"> </span><span class="o">{</span>
</span><span id="__span-12-48"><a id="__codelineno-12-48" name="__codelineno-12-48" href="#__codelineno-12-48"></a><span class="w">            </span><span class="s2">&quot;block_size&quot;</span>:<span class="w"> </span><span class="m">262144</span>,
</span><span id="__span-12-49"><a id="__codelineno-12-49" name="__codelineno-12-49" href="#__codelineno-12-49"></a><span class="w">            </span><span class="s2">&quot;queue_depth&quot;</span>:<span class="w"> </span><span class="m">32</span>,
</span><span id="__span-12-50"><a id="__codelineno-12-50" name="__codelineno-12-50" href="#__codelineno-12-50"></a><span class="w">            </span><span class="s2">&quot;thread_count&quot;</span>:<span class="w"> </span><span class="m">1</span>,
</span><span id="__span-12-51"><a id="__codelineno-12-51" name="__codelineno-12-51" href="#__codelineno-12-51"></a><span class="w">            </span><span class="s2">&quot;single_submit&quot;</span>:<span class="w"> </span>false,
</span><span id="__span-12-52"><a id="__codelineno-12-52" name="__codelineno-12-52" href="#__codelineno-12-52"></a><span class="w">            </span><span class="s2">&quot;overlap_events&quot;</span>:<span class="w"> </span><span class="nb">true</span>
</span><span id="__span-12-53"><a id="__codelineno-12-53" name="__codelineno-12-53" href="#__codelineno-12-53"></a><span class="w">        </span><span class="o">}</span>,
</span><span id="__span-12-54"><a id="__codelineno-12-54" name="__codelineno-12-54" href="#__codelineno-12-54"></a><span class="w">        </span><span class="s2">&quot;overlap_comm&quot;</span>:<span class="w"> </span>true,
</span><span id="__span-12-55"><a id="__codelineno-12-55" name="__codelineno-12-55" href="#__codelineno-12-55"></a><span class="w">        </span><span class="s2">&quot;contiguous_gradients&quot;</span>:<span class="w"> </span>true,
</span><span id="__span-12-56"><a id="__codelineno-12-56" name="__codelineno-12-56" href="#__codelineno-12-56"></a><span class="w">        </span><span class="s2">&quot;sub_group_size&quot;</span>:<span class="w"> </span>1e9,
</span><span id="__span-12-57"><a id="__codelineno-12-57" name="__codelineno-12-57" href="#__codelineno-12-57"></a><span class="w">        </span><span class="s2">&quot;reduce_bucket_size&quot;</span>:<span class="w"> </span><span class="s2">&quot;auto&quot;</span>,
</span><span id="__span-12-58"><a id="__codelineno-12-58" name="__codelineno-12-58" href="#__codelineno-12-58"></a><span class="w">        </span><span class="s2">&quot;stage3_prefetch_bucket_size&quot;</span>:<span class="w"> </span><span class="s2">&quot;auto&quot;</span>,
</span><span id="__span-12-59"><a id="__codelineno-12-59" name="__codelineno-12-59" href="#__codelineno-12-59"></a><span class="w">        </span><span class="s2">&quot;stage3_param_persistence_threshold&quot;</span>:<span class="w"> </span><span class="s2">&quot;auto&quot;</span>,
</span><span id="__span-12-60"><a id="__codelineno-12-60" name="__codelineno-12-60" href="#__codelineno-12-60"></a><span class="w">        </span><span class="s2">&quot;stage3_max_live_parameters&quot;</span>:<span class="w"> </span>1e9,
</span><span id="__span-12-61"><a id="__codelineno-12-61" name="__codelineno-12-61" href="#__codelineno-12-61"></a><span class="w">        </span><span class="s2">&quot;stage3_max_reuse_distance&quot;</span>:<span class="w"> </span>1e9,
</span><span id="__span-12-62"><a id="__codelineno-12-62" name="__codelineno-12-62" href="#__codelineno-12-62"></a><span class="w">        </span><span class="s2">&quot;stage3_gather_16bit_weights_on_model_save&quot;</span>:<span class="w"> </span><span class="nb">true</span>
</span><span id="__span-12-63"><a id="__codelineno-12-63" name="__codelineno-12-63" href="#__codelineno-12-63"></a><span class="w">    </span><span class="o">}</span>,
</span><span id="__span-12-64"><a id="__codelineno-12-64" name="__codelineno-12-64" href="#__codelineno-12-64"></a>
</span><span id="__span-12-65"><a id="__codelineno-12-65" name="__codelineno-12-65" href="#__codelineno-12-65"></a><span class="w">    </span><span class="s2">&quot;gradient_accumulation_steps&quot;</span>:<span class="w"> </span><span class="s2">&quot;auto&quot;</span>,
</span><span id="__span-12-66"><a id="__codelineno-12-66" name="__codelineno-12-66" href="#__codelineno-12-66"></a><span class="w">    </span><span class="s2">&quot;gradient_clipping&quot;</span>:<span class="w"> </span><span class="s2">&quot;auto&quot;</span>,
</span><span id="__span-12-67"><a id="__codelineno-12-67" name="__codelineno-12-67" href="#__codelineno-12-67"></a><span class="w">    </span><span class="s2">&quot;steps_per_print&quot;</span>:<span class="w"> </span><span class="m">2000</span>,
</span><span id="__span-12-68"><a id="__codelineno-12-68" name="__codelineno-12-68" href="#__codelineno-12-68"></a><span class="w">    </span><span class="s2">&quot;train_batch_size&quot;</span>:<span class="w"> </span><span class="s2">&quot;auto&quot;</span>,
</span><span id="__span-12-69"><a id="__codelineno-12-69" name="__codelineno-12-69" href="#__codelineno-12-69"></a><span class="w">    </span><span class="s2">&quot;train_micro_batch_size_per_gpu&quot;</span>:<span class="w"> </span><span class="s2">&quot;auto&quot;</span>,
</span><span id="__span-12-70"><a id="__codelineno-12-70" name="__codelineno-12-70" href="#__codelineno-12-70"></a><span class="w">    </span><span class="s2">&quot;wall_clock_breakdown&quot;</span>:<span class="w"> </span><span class="nb">false</span>
</span><span id="__span-12-71"><a id="__codelineno-12-71" name="__codelineno-12-71" href="#__codelineno-12-71"></a><span class="o">}</span>
</span></code></pre></div>
<h2 id="deepspeed-deepspeed-features">DeepSpeed 구성[[deepspeed-features]]</h2>
<p>이 섹션에서 간략하게 설명하는 몇 가지 중요한 매개변수를 DeepSpeed 구성 파일에 지정할 수 있습니다.</p>
<h3 id="activationgradient-checkpointing">활성화/그레이디언트 체크포인팅[[activationgradient-checkpointing]]</h3>
<p>활성화 및 그레이디언트 체크포인팅은 속도를 더 많은 GPU 메모리와 교환하여 GPU 메모리가 부족한 상황을 극복하거나 배치 크기를 늘려 성능을 향상시킬 수 있습니다. 이 기능을 활성화하려면 다음과 같이 하세요:</p>
<ol>
<li>허깅 페이스 모델의 경우, [<code>Trainer</code>]에서 <code>model.gradient_checkpointing_enable()</code> 또는 <code>--gradient_checkpointing</code>을 설정합니다.</li>
<li>허깅 페이스가 아닌 모델의 경우, 딥스피드 <a href="https://deepspeed.readthedocs.io/en/latest/activation-checkpointing.html">Activation Checkpointing API</a>를 사용합니다. 트랜스포머 모델링 코드를 대체하고 <code>torch.utils.checkpoint</code>를 DeepSpeed API로 대체할 수도 있습니다. 이 접근 방식은 순방향 활성화를 다시 계산하는 대신 CPU 메모리로 오프로드할 수 있으므로 더 유연합니다.</li>
</ol>
<h3 id="optimizer-and-scheduler">옵티마이저와 스케줄러[[optimizer-and-scheduler]]</h3>
<p><code>offload_optimizer</code>를 활성화하지 않는 한 DeepSpeed와 트랜스포머 옵티마이저 및 스케줄러를 혼합하여 사용할 수 있습니다. <code>offload_optimizer</code>를 활성화하면 CPU와 GPU 구현이 모두 있는 경우 DeepSpeed가 아닌 최적화기(LAMB 제외)를 사용할 수 있습니다.</p>
<p><Tip warning={true}></p>
<p>구성 파일의 최적화 프로그램 및 스케줄러 매개변수는 명령줄에서 설정할 수 있으므로 오류를 찾기 어렵지 않습니다. 예를 들어 학습 속도가 다른 곳에서 다른 값으로 설정된 경우 명령줄에서 이를 재정의할 수 있습니다. 최적화 프로그램 및 스케줄러 매개변수 외에도 [<code>Trainer</code>] 명령줄 인수가 DeepSpeed 구성과 일치하는지 확인해야 합니다.</p>
<p></Tip></p>
<p><hfoptions id="opt-sched">
<hfoption id="optimizer"></p>
<p>DeepSpeed는 여러 <a href="https://www.deepspeed.ai/docs/config-json/#optimizer-parameters">옵티마이저</a>를 제공하지만(Adam, AdamW, OneBitAdam 및 LAMB) PyTorch에서 다른 옵티마이저를 가져올 수도 있습니다. 설정에서 옵티마이저를 구성하지 않으면 [<code>Trainer</code>]가 자동으로 AdamW를 선택하고 명령줄에서 제공된 값 또는 기본값을 사용합니다: <code>lr</code>, <code>adam_beta1</code>, <code>adam_beta2</code>, <code>adam_epsilon</code>, <code>weight_decay</code>.</p>
<p>매개변수를 <code>"auto"</code>으로 설정하거나 원하는 값을 직접 수동으로 입력할 수 있습니다.</p>
<div class="language-yaml highlight"><pre><span></span><code><span id="__span-13-1"><a id="__codelineno-13-1" name="__codelineno-13-1" href="#__codelineno-13-1"></a><span class="p p-Indicator">{</span>
</span><span id="__span-13-2"><a id="__codelineno-13-2" name="__codelineno-13-2" href="#__codelineno-13-2"></a><span class="w">   </span><span class="s">&quot;optimizer&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="p p-Indicator">{</span>
</span><span id="__span-13-3"><a id="__codelineno-13-3" name="__codelineno-13-3" href="#__codelineno-13-3"></a><span class="w">       </span><span class="s">&quot;type&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="s">&quot;AdamW&quot;</span><span class="p p-Indicator">,</span>
</span><span id="__span-13-4"><a id="__codelineno-13-4" name="__codelineno-13-4" href="#__codelineno-13-4"></a><span class="w">       </span><span class="s">&quot;params&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="p p-Indicator">{</span>
</span><span id="__span-13-5"><a id="__codelineno-13-5" name="__codelineno-13-5" href="#__codelineno-13-5"></a><span class="w">         </span><span class="s">&quot;lr&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="s">&quot;auto&quot;</span><span class="p p-Indicator">,</span>
</span><span id="__span-13-6"><a id="__codelineno-13-6" name="__codelineno-13-6" href="#__codelineno-13-6"></a><span class="w">         </span><span class="s">&quot;betas&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="s">&quot;auto&quot;</span><span class="p p-Indicator">,</span>
</span><span id="__span-13-7"><a id="__codelineno-13-7" name="__codelineno-13-7" href="#__codelineno-13-7"></a><span class="w">         </span><span class="s">&quot;eps&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="s">&quot;auto&quot;</span><span class="p p-Indicator">,</span>
</span><span id="__span-13-8"><a id="__codelineno-13-8" name="__codelineno-13-8" href="#__codelineno-13-8"></a><span class="w">         </span><span class="s">&quot;weight_decay&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="s">&quot;auto&quot;</span>
</span><span id="__span-13-9"><a id="__codelineno-13-9" name="__codelineno-13-9" href="#__codelineno-13-9"></a><span class="w">       </span><span class="p p-Indicator">}</span>
</span><span id="__span-13-10"><a id="__codelineno-13-10" name="__codelineno-13-10" href="#__codelineno-13-10"></a><span class="w">   </span><span class="p p-Indicator">}</span>
</span><span id="__span-13-11"><a id="__codelineno-13-11" name="__codelineno-13-11" href="#__codelineno-13-11"></a><span class="p p-Indicator">}</span>
</span></code></pre></div>
<p>최상위 구성에 다음을 추가하여 지원되지 않는 옵티마이저를 사용할 수도 있습니다.</p>
<div class="language-yaml highlight"><pre><span></span><code><span id="__span-14-1"><a id="__codelineno-14-1" name="__codelineno-14-1" href="#__codelineno-14-1"></a><span class="p p-Indicator">{</span>
</span><span id="__span-14-2"><a id="__codelineno-14-2" name="__codelineno-14-2" href="#__codelineno-14-2"></a><span class="w">   </span><span class="s">&quot;zero_allow_untested_optimizer&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="nv">true</span>
</span><span id="__span-14-3"><a id="__codelineno-14-3" name="__codelineno-14-3" href="#__codelineno-14-3"></a><span class="p p-Indicator">}</span>
</span></code></pre></div>
<p>DeepSpeed==0.8.3부터 오프로드를 사용하려면 오프로드가 DeepSpeed의 CPU Adam 옵티마이저에서 가장 잘 작동하므로 최상위 수준 구성에 다음 사항을 추가해야 합니다.</p>
<div class="language-yaml highlight"><pre><span></span><code><span id="__span-15-1"><a id="__codelineno-15-1" name="__codelineno-15-1" href="#__codelineno-15-1"></a><span class="p p-Indicator">{</span>
</span><span id="__span-15-2"><a id="__codelineno-15-2" name="__codelineno-15-2" href="#__codelineno-15-2"></a><span class="w">   </span><span class="s">&quot;zero_force_ds_cpu_optimizer&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="nv">false</span>
</span><span id="__span-15-3"><a id="__codelineno-15-3" name="__codelineno-15-3" href="#__codelineno-15-3"></a><span class="p p-Indicator">}</span>
</span></code></pre></div>
<p></hfoption>
<hfoption id="scheduler"></p>
<p>DeepSpeed는 LRRangeTest, OneCycle, WarmupLR 및 WarmupDecayLR learning rate<a href="https://www.deepspeed.ai/docs/config-json/#scheduler-parameters">schedulers</a>를 지원합니다.</p>
<p>트랜스포머와 DeepSpeed는 동일한 두 가지 스케줄러를 제공합니다:</p>
<ul>
<li>WarmupLR은 Transformers의 <code>--lr_scheduler_type constant_warmup</code>과 동일합니다.</li>
<li>WarmupDecayLR은 Transformers의 <code>--lr_scheduler_type linear</code>와 동일합니다(Transformers에서 사용되는 기본 스케줄러입니다).</li>
</ul>
<p>설정에서 스케줄러를 구성하지 않으면[<code>Trainer</code>]는 자동으로 WarmupDecayLR을 선택하고 명령줄에서 제공된 값 또는 기본값을 사용합니다: <code>warmup_min_lr</code>, <code>warmup_max_lr</code>, <code>warmup_num_steps</code>, <code>total_num_steps</code> (<code>max_steps</code>가 제공되지 않으면 런타임 중에 자동으로 계산됨).</p>
<p>매개변수를 <code>"auto"</code>으로 설정하거나 원하는 값을 직접 수동으로 입력할 수 있습니다.</p>
<div class="language-yaml highlight"><pre><span></span><code><span id="__span-16-1"><a id="__codelineno-16-1" name="__codelineno-16-1" href="#__codelineno-16-1"></a><span class="p p-Indicator">{</span>
</span><span id="__span-16-2"><a id="__codelineno-16-2" name="__codelineno-16-2" href="#__codelineno-16-2"></a><span class="w">   </span><span class="s">&quot;scheduler&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="p p-Indicator">{</span>
</span><span id="__span-16-3"><a id="__codelineno-16-3" name="__codelineno-16-3" href="#__codelineno-16-3"></a><span class="w">         </span><span class="s">&quot;type&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="s">&quot;WarmupDecayLR&quot;</span><span class="p p-Indicator">,</span>
</span><span id="__span-16-4"><a id="__codelineno-16-4" name="__codelineno-16-4" href="#__codelineno-16-4"></a><span class="w">         </span><span class="s">&quot;params&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="p p-Indicator">{</span>
</span><span id="__span-16-5"><a id="__codelineno-16-5" name="__codelineno-16-5" href="#__codelineno-16-5"></a><span class="w">             </span><span class="s">&quot;total_num_steps&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="s">&quot;auto&quot;</span><span class="p p-Indicator">,</span>
</span><span id="__span-16-6"><a id="__codelineno-16-6" name="__codelineno-16-6" href="#__codelineno-16-6"></a><span class="w">             </span><span class="s">&quot;warmup_min_lr&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="s">&quot;auto&quot;</span><span class="p p-Indicator">,</span>
</span><span id="__span-16-7"><a id="__codelineno-16-7" name="__codelineno-16-7" href="#__codelineno-16-7"></a><span class="w">             </span><span class="s">&quot;warmup_max_lr&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="s">&quot;auto&quot;</span><span class="p p-Indicator">,</span>
</span><span id="__span-16-8"><a id="__codelineno-16-8" name="__codelineno-16-8" href="#__codelineno-16-8"></a><span class="w">             </span><span class="s">&quot;warmup_num_steps&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="s">&quot;auto&quot;</span>
</span><span id="__span-16-9"><a id="__codelineno-16-9" name="__codelineno-16-9" href="#__codelineno-16-9"></a><span class="w">         </span><span class="p p-Indicator">}</span>
</span><span id="__span-16-10"><a id="__codelineno-16-10" name="__codelineno-16-10" href="#__codelineno-16-10"></a><span class="w">     </span><span class="p p-Indicator">}</span>
</span><span id="__span-16-11"><a id="__codelineno-16-11" name="__codelineno-16-11" href="#__codelineno-16-11"></a><span class="p p-Indicator">}</span>
</span></code></pre></div>
<p></hfoption>
</hfoptions></p>
<h3 id="precision">정밀도[[precision]]</h3>
<p>DeepSpeed는 fp32, fp16 및 bf16 혼합 정밀도를 지원합니다.</p>
<p><hfoptions id="precision">
<hfoption id="fp32"></p>
<p>모델이 혼합 정밀도로 사전 학습되지 않은 경우와 같이 혼합 정밀도로 잘 작동하지 않는 경우 NaN 손실을 유발할 수 있는 오버플로 또는 언더플로 문제가 발생할 수 있습니다. 이러한 경우에는 기본 fp16 모드를 명시적으로 비활성화하여 전체 fp32 정밀도를 사용해야 합니다.</p>
<div class="language-yaml highlight"><pre><span></span><code><span id="__span-17-1"><a id="__codelineno-17-1" name="__codelineno-17-1" href="#__codelineno-17-1"></a><span class="p p-Indicator">{</span>
</span><span id="__span-17-2"><a id="__codelineno-17-2" name="__codelineno-17-2" href="#__codelineno-17-2"></a><span class="w">    </span><span class="s">&quot;fp16&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="p p-Indicator">{</span>
</span><span id="__span-17-3"><a id="__codelineno-17-3" name="__codelineno-17-3" href="#__codelineno-17-3"></a><span class="w">        </span><span class="s">&quot;enabled&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="nv">false</span>
</span><span id="__span-17-4"><a id="__codelineno-17-4" name="__codelineno-17-4" href="#__codelineno-17-4"></a><span class="w">    </span><span class="p p-Indicator">}</span>
</span><span id="__span-17-5"><a id="__codelineno-17-5" name="__codelineno-17-5" href="#__codelineno-17-5"></a><span class="p p-Indicator">}</span>
</span></code></pre></div>
<p>Ampere GPU 및 PyTorch 1.7 이상의 경우 일부 연산에 대해 더 효율적인 <a href="https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices">tf32</a> 형식으로 자동 전환되지만 결과는 여전히 fp32로 표시됩니다. [<code>Trainer</code>]에서 <code>--tf32</code>를 설정하여 활성화하고 <code>--tf32 0</code> 또는 <code>--no_tf32</code>를 비활성화하면 제어할 수 있습니다.</p>
<p></hfoption>
<hfoption id="fp16"></p>
<p>PyTorch AMP와 같은 fp16 혼합 정밀도를 구성하면 메모리 사용량이 줄어들고 훈련 속도가 빨라집니다.[<code>Trainer</code>]는 <code>args.fp16_backend</code> 값에 따라 fp16을 자동으로 활성화 또는 비활성화하며, 나머지 구성은 사용자가 설정할 수 있습니다. 명령줄에서 다음 인수를 전달하면 fp16이 활성화됩니다: <code>fp16</code>, <code>--fp16_backend amp</code> 또는 <code>--fp16_full_eval</code>.</p>
<div class="language-yaml highlight"><pre><span></span><code><span id="__span-18-1"><a id="__codelineno-18-1" name="__codelineno-18-1" href="#__codelineno-18-1"></a><span class="p p-Indicator">{</span>
</span><span id="__span-18-2"><a id="__codelineno-18-2" name="__codelineno-18-2" href="#__codelineno-18-2"></a><span class="w">    </span><span class="s">&quot;fp16&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="p p-Indicator">{</span>
</span><span id="__span-18-3"><a id="__codelineno-18-3" name="__codelineno-18-3" href="#__codelineno-18-3"></a><span class="w">        </span><span class="s">&quot;enabled&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="s">&quot;auto&quot;</span><span class="p p-Indicator">,</span>
</span><span id="__span-18-4"><a id="__codelineno-18-4" name="__codelineno-18-4" href="#__codelineno-18-4"></a><span class="w">        </span><span class="s">&quot;loss_scale&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="nv">0</span><span class="p p-Indicator">,</span>
</span><span id="__span-18-5"><a id="__codelineno-18-5" name="__codelineno-18-5" href="#__codelineno-18-5"></a><span class="w">        </span><span class="s">&quot;loss_scale_window&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="nv">1000</span><span class="p p-Indicator">,</span>
</span><span id="__span-18-6"><a id="__codelineno-18-6" name="__codelineno-18-6" href="#__codelineno-18-6"></a><span class="w">        </span><span class="s">&quot;initial_scale_power&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="nv">16</span><span class="p p-Indicator">,</span>
</span><span id="__span-18-7"><a id="__codelineno-18-7" name="__codelineno-18-7" href="#__codelineno-18-7"></a><span class="w">        </span><span class="s">&quot;hysteresis&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="nv">2</span><span class="p p-Indicator">,</span>
</span><span id="__span-18-8"><a id="__codelineno-18-8" name="__codelineno-18-8" href="#__codelineno-18-8"></a><span class="w">        </span><span class="s">&quot;min_loss_scale&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="nv">1</span>
</span><span id="__span-18-9"><a id="__codelineno-18-9" name="__codelineno-18-9" href="#__codelineno-18-9"></a><span class="w">    </span><span class="p p-Indicator">}</span>
</span><span id="__span-18-10"><a id="__codelineno-18-10" name="__codelineno-18-10" href="#__codelineno-18-10"></a><span class="p p-Indicator">}</span>
</span></code></pre></div>
<p>추가 딥스피드 fp16 훈련 옵션은 <a href="https://www.deepspeed.ai/docs/config-json/#fp16-training-options">fp16 훈련 옵션</a> 참조를 참조하세요.</p>
<p></hfoption>
<hfoption id="bf16"></p>
<p>bf16을 사용하려면 DeepSpeed==0.6.0 이상이 필요합니다. bf16은 fp32와 동적 범위가 동일하며 손실 스케일링이 필요하지 않습니다. 그러나 <a href="#gradient-accumulation">gradient accumulation</a>을 bf16과 함께 사용하면 이 형식의 낮은 정밀도로 인해 손실이 발생할 수 있으므로 원하지 않는 그레이디언트가 bf16에 누적될 수 있습니다.</p>
<p>bf16은 설정 파일에서 설정하거나 다음 인수를 전달하면 명령줄에서 활성화할 수 있습니다: <code>--bf16</code> 또는 <code>--bf16_full_eval</code>.</p>
<div class="language-yaml highlight"><pre><span></span><code><span id="__span-19-1"><a id="__codelineno-19-1" name="__codelineno-19-1" href="#__codelineno-19-1"></a><span class="p p-Indicator">{</span>
</span><span id="__span-19-2"><a id="__codelineno-19-2" name="__codelineno-19-2" href="#__codelineno-19-2"></a><span class="w">    </span><span class="s">&quot;bf16&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="p p-Indicator">{</span>
</span><span id="__span-19-3"><a id="__codelineno-19-3" name="__codelineno-19-3" href="#__codelineno-19-3"></a><span class="w">        </span><span class="s">&quot;enabled&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="s">&quot;auto&quot;</span>
</span><span id="__span-19-4"><a id="__codelineno-19-4" name="__codelineno-19-4" href="#__codelineno-19-4"></a><span class="w">    </span><span class="p p-Indicator">}</span>
</span><span id="__span-19-5"><a id="__codelineno-19-5" name="__codelineno-19-5" href="#__codelineno-19-5"></a><span class="p p-Indicator">}</span>
</span></code></pre></div>
<p></hfoption>
</hfoptions></p>
<h3 id="batch-size">배치 크기[[batch-size]]</h3>
<p>배치 크기는 자동으로 구성하거나 명시적으로 설정할 수 있습니다. <code>"auto"</code> 옵션을 사용하도록 선택하면 [<code>Trainer</code>]는 <code>train_micro_batch_size_per_gpu</code>를 args.<code>per_device_train_batch_size</code>의 값으로, <code>train_batch_size</code>를 <code>args.world_size * args.per_device_train_batch_size * args.gradient_accumulation_steps</code>로 설정합니다.</p>
<div class="language-yaml highlight"><pre><span></span><code><span id="__span-20-1"><a id="__codelineno-20-1" name="__codelineno-20-1" href="#__codelineno-20-1"></a><span class="p p-Indicator">{</span>
</span><span id="__span-20-2"><a id="__codelineno-20-2" name="__codelineno-20-2" href="#__codelineno-20-2"></a><span class="w">    </span><span class="s">&quot;train_micro_batch_size_per_gpu&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="s">&quot;auto&quot;</span><span class="p p-Indicator">,</span>
</span><span id="__span-20-3"><a id="__codelineno-20-3" name="__codelineno-20-3" href="#__codelineno-20-3"></a><span class="w">    </span><span class="s">&quot;train_batch_size&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="s">&quot;auto&quot;</span>
</span><span id="__span-20-4"><a id="__codelineno-20-4" name="__codelineno-20-4" href="#__codelineno-20-4"></a><span class="p p-Indicator">}</span>
</span></code></pre></div>
<h3 id="gradient-accumulation">그레이디언트 누적[[gradient-accumulation]]</h3>
<p>그레이디언트 누적을 자동으로 구성하거나 명시적으로 설정할 수 있습니다. <code>"auto"</code> 옵션을 사용하도록 선택하면 [<code>Trainer</code>]가 <code>args.gradient_accumulation_steps</code>의 값으로 설정합니다.</p>
<div class="language-yaml highlight"><pre><span></span><code><span id="__span-21-1"><a id="__codelineno-21-1" name="__codelineno-21-1" href="#__codelineno-21-1"></a><span class="p p-Indicator">{</span>
</span><span id="__span-21-2"><a id="__codelineno-21-2" name="__codelineno-21-2" href="#__codelineno-21-2"></a><span class="w">    </span><span class="s">&quot;gradient_accumulation_steps&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="s">&quot;auto&quot;</span>
</span><span id="__span-21-3"><a id="__codelineno-21-3" name="__codelineno-21-3" href="#__codelineno-21-3"></a><span class="p p-Indicator">}</span>
</span></code></pre></div>
<h3 id="gradient-clipping">그레이디언트 클리핑[[gradient-clipping]]</h3>
<p>그레이디언트 클리핑은 자동으로 구성하거나 명시적으로 설정할 수 있습니다. <code>"auto"</code> 옵션을 사용하도록 선택하면 [<code>Trainer</code>]가 <code>args.max_grad_norm</code>의 값으로 설정합니다.</p>
<div class="language-yaml highlight"><pre><span></span><code><span id="__span-22-1"><a id="__codelineno-22-1" name="__codelineno-22-1" href="#__codelineno-22-1"></a><span class="p p-Indicator">{</span>
</span><span id="__span-22-2"><a id="__codelineno-22-2" name="__codelineno-22-2" href="#__codelineno-22-2"></a><span class="w">    </span><span class="s">&quot;gradient_clipping&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="s">&quot;auto&quot;</span>
</span><span id="__span-22-3"><a id="__codelineno-22-3" name="__codelineno-22-3" href="#__codelineno-22-3"></a><span class="p p-Indicator">}</span>
</span></code></pre></div>
<h3 id="communication-data-typecommunication-data-type">통신 데이터 유형(Communication data type)[[communication-data-type]]</h3>
<p>축소, 수집 및 분산 작업과 같은 통신 집합체의 경우 별도의 데이터 유형이 사용됩니다.</p>
<p>모든 수집 및 분산 작업은 데이터와 동일한 데이터 유형으로 수행됩니다. 예를 들어 bf16으로 훈련하는 경우, 수집은 비손실 연산이므로 데이터도 bf16으로 수집됩니다.</p>
<p>예를 들어 그레이디언트가 여러 GPU에 걸쳐 평균화되는 경우와 같이 감소 연산은 손실이 발생합니다. 통신이 fp16 또는 bf16으로 수행되는 경우, 낮은 정밀도로 여러 숫자를 더하면 정확하지 않기 때문에 손실이 발생할 가능성이 더 높습니다. 특히 fp16보다 정밀도가 낮은 bf16의 경우 더욱 그렇습니다. 이러한 이유로 기울기를 평균화할 때 손실이 최소화되므로 감소 연산에는 fp16이 기본값으로 사용됩니다.</p>
<p>통신 데이터 유형은 설정 파일에서 <code>communication_data_type</code> 매개변수를 설정하여 선택할 수 있습니다. 예를 들어, fp32를 선택하면 약간의 오버헤드가 추가되지만 감소 연산이 fp32에 누적되고 준비가 되면 훈련 중인 반정밀 dtype으로 다운캐스트됩니다.</p>
<div class="language-yaml highlight"><pre><span></span><code><span id="__span-23-1"><a id="__codelineno-23-1" name="__codelineno-23-1" href="#__codelineno-23-1"></a><span class="p p-Indicator">{</span>
</span><span id="__span-23-2"><a id="__codelineno-23-2" name="__codelineno-23-2" href="#__codelineno-23-2"></a><span class="w">    </span><span class="s">&quot;communication_data_type&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="s">&quot;fp32&quot;</span>
</span><span id="__span-23-3"><a id="__codelineno-23-3" name="__codelineno-23-3" href="#__codelineno-23-3"></a><span class="p p-Indicator">}</span>
</span></code></pre></div>
<h2 id="deployment">모델 배포[[deployment]]</h2>
<p><a href="https://pytorch.org/docs/stable/elastic/run.html">torchrun</a>, <code>deepspeed</code> 런처 또는 <a href="https://huggingface.co/docs/accelerate/basic_tutorials/launch#using-accelerate-launch">Accelerate</a> 등 다양한 런처를 통해 DeepSpeed를 배포할 수 있습니다. 배포하려면 [<code>Trainer</code>] 명령줄에 <code>--deepspeed ds_config.json</code>을 추가합니다. 필요한 명령줄 인수를 코드에 추가하려면 DeepSpeed의 <a href="https://deepspeed.readthedocs.io/en/latest/initialize.html#argument-parsing"><code>add_config_arguments</code></a> 유틸리티를 사용하는 것이 좋습니다.</p>
<p>이 가이드에서는 다양한 트레이닝 설정에 대해 <code>deepspeed</code> 런처로 DeepSpeed를 배포하는 방법을 보여드립니다. 보다 실용적인 사용 예제는 이 <a href="https://github.com/huggingface/transformers/issues/8771#issuecomment-759248400">post</a>에서 확인할 수 있습니다.</p>
<p><hfoptions id="deploy">
<hfoption id="multi-GPU"></p>
<p>여러 GPU에 DeepSpeed를 배포하려면 <code>--num_gpus</code> 매개변수를 추가하세요. 사용 가능한 모든 GPU를 사용하려는 경우 <code>--num_gpus</code>를 추가할 필요가 없습니다. 아래 예제에서는 2개의 GPU를 사용합니다.</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-24-1"><a id="__codelineno-24-1" name="__codelineno-24-1" href="#__codelineno-24-1"></a>deepspeed<span class="w"> </span>--num_gpus<span class="o">=</span><span class="m">2</span><span class="w"> </span>examples/pytorch/translation/run_translation.py<span class="w"> </span><span class="se">\</span>
</span><span id="__span-24-2"><a id="__codelineno-24-2" name="__codelineno-24-2" href="#__codelineno-24-2"></a>--deepspeed<span class="w"> </span>tests/deepspeed/ds_config_zero3.json<span class="w"> </span><span class="se">\</span>
</span><span id="__span-24-3"><a id="__codelineno-24-3" name="__codelineno-24-3" href="#__codelineno-24-3"></a>--model_name_or_path<span class="w"> </span>google-t5/t5-small<span class="w"> </span>--per_device_train_batch_size<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-24-4"><a id="__codelineno-24-4" name="__codelineno-24-4" href="#__codelineno-24-4"></a>--output_dir<span class="w"> </span>output_dir<span class="w"> </span>--fp16<span class="w"> </span><span class="se">\</span>
</span><span id="__span-24-5"><a id="__codelineno-24-5" name="__codelineno-24-5" href="#__codelineno-24-5"></a>--do_train<span class="w"> </span>--max_train_samples<span class="w"> </span><span class="m">500</span><span class="w"> </span>--num_train_epochs<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-24-6"><a id="__codelineno-24-6" name="__codelineno-24-6" href="#__codelineno-24-6"></a>--dataset_name<span class="w"> </span>wmt16<span class="w"> </span>--dataset_config<span class="w"> </span><span class="s2">&quot;ro-en&quot;</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-24-7"><a id="__codelineno-24-7" name="__codelineno-24-7" href="#__codelineno-24-7"></a>--source_lang<span class="w"> </span>en<span class="w"> </span>--target_lang<span class="w"> </span>ro
</span></code></pre></div>
<p></hfoption>
<hfoption id="single-GPU"></p>
<p>단일 GPU에 DeepSpeed를 배포하려면 <code>--num_gpus</code> 매개변수를 추가하세요. GPU가 1개만 있는 경우 이 값을 명시적으로 설정할 필요는 없습니다. DeepSpeed는 지정된 노드에서 볼 수 있는 모든 GPU를 배포하므로 이 값을 명시적으로 설정할 필요는 없습니다.</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-25-1"><a id="__codelineno-25-1" name="__codelineno-25-1" href="#__codelineno-25-1"></a>deepspeed<span class="w"> </span>--num_gpus<span class="o">=</span><span class="m">1</span><span class="w"> </span>examples/pytorch/translation/run_translation.py<span class="w"> </span><span class="se">\</span>
</span><span id="__span-25-2"><a id="__codelineno-25-2" name="__codelineno-25-2" href="#__codelineno-25-2"></a>--deepspeed<span class="w"> </span>tests/deepspeed/ds_config_zero2.json<span class="w"> </span><span class="se">\</span>
</span><span id="__span-25-3"><a id="__codelineno-25-3" name="__codelineno-25-3" href="#__codelineno-25-3"></a>--model_name_or_path<span class="w"> </span>google-t5/t5-small<span class="w"> </span>--per_device_train_batch_size<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-25-4"><a id="__codelineno-25-4" name="__codelineno-25-4" href="#__codelineno-25-4"></a>--output_dir<span class="w"> </span>output_dir<span class="w"> </span>--fp16<span class="w"> </span><span class="se">\</span>
</span><span id="__span-25-5"><a id="__codelineno-25-5" name="__codelineno-25-5" href="#__codelineno-25-5"></a>--do_train<span class="w"> </span>--max_train_samples<span class="w"> </span><span class="m">500</span><span class="w"> </span>--num_train_epochs<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-25-6"><a id="__codelineno-25-6" name="__codelineno-25-6" href="#__codelineno-25-6"></a>--dataset_name<span class="w"> </span>wmt16<span class="w"> </span>--dataset_config<span class="w"> </span><span class="s2">&quot;ro-en&quot;</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-25-7"><a id="__codelineno-25-7" name="__codelineno-25-7" href="#__codelineno-25-7"></a>--source_lang<span class="w"> </span>en<span class="w"> </span>--target_lang<span class="w"> </span>ro
</span></code></pre></div>
<p>DeepSpeed는 단 하나의 GPU로도 여전히 유용합니다:</p>
<ol>
<li>일부 계산과 메모리를 CPU로 오프로드하여 더 큰 배치 크기를 사용하거나 일반적으로 맞지 않는 매우 큰 모델을 맞추기 위해 모델에 더 많은 GPU 리소스를 사용할 수 있도록 합니다.</li>
<li>스마트 GPU 메모리 관리 시스템으로 메모리 조각화를 최소화하여 더 큰 모델과 데이터 배치에 맞출 수 있습니다.</li>
</ol>
<p><Tip></p>
<p>단일 GPU에서 더 나은 성능을 얻으려면 <a href="#zero-configuration">ZeRO-2</a> 구성 파일에서 <code>allgather_bucket_size</code> 및 <code>reduce_bucket_size</code> 값을 2e8로 설정하세요.</p>
<p></Tip></p>
<p></hfoption>
</hfoptions></p>
<h3 id="multi-node-deployment">다중 노드 환경에서의 모델 배포[[multi-node-deployment]]</h3>
<p>노드는 워크로드를 실행하기 위한 하나 이상의 GPU입니다. 더 강력한 설정은 멀티 노드 설정으로, <code>deepspeed</code> 런처로 실행할 수 있습니다. 이 가이드에서는 각각 8개의 GPU가 있는 두 개의 노드가 있다고 가정해 보겠습니다. 첫 번째 노드는 <code>ssh hostname1</code>로, 두 번째 노드는 <code>ssh hostname2</code>로 접속할 수 있습니다. 두 노드 모두 비밀번호 없이 ssh를 통해 로컬로 서로 통신할 수 있어야 합니다.</p>
<p>기본적으로 DeepSpeed는 멀티노드 환경에서 공유 저장소를 사용할 것으로 예상합니다. 그렇지 않고 각 노드가 로컬 파일 시스템만 볼 수 있는 경우, 공유 파일 시스템에 대한 액세스 없이 로딩할 수 있도록 <a href="https://www.deepspeed.ai/docs/config-json/#checkpoint-options"><code>checkpoint</code></a>를 포함하도록 구성 파일을 조정해야 합니다:</p>
<div class="language-yaml highlight"><pre><span></span><code><span id="__span-26-1"><a id="__codelineno-26-1" name="__codelineno-26-1" href="#__codelineno-26-1"></a><span class="p p-Indicator">{</span>
</span><span id="__span-26-2"><a id="__codelineno-26-2" name="__codelineno-26-2" href="#__codelineno-26-2"></a><span class="w">  </span><span class="s">&quot;checkpoint&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="p p-Indicator">{</span>
</span><span id="__span-26-3"><a id="__codelineno-26-3" name="__codelineno-26-3" href="#__codelineno-26-3"></a><span class="w">    </span><span class="s">&quot;use_node_local_storage&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="nv">true</span>
</span><span id="__span-26-4"><a id="__codelineno-26-4" name="__codelineno-26-4" href="#__codelineno-26-4"></a><span class="w">  </span><span class="p p-Indicator">}</span>
</span><span id="__span-26-5"><a id="__codelineno-26-5" name="__codelineno-26-5" href="#__codelineno-26-5"></a><span class="p p-Indicator">}</span>
</span></code></pre></div>
<p>[<code>Trainer</code>]의 <code>`--save_on_each_node</code> 인수를 사용하여 위의 <code>checkpoint</code>를 구성에 자동으로 추가할 수도 있습니다.</p>
<p><hfoptions id="multinode">
<hfoption id="torchrun"></p>
<p><a href="https://pytorch.org/docs/stable/elastic/run.html">torchrun</a>의 경우, 각 노드에 ssh로 접속한 후 두 노드 모두에서 다음 명령을 실행해야 합니다. 런처는 두 노드가 동기화될 때까지 기다렸다가 트레이닝을 시작합니다.</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-27-1"><a id="__codelineno-27-1" name="__codelineno-27-1" href="#__codelineno-27-1"></a>torchrun<span class="w"> </span>--nproc_per_node<span class="o">=</span><span class="m">8</span><span class="w"> </span>--nnode<span class="o">=</span><span class="m">2</span><span class="w"> </span>--node_rank<span class="o">=</span><span class="m">0</span><span class="w"> </span>--master_addr<span class="o">=</span>hostname1<span class="w"> </span><span class="se">\</span>
</span><span id="__span-27-2"><a id="__codelineno-27-2" name="__codelineno-27-2" href="#__codelineno-27-2"></a>--master_port<span class="o">=</span><span class="m">9901</span><span class="w"> </span>your_program.py<span class="w"> </span>&lt;normal<span class="w"> </span>cl<span class="w"> </span>args&gt;<span class="w"> </span>--deepspeed<span class="w"> </span>ds_config.json
</span></code></pre></div>
<p></hfoption>
<hfoption id="deepspeed"></p>
<p><code>deepspeed</code> 런처의 경우, 먼저 <code>hostfile</code>을 생성합니다.</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-28-1"><a id="__codelineno-28-1" name="__codelineno-28-1" href="#__codelineno-28-1"></a>hostname1<span class="w"> </span><span class="nv">slots</span><span class="o">=</span><span class="m">8</span>
</span><span id="__span-28-2"><a id="__codelineno-28-2" name="__codelineno-28-2" href="#__codelineno-28-2"></a>hostname2<span class="w"> </span><span class="nv">slots</span><span class="o">=</span><span class="m">8</span>
</span></code></pre></div>
<p>그런 다음 다음 명령어로 트레이닝을 시작할 수 있습니다. <code>deepspeed</code> 런처는 두 노드에서 동시에 명령을 자동으로 실행합니다.</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-29-1"><a id="__codelineno-29-1" name="__codelineno-29-1" href="#__codelineno-29-1"></a>deepspeed<span class="w"> </span>--num_gpus<span class="w"> </span><span class="m">8</span><span class="w"> </span>--num_nodes<span class="w"> </span><span class="m">2</span><span class="w"> </span>--hostfile<span class="w"> </span>hostfile<span class="w"> </span>--master_addr<span class="w"> </span>hostname1<span class="w"> </span>--master_port<span class="o">=</span><span class="m">9901</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-29-2"><a id="__codelineno-29-2" name="__codelineno-29-2" href="#__codelineno-29-2"></a>your_program.py<span class="w"> </span>&lt;normal<span class="w"> </span>cl<span class="w"> </span>args&gt;<span class="w"> </span>--deepspeed<span class="w"> </span>ds_config.json
</span></code></pre></div>
<p>다중 노드 컴퓨팅 리소스 구성에 대한 자세한 내용은 <a href="https://www.deepspeed.ai/getting-started/#resource-configuration-multi-node">Resource Configuration (multi-node)</a> 가이드를 참조하세요.</p>
<p></hfoption>
</hfoptions></p>
<h3 id="slurmslurm">SLURM[[slurm]]</h3>
<p>SLURM 환경에서는 특정 SLURM 환경에 맞게 SLURM 스크립트를 조정해야 합니다.SLURM 스크립트 예시는 다음과 같습니다:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-30-1"><a id="__codelineno-30-1" name="__codelineno-30-1" href="#__codelineno-30-1"></a><span class="c1">#SBATCH --job-name=test-nodes        # 작업 이름</span>
</span><span id="__span-30-2"><a id="__codelineno-30-2" name="__codelineno-30-2" href="#__codelineno-30-2"></a><span class="c1">#SBATCH --nodes=2                    # 노드 수</span>
</span><span id="__span-30-3"><a id="__codelineno-30-3" name="__codelineno-30-3" href="#__codelineno-30-3"></a><span class="c1">#SBATCH --ntasks-per-node=1          # 중요 - 노드당 분산 작업 1개!</span>
</span><span id="__span-30-4"><a id="__codelineno-30-4" name="__codelineno-30-4" href="#__codelineno-30-4"></a><span class="c1">#SBATCH --cpus-per-task=10           # 작업당 CPU 코어 수</span>
</span><span id="__span-30-5"><a id="__codelineno-30-5" name="__codelineno-30-5" href="#__codelineno-30-5"></a><span class="c1">#SBATCH --gres=gpu:8                 # gpu 수</span>
</span><span id="__span-30-6"><a id="__codelineno-30-6" name="__codelineno-30-6" href="#__codelineno-30-6"></a><span class="c1">#SBATCH --time 20:00:00              # 최대 실행 시간 (HH:MM:SS)</span>
</span><span id="__span-30-7"><a id="__codelineno-30-7" name="__codelineno-30-7" href="#__codelineno-30-7"></a><span class="c1">#SBATCH --output=%x-%j.out           # 출력 파일 이름</span>
</span><span id="__span-30-8"><a id="__codelineno-30-8" name="__codelineno-30-8" href="#__codelineno-30-8"></a>
</span><span id="__span-30-9"><a id="__codelineno-30-9" name="__codelineno-30-9" href="#__codelineno-30-9"></a><span class="nb">export</span><span class="w"> </span><span class="nv">GPUS_PER_NODE</span><span class="o">=</span><span class="m">8</span>
</span><span id="__span-30-10"><a id="__codelineno-30-10" name="__codelineno-30-10" href="#__codelineno-30-10"></a><span class="nb">export</span><span class="w"> </span><span class="nv">MASTER_ADDR</span><span class="o">=</span><span class="k">$(</span>scontrol<span class="w"> </span>show<span class="w"> </span>hostnames<span class="w"> </span><span class="nv">$SLURM_JOB_NODELIST</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>head<span class="w"> </span>-n<span class="w"> </span><span class="m">1</span><span class="k">)</span>
</span><span id="__span-30-11"><a id="__codelineno-30-11" name="__codelineno-30-11" href="#__codelineno-30-11"></a><span class="nb">export</span><span class="w"> </span><span class="nv">MASTER_PORT</span><span class="o">=</span><span class="m">9901</span>
</span><span id="__span-30-12"><a id="__codelineno-30-12" name="__codelineno-30-12" href="#__codelineno-30-12"></a>
</span><span id="__span-30-13"><a id="__codelineno-30-13" name="__codelineno-30-13" href="#__codelineno-30-13"></a>srun<span class="w"> </span>--jobid<span class="w"> </span><span class="nv">$SLURM_JOBID</span><span class="w"> </span>bash<span class="w"> </span>-c<span class="w"> </span><span class="s1">&#39;python -m torch.distributed.run \</span>
</span><span id="__span-30-14"><a id="__codelineno-30-14" name="__codelineno-30-14" href="#__codelineno-30-14"></a><span class="s1"> --nproc_per_node $GPUS_PER_NODE --nnodes $SLURM_NNODES --node_rank $SLURM_PROCID \</span>
</span><span id="__span-30-15"><a id="__codelineno-30-15" name="__codelineno-30-15" href="#__codelineno-30-15"></a><span class="s1"> --master_addr $MASTER_ADDR --master_port $MASTER_PORT \</span>
</span><span id="__span-30-16"><a id="__codelineno-30-16" name="__codelineno-30-16" href="#__codelineno-30-16"></a><span class="s1">your_program.py &lt;normal cl args&gt; --deepspeed ds_config.json&#39;</span>
</span></code></pre></div>
<p>그런 다음 모든 노드에서 동시에 학습을 시작하는 다음 명령을 사용하여 다중 노드 배포를 예약할 수 있습니다.</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-31-1"><a id="__codelineno-31-1" name="__codelineno-31-1" href="#__codelineno-31-1"></a>sbatch<span class="w"> </span>launch.slurm
</span></code></pre></div>
<h3 id="notebook">노트북[[notebook]]</h3>
<p><code>deepspeed</code> 런처는 노트북에서의 배포를 지원하지 않으므로 분산 환경을 에뮬레이션해야 합니다. 하지만 이는 1개의 GPU에서만 작동합니다. 1개 이상의 GPU를 사용하려면 딥스피드가 작동할 수 있는 다중 프로세스 환경을 사용해야 합니다. 즉, 여기에 표시된 것처럼 에뮬레이션할 수 없는 <code>deepspeed</code> 런처를 사용해야 합니다.</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-32-1"><a id="__codelineno-32-1" name="__codelineno-32-1" href="#__codelineno-32-1"></a><span class="c1"># DeepSpeed는 단일 프로세스만 사용하더라도 분산 환경을 필요로 합니다.</span>
</span><span id="__span-32-2"><a id="__codelineno-32-2" name="__codelineno-32-2" href="#__codelineno-32-2"></a><span class="c1"># 이 코드로 분산 환경을 모방합니다.</span>
</span><span id="__span-32-3"><a id="__codelineno-32-3" name="__codelineno-32-3" href="#__codelineno-32-3"></a><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
</span><span id="__span-32-4"><a id="__codelineno-32-4" name="__codelineno-32-4" href="#__codelineno-32-4"></a>
</span><span id="__span-32-5"><a id="__codelineno-32-5" name="__codelineno-32-5" href="#__codelineno-32-5"></a><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;MASTER_ADDR&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;localhost&quot;</span>
</span><span id="__span-32-6"><a id="__codelineno-32-6" name="__codelineno-32-6" href="#__codelineno-32-6"></a><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;MASTER_PORT&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;9994&quot;</span>  <span class="c1"># RuntimeError: Address already in use 오류 발생 시 수정</span>
</span><span id="__span-32-7"><a id="__codelineno-32-7" name="__codelineno-32-7" href="#__codelineno-32-7"></a><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;RANK&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;0&quot;</span>
</span><span id="__span-32-8"><a id="__codelineno-32-8" name="__codelineno-32-8" href="#__codelineno-32-8"></a><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;LOCAL_RANK&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;0&quot;</span>
</span><span id="__span-32-9"><a id="__codelineno-32-9" name="__codelineno-32-9" href="#__codelineno-32-9"></a><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;WORLD_SIZE&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;1&quot;</span>
</span><span id="__span-32-10"><a id="__codelineno-32-10" name="__codelineno-32-10" href="#__codelineno-32-10"></a>
</span><span id="__span-32-11"><a id="__codelineno-32-11" name="__codelineno-32-11" href="#__codelineno-32-11"></a><span class="c1"># 이제 평소와 같이 진행하되, DeepSpeed 설정 파일을 전달합니다.</span>
</span><span id="__span-32-12"><a id="__codelineno-32-12" name="__codelineno-32-12" href="#__codelineno-32-12"></a><span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">deepspeed</span><span class="o">=</span><span class="s2">&quot;ds_config_zero3.json&quot;</span><span class="p">)</span>
</span><span id="__span-32-13"><a id="__codelineno-32-13" name="__codelineno-32-13" href="#__codelineno-32-13"></a><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
</span><span id="__span-32-14"><a id="__codelineno-32-14" name="__codelineno-32-14" href="#__codelineno-32-14"></a><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</span></code></pre></div>
<p>현재 디렉터리의 노트북에 구성 파일을 즉석에서 만들고 싶다면 전용 셀을 만들 수 있습니다.</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-33-1"><a id="__codelineno-33-1" name="__codelineno-33-1" href="#__codelineno-33-1"></a><span class="o">%%</span><span class="n">bash</span>
</span><span id="__span-33-2"><a id="__codelineno-33-2" name="__codelineno-33-2" href="#__codelineno-33-2"></a><span class="n">cat</span> <span class="o">&lt;&lt;</span><span class="s1">&#39;EOT&#39;</span> <span class="o">&gt;</span> <span class="n">ds_config_zero3</span><span class="o">.</span><span class="n">json</span>
</span><span id="__span-33-3"><a id="__codelineno-33-3" name="__codelineno-33-3" href="#__codelineno-33-3"></a><span class="p">{</span>
</span><span id="__span-33-4"><a id="__codelineno-33-4" name="__codelineno-33-4" href="#__codelineno-33-4"></a>    <span class="s2">&quot;fp16&quot;</span><span class="p">:</span> <span class="p">{</span>
</span><span id="__span-33-5"><a id="__codelineno-33-5" name="__codelineno-33-5" href="#__codelineno-33-5"></a>        <span class="s2">&quot;enabled&quot;</span><span class="p">:</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
</span><span id="__span-33-6"><a id="__codelineno-33-6" name="__codelineno-33-6" href="#__codelineno-33-6"></a>        <span class="s2">&quot;loss_scale&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="__span-33-7"><a id="__codelineno-33-7" name="__codelineno-33-7" href="#__codelineno-33-7"></a>        <span class="s2">&quot;loss_scale_window&quot;</span><span class="p">:</span> <span class="mi">1000</span><span class="p">,</span>
</span><span id="__span-33-8"><a id="__codelineno-33-8" name="__codelineno-33-8" href="#__codelineno-33-8"></a>        <span class="s2">&quot;initial_scale_power&quot;</span><span class="p">:</span> <span class="mi">16</span><span class="p">,</span>
</span><span id="__span-33-9"><a id="__codelineno-33-9" name="__codelineno-33-9" href="#__codelineno-33-9"></a>        <span class="s2">&quot;hysteresis&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
</span><span id="__span-33-10"><a id="__codelineno-33-10" name="__codelineno-33-10" href="#__codelineno-33-10"></a>        <span class="s2">&quot;min_loss_scale&quot;</span><span class="p">:</span> <span class="mi">1</span>
</span><span id="__span-33-11"><a id="__codelineno-33-11" name="__codelineno-33-11" href="#__codelineno-33-11"></a>    <span class="p">},</span>
</span><span id="__span-33-12"><a id="__codelineno-33-12" name="__codelineno-33-12" href="#__codelineno-33-12"></a>
</span><span id="__span-33-13"><a id="__codelineno-33-13" name="__codelineno-33-13" href="#__codelineno-33-13"></a>    <span class="s2">&quot;optimizer&quot;</span><span class="p">:</span> <span class="p">{</span>
</span><span id="__span-33-14"><a id="__codelineno-33-14" name="__codelineno-33-14" href="#__codelineno-33-14"></a>        <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;AdamW&quot;</span><span class="p">,</span>
</span><span id="__span-33-15"><a id="__codelineno-33-15" name="__codelineno-33-15" href="#__codelineno-33-15"></a>        <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{</span>
</span><span id="__span-33-16"><a id="__codelineno-33-16" name="__codelineno-33-16" href="#__codelineno-33-16"></a>            <span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
</span><span id="__span-33-17"><a id="__codelineno-33-17" name="__codelineno-33-17" href="#__codelineno-33-17"></a>            <span class="s2">&quot;betas&quot;</span><span class="p">:</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
</span><span id="__span-33-18"><a id="__codelineno-33-18" name="__codelineno-33-18" href="#__codelineno-33-18"></a>            <span class="s2">&quot;eps&quot;</span><span class="p">:</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
</span><span id="__span-33-19"><a id="__codelineno-33-19" name="__codelineno-33-19" href="#__codelineno-33-19"></a>            <span class="s2">&quot;weight_decay&quot;</span><span class="p">:</span> <span class="s2">&quot;auto&quot;</span>
</span><span id="__span-33-20"><a id="__codelineno-33-20" name="__codelineno-33-20" href="#__codelineno-33-20"></a>        <span class="p">}</span>
</span><span id="__span-33-21"><a id="__codelineno-33-21" name="__codelineno-33-21" href="#__codelineno-33-21"></a>    <span class="p">},</span>
</span><span id="__span-33-22"><a id="__codelineno-33-22" name="__codelineno-33-22" href="#__codelineno-33-22"></a>
</span><span id="__span-33-23"><a id="__codelineno-33-23" name="__codelineno-33-23" href="#__codelineno-33-23"></a>    <span class="s2">&quot;scheduler&quot;</span><span class="p">:</span> <span class="p">{</span>
</span><span id="__span-33-24"><a id="__codelineno-33-24" name="__codelineno-33-24" href="#__codelineno-33-24"></a>        <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;WarmupLR&quot;</span><span class="p">,</span>
</span><span id="__span-33-25"><a id="__codelineno-33-25" name="__codelineno-33-25" href="#__codelineno-33-25"></a>        <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{</span>
</span><span id="__span-33-26"><a id="__codelineno-33-26" name="__codelineno-33-26" href="#__codelineno-33-26"></a>            <span class="s2">&quot;warmup_min_lr&quot;</span><span class="p">:</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
</span><span id="__span-33-27"><a id="__codelineno-33-27" name="__codelineno-33-27" href="#__codelineno-33-27"></a>            <span class="s2">&quot;warmup_max_lr&quot;</span><span class="p">:</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
</span><span id="__span-33-28"><a id="__codelineno-33-28" name="__codelineno-33-28" href="#__codelineno-33-28"></a>            <span class="s2">&quot;warmup_num_steps&quot;</span><span class="p">:</span> <span class="s2">&quot;auto&quot;</span>
</span><span id="__span-33-29"><a id="__codelineno-33-29" name="__codelineno-33-29" href="#__codelineno-33-29"></a>        <span class="p">}</span>
</span><span id="__span-33-30"><a id="__codelineno-33-30" name="__codelineno-33-30" href="#__codelineno-33-30"></a>    <span class="p">},</span>
</span><span id="__span-33-31"><a id="__codelineno-33-31" name="__codelineno-33-31" href="#__codelineno-33-31"></a>
</span><span id="__span-33-32"><a id="__codelineno-33-32" name="__codelineno-33-32" href="#__codelineno-33-32"></a>    <span class="s2">&quot;zero_optimization&quot;</span><span class="p">:</span> <span class="p">{</span>
</span><span id="__span-33-33"><a id="__codelineno-33-33" name="__codelineno-33-33" href="#__codelineno-33-33"></a>        <span class="s2">&quot;stage&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
</span><span id="__span-33-34"><a id="__codelineno-33-34" name="__codelineno-33-34" href="#__codelineno-33-34"></a>        <span class="s2">&quot;offload_optimizer&quot;</span><span class="p">:</span> <span class="p">{</span>
</span><span id="__span-33-35"><a id="__codelineno-33-35" name="__codelineno-33-35" href="#__codelineno-33-35"></a>            <span class="s2">&quot;device&quot;</span><span class="p">:</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
</span><span id="__span-33-36"><a id="__codelineno-33-36" name="__codelineno-33-36" href="#__codelineno-33-36"></a>            <span class="s2">&quot;pin_memory&quot;</span><span class="p">:</span> <span class="n">true</span>
</span><span id="__span-33-37"><a id="__codelineno-33-37" name="__codelineno-33-37" href="#__codelineno-33-37"></a>        <span class="p">},</span>
</span><span id="__span-33-38"><a id="__codelineno-33-38" name="__codelineno-33-38" href="#__codelineno-33-38"></a>        <span class="s2">&quot;offload_param&quot;</span><span class="p">:</span> <span class="p">{</span>
</span><span id="__span-33-39"><a id="__codelineno-33-39" name="__codelineno-33-39" href="#__codelineno-33-39"></a>            <span class="s2">&quot;device&quot;</span><span class="p">:</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
</span><span id="__span-33-40"><a id="__codelineno-33-40" name="__codelineno-33-40" href="#__codelineno-33-40"></a>            <span class="s2">&quot;pin_memory&quot;</span><span class="p">:</span> <span class="n">true</span>
</span><span id="__span-33-41"><a id="__codelineno-33-41" name="__codelineno-33-41" href="#__codelineno-33-41"></a>        <span class="p">},</span>
</span><span id="__span-33-42"><a id="__codelineno-33-42" name="__codelineno-33-42" href="#__codelineno-33-42"></a>        <span class="s2">&quot;overlap_comm&quot;</span><span class="p">:</span> <span class="n">true</span><span class="p">,</span>
</span><span id="__span-33-43"><a id="__codelineno-33-43" name="__codelineno-33-43" href="#__codelineno-33-43"></a>        <span class="s2">&quot;contiguous_gradients&quot;</span><span class="p">:</span> <span class="n">true</span><span class="p">,</span>
</span><span id="__span-33-44"><a id="__codelineno-33-44" name="__codelineno-33-44" href="#__codelineno-33-44"></a>        <span class="s2">&quot;sub_group_size&quot;</span><span class="p">:</span> <span class="mf">1e9</span><span class="p">,</span>
</span><span id="__span-33-45"><a id="__codelineno-33-45" name="__codelineno-33-45" href="#__codelineno-33-45"></a>        <span class="s2">&quot;reduce_bucket_size&quot;</span><span class="p">:</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
</span><span id="__span-33-46"><a id="__codelineno-33-46" name="__codelineno-33-46" href="#__codelineno-33-46"></a>        <span class="s2">&quot;stage3_prefetch_bucket_size&quot;</span><span class="p">:</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
</span><span id="__span-33-47"><a id="__codelineno-33-47" name="__codelineno-33-47" href="#__codelineno-33-47"></a>        <span class="s2">&quot;stage3_param_persistence_threshold&quot;</span><span class="p">:</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
</span><span id="__span-33-48"><a id="__codelineno-33-48" name="__codelineno-33-48" href="#__codelineno-33-48"></a>        <span class="s2">&quot;stage3_max_live_parameters&quot;</span><span class="p">:</span> <span class="mf">1e9</span><span class="p">,</span>
</span><span id="__span-33-49"><a id="__codelineno-33-49" name="__codelineno-33-49" href="#__codelineno-33-49"></a>        <span class="s2">&quot;stage3_max_reuse_distance&quot;</span><span class="p">:</span> <span class="mf">1e9</span><span class="p">,</span>
</span><span id="__span-33-50"><a id="__codelineno-33-50" name="__codelineno-33-50" href="#__codelineno-33-50"></a>        <span class="s2">&quot;stage3_gather_16bit_weights_on_model_save&quot;</span><span class="p">:</span> <span class="n">true</span>
</span><span id="__span-33-51"><a id="__codelineno-33-51" name="__codelineno-33-51" href="#__codelineno-33-51"></a>    <span class="p">},</span>
</span><span id="__span-33-52"><a id="__codelineno-33-52" name="__codelineno-33-52" href="#__codelineno-33-52"></a>
</span><span id="__span-33-53"><a id="__codelineno-33-53" name="__codelineno-33-53" href="#__codelineno-33-53"></a>    <span class="s2">&quot;gradient_accumulation_steps&quot;</span><span class="p">:</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
</span><span id="__span-33-54"><a id="__codelineno-33-54" name="__codelineno-33-54" href="#__codelineno-33-54"></a>    <span class="s2">&quot;gradient_clipping&quot;</span><span class="p">:</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
</span><span id="__span-33-55"><a id="__codelineno-33-55" name="__codelineno-33-55" href="#__codelineno-33-55"></a>    <span class="s2">&quot;steps_per_print&quot;</span><span class="p">:</span> <span class="mi">2000</span><span class="p">,</span>
</span><span id="__span-33-56"><a id="__codelineno-33-56" name="__codelineno-33-56" href="#__codelineno-33-56"></a>    <span class="s2">&quot;train_batch_size&quot;</span><span class="p">:</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
</span><span id="__span-33-57"><a id="__codelineno-33-57" name="__codelineno-33-57" href="#__codelineno-33-57"></a>    <span class="s2">&quot;train_micro_batch_size_per_gpu&quot;</span><span class="p">:</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
</span><span id="__span-33-58"><a id="__codelineno-33-58" name="__codelineno-33-58" href="#__codelineno-33-58"></a>    <span class="s2">&quot;wall_clock_breakdown&quot;</span><span class="p">:</span> <span class="n">false</span>
</span><span id="__span-33-59"><a id="__codelineno-33-59" name="__codelineno-33-59" href="#__codelineno-33-59"></a><span class="p">}</span>
</span><span id="__span-33-60"><a id="__codelineno-33-60" name="__codelineno-33-60" href="#__codelineno-33-60"></a><span class="n">EOT</span>
</span></code></pre></div>
<p>트레이닝 스크립트가 노트북 셀이 아닌 파일에 있는 경우, 노트북 셀의 셸에서 <code>deepspeed</code>를 정상적으로 실행할 수 있습니다. 예를 들어 <code>run_translation.py</code>를 시작하려면 다음과 같이 하세요.:</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-34-1"><a id="__codelineno-34-1" name="__codelineno-34-1" href="#__codelineno-34-1"></a><span class="err">!</span><span class="n">git</span> <span class="n">clone</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">huggingface</span><span class="o">/</span><span class="n">transformers</span>
</span><span id="__span-34-2"><a id="__codelineno-34-2" name="__codelineno-34-2" href="#__codelineno-34-2"></a><span class="err">!</span><span class="n">cd</span> <span class="n">transformers</span><span class="p">;</span> <span class="n">deepspeed</span> <span class="n">examples</span><span class="o">/</span><span class="n">pytorch</span><span class="o">/</span><span class="n">translation</span><span class="o">/</span><span class="n">run_translation</span><span class="o">.</span><span class="n">py</span> <span class="o">...</span>
</span></code></pre></div>
<p>또한 <code>%%bash</code> 매직을 사용하여 여러 줄의 코드를 작성하여 셸 프로그램을 실행할 수도 있지만 교육이 완료될 때까지 로그를 볼 수 없습니다. <code>%%bash</code> 매직으로 분산 환경을 에뮬레이션할 필요는 없습니다.</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-35-1"><a id="__codelineno-35-1" name="__codelineno-35-1" href="#__codelineno-35-1"></a><span class="o">%%</span><span class="n">bash</span>
</span><span id="__span-35-2"><a id="__codelineno-35-2" name="__codelineno-35-2" href="#__codelineno-35-2"></a>
</span><span id="__span-35-3"><a id="__codelineno-35-3" name="__codelineno-35-3" href="#__codelineno-35-3"></a><span class="n">git</span> <span class="n">clone</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">huggingface</span><span class="o">/</span><span class="n">transformers</span>
</span><span id="__span-35-4"><a id="__codelineno-35-4" name="__codelineno-35-4" href="#__codelineno-35-4"></a><span class="n">cd</span> <span class="n">transformers</span>
</span><span id="__span-35-5"><a id="__codelineno-35-5" name="__codelineno-35-5" href="#__codelineno-35-5"></a><span class="n">deepspeed</span> <span class="n">examples</span><span class="o">/</span><span class="n">pytorch</span><span class="o">/</span><span class="n">translation</span><span class="o">/</span><span class="n">run_translation</span><span class="o">.</span><span class="n">py</span> <span class="o">...</span>
</span></code></pre></div>
<h2 id="save-model-weights">모델 가중치 저장하기[[save-model-weights]]</h2>
<p>딥스피드는 기본 고정밀 fp32 가중치를 사용자 지정 체크포인트 최적화 파일(glob 패턴은 <code>global_step*/*optim_states.pt</code>처럼 보입니다)에 저장하고 일반 체크포인트 아래에 저장합니다.</p>
<p><hfoptions id="save">
<hfoption id="fp16"></p>
<p>ZeRO-2로 훈련된 모델은 pytorch_model.bin 가중치를 fp16에 저장합니다. ZeRO-3으로 훈련된 모델의 모델 가중치를 fp16에 저장하려면 모델 가중치가 여러 GPU에 분할되어 있으므로 <code>“stage3_gather_16bit_weights_on_model_save”: true</code>를 설정해야 합니다. 그렇지 않으면 [<code>Trainer</code>]가 가중치를 fp16에 저장하지 않고 pytorch_model.bin 파일을 생성하지 않습니다. 이는 DeepSpeed의 state_dict에 실제 가중치 대신 플레이스홀더가 포함되어 있어 이를 로드할 수 없기 때문입니다.</p>
<div class="language-yaml highlight"><pre><span></span><code><span id="__span-36-1"><a id="__codelineno-36-1" name="__codelineno-36-1" href="#__codelineno-36-1"></a><span class="p p-Indicator">{</span>
</span><span id="__span-36-2"><a id="__codelineno-36-2" name="__codelineno-36-2" href="#__codelineno-36-2"></a><span class="w">    </span><span class="s">&quot;zero_optimization&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="p p-Indicator">{</span>
</span><span id="__span-36-3"><a id="__codelineno-36-3" name="__codelineno-36-3" href="#__codelineno-36-3"></a><span class="w">        </span><span class="s">&quot;stage3_gather_16bit_weights_on_model_save&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="nv">true</span>
</span><span id="__span-36-4"><a id="__codelineno-36-4" name="__codelineno-36-4" href="#__codelineno-36-4"></a><span class="w">    </span><span class="p p-Indicator">}</span>
</span><span id="__span-36-5"><a id="__codelineno-36-5" name="__codelineno-36-5" href="#__codelineno-36-5"></a><span class="p p-Indicator">}</span>
</span></code></pre></div>
<p></hfoption>
<hfoption id="fp32"></p>
<p>전체 정밀 가중치는 많은 메모리가 필요할 수 있으므로 트레이닝 중에 저장해서는 안 됩니다. 일반적으로 훈련이 완료된 후 오프라인으로 fp32 가중치를 저장하는 것이 가장 좋습니다. 그러나 여유 CPU 메모리가 많은 경우 훈련 중에 fp32 가중치를 저장할 수 있습니다. 이 섹션에서는 온라인과 오프라인 방식을 모두 다룹니다.</p>
<h3 id="online">온라인 환경[[online]]</h3>
<p>다음과 같이 최신 체크포인트를 로드하려면 체크포인트를 하나 이상 저장해야 합니다:</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-37-1"><a id="__codelineno-37-1" name="__codelineno-37-1" href="#__codelineno-37-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">transformers.trainer_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_last_checkpoint</span>
</span><span id="__span-37-2"><a id="__codelineno-37-2" name="__codelineno-37-2" href="#__codelineno-37-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">deepspeed.utils.zero_to_fp32</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_state_dict_from_zero_checkpoint</span>
</span><span id="__span-37-3"><a id="__codelineno-37-3" name="__codelineno-37-3" href="#__codelineno-37-3"></a>
</span><span id="__span-37-4"><a id="__codelineno-37-4" name="__codelineno-37-4" href="#__codelineno-37-4"></a><span class="n">checkpoint_dir</span> <span class="o">=</span> <span class="n">get_last_checkpoint</span><span class="p">(</span><span class="n">trainer</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">output_dir</span><span class="p">)</span>
</span><span id="__span-37-5"><a id="__codelineno-37-5" name="__codelineno-37-5" href="#__codelineno-37-5"></a><span class="n">fp32_model</span> <span class="o">=</span> <span class="n">load_state_dict_from_zero_checkpoint</span><span class="p">(</span><span class="n">trainer</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">checkpoint_dir</span><span class="p">)</span>
</span></code></pre></div>
<p><code>--load_best_model_at_end</code> 매개변수를 활성화하여 [<code>TrainingArguments</code>]에서 최적의 체크포인트를 추적하는 경우, 먼저 학습을 완료하고 최종 모델을 명시적으로 저장할 수 있습니다. 그런 다음 아래와 같이 다시 로드할 수 있습니다:</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-38-1"><a id="__codelineno-38-1" name="__codelineno-38-1" href="#__codelineno-38-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">deepspeed.utils.zero_to_fp32</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_state_dict_from_zero_checkpoint</span>
</span><span id="__span-38-2"><a id="__codelineno-38-2" name="__codelineno-38-2" href="#__codelineno-38-2"></a>
</span><span id="__span-38-3"><a id="__codelineno-38-3" name="__codelineno-38-3" href="#__codelineno-38-3"></a><span class="n">checkpoint_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">trainer</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">output_dir</span><span class="p">,</span> <span class="s2">&quot;checkpoint-final&quot;</span><span class="p">)</span>
</span><span id="__span-38-4"><a id="__codelineno-38-4" name="__codelineno-38-4" href="#__codelineno-38-4"></a><span class="n">trainer</span><span class="o">.</span><span class="n">deepspeed</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">)</span>
</span><span id="__span-38-5"><a id="__codelineno-38-5" name="__codelineno-38-5" href="#__codelineno-38-5"></a><span class="n">fp32_model</span> <span class="o">=</span> <span class="n">load_state_dict_from_zero_checkpoint</span><span class="p">(</span><span class="n">trainer</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">checkpoint_dir</span><span class="p">)</span>
</span></code></pre></div>
<p><Tip></p>
<p><code>load_state_dict_from_zero_checkpoint</code>가 실행되면 동일한 애플리케이션의 컨텍스트에서 모델을 더 이상 DeepSpeed에서 사용할 수 없습니다. <code>model.load_state_dict(state_dict)</code>는 모든 딥스피드 마법을 제거하므로 딥스피드 엔진을 다시 초기화해야 합니다. 이 기능은 훈련이 끝날 때만 사용하세요.</p>
<p></Tip></p>
<p>fp32 가중치의 state_dict를 추출하여 로드할 수도 있습니다:</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-39-1"><a id="__codelineno-39-1" name="__codelineno-39-1" href="#__codelineno-39-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">deepspeed.utils.zero_to_fp32</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_fp32_state_dict_from_zero_checkpoint</span>
</span><span id="__span-39-2"><a id="__codelineno-39-2" name="__codelineno-39-2" href="#__codelineno-39-2"></a>
</span><span id="__span-39-3"><a id="__codelineno-39-3" name="__codelineno-39-3" href="#__codelineno-39-3"></a><span class="n">state_dict</span> <span class="o">=</span> <span class="n">get_fp32_state_dict_from_zero_checkpoint</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">)</span>  <span class="c1"># cpu에 이미 존재함</span>
</span><span id="__span-39-4"><a id="__codelineno-39-4" name="__codelineno-39-4" href="#__codelineno-39-4"></a><span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
</span><span id="__span-39-5"><a id="__codelineno-39-5" name="__codelineno-39-5" href="#__codelineno-39-5"></a><span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span>
</span></code></pre></div>
<h3 id="offline">오프라인 환경[[offline]]</h3>
<p>DeepSpeed는 언제든지 가중치를 추출할 수 있도록 체크포인트 폴더의 최상위 레벨에 zero_to_fp32.py 스크립트를 제공합니다. 이 스크립트는 독립형 스크립트로 구성 파일이나 [<code>Trainer</code>]가 필요하지 않습니다.</p>
<p>예를 들어 체크포인트 폴더가 다음과 같은 경우입니다:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-40-1"><a id="__codelineno-40-1" name="__codelineno-40-1" href="#__codelineno-40-1"></a>$<span class="w"> </span>ls<span class="w"> </span>-l<span class="w"> </span>output_dir/checkpoint-1/
</span><span id="__span-40-2"><a id="__codelineno-40-2" name="__codelineno-40-2" href="#__codelineno-40-2"></a>-rw-rw-r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>stas<span class="w"> </span>stas<span class="w"> </span><span class="m">1</span>.4K<span class="w"> </span>Mar<span class="w"> </span><span class="m">27</span><span class="w"> </span><span class="m">20</span>:42<span class="w"> </span>config.json
</span><span id="__span-40-3"><a id="__codelineno-40-3" name="__codelineno-40-3" href="#__codelineno-40-3"></a>drwxrwxr-x<span class="w"> </span><span class="m">2</span><span class="w"> </span>stas<span class="w"> </span>stas<span class="w"> </span><span class="m">4</span>.0K<span class="w"> </span>Mar<span class="w"> </span><span class="m">25</span><span class="w"> </span><span class="m">19</span>:52<span class="w"> </span>global_step1/
</span><span id="__span-40-4"><a id="__codelineno-40-4" name="__codelineno-40-4" href="#__codelineno-40-4"></a>-rw-rw-r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>stas<span class="w"> </span>stas<span class="w">   </span><span class="m">12</span><span class="w"> </span>Mar<span class="w"> </span><span class="m">27</span><span class="w"> </span><span class="m">13</span>:16<span class="w"> </span>latest
</span><span id="__span-40-5"><a id="__codelineno-40-5" name="__codelineno-40-5" href="#__codelineno-40-5"></a>-rw-rw-r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>stas<span class="w"> </span>stas<span class="w"> </span>827K<span class="w"> </span>Mar<span class="w"> </span><span class="m">27</span><span class="w"> </span><span class="m">20</span>:42<span class="w"> </span>optimizer.pt
</span><span id="__span-40-6"><a id="__codelineno-40-6" name="__codelineno-40-6" href="#__codelineno-40-6"></a>-rw-rw-r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>stas<span class="w"> </span>stas<span class="w"> </span>231M<span class="w"> </span>Mar<span class="w"> </span><span class="m">27</span><span class="w"> </span><span class="m">20</span>:42<span class="w"> </span>pytorch_model.bin
</span><span id="__span-40-7"><a id="__codelineno-40-7" name="__codelineno-40-7" href="#__codelineno-40-7"></a>-rw-rw-r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>stas<span class="w"> </span>stas<span class="w">  </span><span class="m">623</span><span class="w"> </span>Mar<span class="w"> </span><span class="m">27</span><span class="w"> </span><span class="m">20</span>:42<span class="w"> </span>scheduler.pt
</span><span id="__span-40-8"><a id="__codelineno-40-8" name="__codelineno-40-8" href="#__codelineno-40-8"></a>-rw-rw-r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>stas<span class="w"> </span>stas<span class="w"> </span><span class="m">1</span>.8K<span class="w"> </span>Mar<span class="w"> </span><span class="m">27</span><span class="w"> </span><span class="m">20</span>:42<span class="w"> </span>special_tokens_map.json
</span><span id="__span-40-9"><a id="__codelineno-40-9" name="__codelineno-40-9" href="#__codelineno-40-9"></a>-rw-rw-r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>stas<span class="w"> </span>stas<span class="w"> </span>774K<span class="w"> </span>Mar<span class="w"> </span><span class="m">27</span><span class="w"> </span><span class="m">20</span>:42<span class="w"> </span>spiece.model
</span><span id="__span-40-10"><a id="__codelineno-40-10" name="__codelineno-40-10" href="#__codelineno-40-10"></a>-rw-rw-r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>stas<span class="w"> </span>stas<span class="w"> </span><span class="m">1</span>.9K<span class="w"> </span>Mar<span class="w"> </span><span class="m">27</span><span class="w"> </span><span class="m">20</span>:42<span class="w"> </span>tokenizer_config.json
</span><span id="__span-40-11"><a id="__codelineno-40-11" name="__codelineno-40-11" href="#__codelineno-40-11"></a>-rw-rw-r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>stas<span class="w"> </span>stas<span class="w">  </span><span class="m">339</span><span class="w"> </span>Mar<span class="w"> </span><span class="m">27</span><span class="w"> </span><span class="m">20</span>:42<span class="w"> </span>trainer_state.json
</span><span id="__span-40-12"><a id="__codelineno-40-12" name="__codelineno-40-12" href="#__codelineno-40-12"></a>-rw-rw-r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>stas<span class="w"> </span>stas<span class="w"> </span><span class="m">2</span>.3K<span class="w"> </span>Mar<span class="w"> </span><span class="m">27</span><span class="w"> </span><span class="m">20</span>:42<span class="w"> </span>training_args.bin
</span><span id="__span-40-13"><a id="__codelineno-40-13" name="__codelineno-40-13" href="#__codelineno-40-13"></a>-rwxrw-r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>stas<span class="w"> </span>stas<span class="w"> </span><span class="m">5</span>.5K<span class="w"> </span>Mar<span class="w"> </span><span class="m">27</span><span class="w"> </span><span class="m">13</span>:16<span class="w"> </span>zero_to_fp32.py*
</span></code></pre></div>
<p>딥스피드 체크포인트(ZeRO-2 또는 ZeRO-3) 하위 폴더 <code>global_step1</code>에서 fp32 가중치를 재구성하려면 다음 명령을 실행하여 여러 GPU의 전체 fp32 가중치를 단일 pytorch_model.bin 파일로 생성하고 통합합니다. 스크립트는 자동으로 체크포인트가 포함된 하위 폴더를 찾습니다.</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-41-1"><a id="__codelineno-41-1" name="__codelineno-41-1" href="#__codelineno-41-1"></a><span class="n">python</span> <span class="n">zero_to_fp32</span><span class="o">.</span><span class="n">py</span> <span class="o">.</span> <span class="n">pytorch_model</span><span class="o">.</span><span class="n">bin</span>
</span></code></pre></div>
<p><Tip></p>
<p>자세한 사용법은 <code>python zero_to_fp32.py -h</code>를 실행하세요. 이 스크립트에는 최종 fp32 가중치의 2배의 일반 RAM이 필요합니다.</p>
<p></Tip></p>
<p></hfoption>
</hfoptions></p>
<h2 id="zero-inferencezero-inference">ZeRO Inference[[zero-inference]]</h2>
<p><a href="https://www.deepspeed.ai/2022/09/09/zero-inference.html">ZeRO Inference</a>는 모델 가중치를 CPU 또는 NVMe 메모리에 배치하여 GPU에 부담을 주지 않으므로 GPU에서 대규모 모델을 사용하여 추론을 실행할 수 있습니다. 추론은 최적화 상태 및 그레이디언트에 많은 양의 메모리를 추가로 필요로 하지 않으므로 동일한 하드웨어에 훨씬 더 큰 배치 및/또는 시퀀스 길이를 맞출 수 있습니다.</p>
<p>ZeRO Inference는 <a href="#zero-configuration">ZeRO-3</a>와 동일한 구성 파일을 공유하며, ZeRO-2 및 ZeRO-1 구성은 추론에 아무런 이점을 제공하지 않으므로 작동하지 않습니다.</p>
<p>ZeRO Inference를 실행하려면 일반적인 훈련 인수를 [<code>TrainingArguments</code>] 클래스에 전달하고 <code>--do_eval</code> 인수를 추가합니다.</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-42-1"><a id="__codelineno-42-1" name="__codelineno-42-1" href="#__codelineno-42-1"></a>deepspeed<span class="w"> </span>--num_gpus<span class="o">=</span><span class="m">2</span><span class="w"> </span>your_program.py<span class="w"> </span>&lt;normal<span class="w"> </span>cl<span class="w"> </span>args&gt;<span class="w"> </span>--do_eval<span class="w"> </span>--deepspeed<span class="w"> </span>ds_config.json
</span></code></pre></div>
<h2 id="trainer-deepspeed-non-trainer-deepspeed-integration">Trainer 없이 DeepSpeed 사용하기[[non-trainer-deepspeed-integration]]</h2>
<p>DeepSpeed는 [<code>Trainer</code>] 클래스가 없는 트랜스포머에서도 작동합니다. 이는 [<code>~PreTrainedModel.from_pretrained</code>]를 호출할 때 ZeRO-3 매개변수를 수집하고 모델을 여러 GPU에 분할하는 작업만 처리하는 [<code>HfDeepSpeedConfig</code>]가 처리합니다.</p>
<p><Tip></p>
<p>모든 것이 자동으로 처리되기를 원한다면, [<code>Trainer</code>]와 함께 DeepSpeed를 사용해 보세요! <a href="https://www.deepspeed.ai/">DeepSpeed 문서</a>를 참조하여 설정 파일에서 매개변수 값을 수동으로 구성해야 합니다(<code>"auto"</code> 값은 사용할 수 없음).</p>
<p></Tip></p>
<p>ZeRO-3를 효율적으로 배포하려면 모델 앞에 [<code>HfDeepSpeedConfig</code>] 객체를 인스턴스화하고 해당 객체를 유지해야 합니다:</p>
<p><hfoptions id="models">
<hfoption id="pretrained model"></p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-43-1"><a id="__codelineno-43-1" name="__codelineno-43-1" href="#__codelineno-43-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">transformers.integrations</span><span class="w"> </span><span class="kn">import</span> <span class="n">HfDeepSpeedConfig</span>
</span><span id="__span-43-2"><a id="__codelineno-43-2" name="__codelineno-43-2" href="#__codelineno-43-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModel</span>
</span><span id="__span-43-3"><a id="__codelineno-43-3" name="__codelineno-43-3" href="#__codelineno-43-3"></a><span class="kn">import</span><span class="w"> </span><span class="nn">deepspeed</span>
</span><span id="__span-43-4"><a id="__codelineno-43-4" name="__codelineno-43-4" href="#__codelineno-43-4"></a>
</span><span id="__span-43-5"><a id="__codelineno-43-5" name="__codelineno-43-5" href="#__codelineno-43-5"></a><span class="n">ds_config</span> <span class="o">=</span> <span class="p">{</span><span class="o">...</span><span class="p">}</span>  <span class="c1"># deepspeed 설정 객체 또는 파일 경로</span>
</span><span id="__span-43-6"><a id="__codelineno-43-6" name="__codelineno-43-6" href="#__codelineno-43-6"></a><span class="c1"># Zero 3를 감지하기 위해 모델을 인스턴스화하기 전에 반드시 실행해야 합니다</span>
</span><span id="__span-43-7"><a id="__codelineno-43-7" name="__codelineno-43-7" href="#__codelineno-43-7"></a><span class="n">dschf</span> <span class="o">=</span> <span class="n">HfDeepSpeedConfig</span><span class="p">(</span><span class="n">ds_config</span><span class="p">)</span>  <span class="c1"># 이 객체를 유지하세요.</span>
</span><span id="__span-43-8"><a id="__codelineno-43-8" name="__codelineno-43-8" href="#__codelineno-43-8"></a><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;openai-community/gpt2&quot;</span><span class="p">)</span>
</span><span id="__span-43-9"><a id="__codelineno-43-9" name="__codelineno-43-9" href="#__codelineno-43-9"></a><span class="n">engine</span> <span class="o">=</span> <span class="n">deepspeed</span><span class="o">.</span><span class="n">initialize</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">config_params</span><span class="o">=</span><span class="n">ds_config</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
</span></code></pre></div>
<p></hfoption>
<hfoption id="non-pretrained model"></p>
<p>[<code>HfDeepSpeedConfig</code>] is not required for ZeRO-1 or ZeRO-2.</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-44-1"><a id="__codelineno-44-1" name="__codelineno-44-1" href="#__codelineno-44-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">transformers.integrations</span><span class="w"> </span><span class="kn">import</span> <span class="n">HfDeepSpeedConfig</span>
</span><span id="__span-44-2"><a id="__codelineno-44-2" name="__codelineno-44-2" href="#__codelineno-44-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModel</span><span class="p">,</span> <span class="n">AutoConfig</span>
</span><span id="__span-44-3"><a id="__codelineno-44-3" name="__codelineno-44-3" href="#__codelineno-44-3"></a><span class="kn">import</span><span class="w"> </span><span class="nn">deepspeed</span>
</span><span id="__span-44-4"><a id="__codelineno-44-4" name="__codelineno-44-4" href="#__codelineno-44-4"></a>
</span><span id="__span-44-5"><a id="__codelineno-44-5" name="__codelineno-44-5" href="#__codelineno-44-5"></a><span class="n">ds_config</span> <span class="o">=</span> <span class="p">{</span><span class="o">...</span><span class="p">}</span>  <span class="c1"># deepspeed 설정 객체 또는 파일 경로</span>
</span><span id="__span-44-6"><a id="__codelineno-44-6" name="__codelineno-44-6" href="#__codelineno-44-6"></a><span class="c1"># Zero 3를 감지하기 위해 모델을 인스턴스화하기 전에 반드시 실행해야 합니다</span>
</span><span id="__span-44-7"><a id="__codelineno-44-7" name="__codelineno-44-7" href="#__codelineno-44-7"></a><span class="n">dschf</span> <span class="o">=</span> <span class="n">HfDeepSpeedConfig</span><span class="p">(</span><span class="n">ds_config</span><span class="p">)</span>  <span class="c1"># 이 객체를 유지하세요.</span>
</span><span id="__span-44-8"><a id="__codelineno-44-8" name="__codelineno-44-8" href="#__codelineno-44-8"></a><span class="n">config</span> <span class="o">=</span> <span class="n">AutoConfig</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;openai-community/gpt2&quot;</span><span class="p">)</span>
</span><span id="__span-44-9"><a id="__codelineno-44-9" name="__codelineno-44-9" href="#__codelineno-44-9"></a><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</span><span id="__span-44-10"><a id="__codelineno-44-10" name="__codelineno-44-10" href="#__codelineno-44-10"></a><span class="n">engine</span> <span class="o">=</span> <span class="n">deepspeed</span><span class="o">.</span><span class="n">initialize</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">config_params</span><span class="o">=</span><span class="n">ds_config</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
</span></code></pre></div>
<p></hfoption>
</hfoptions></p>
<h3 id="trainer-zero-inference-non-trainer-zero-inference">Trainer 없이 ZeRO Inference 사용하기[[non-trainer-zero-inference]]</h3>
<p>단일 GPU에 모델을 맞출 수 없는 경우 [<code>Trainer</code>]없이 ZeRO 추론을 실행하려면 추가 GPU를 사용하거나 CPU 메모리로 오프로드를 시도하세요. 여기서 이해해야 할 중요한 뉘앙스는 ZeRO가 설계된 방식에 따라 서로 다른 GPU에서 서로 다른 입력을 병렬로 처리할 수 있다는 것입니다.</p>
<p>반드시 확인하세요:</p>
<ul>
<li>GPU 메모리가 충분한 경우 CPU 오프로드를 비활성화합니다(속도가 느려지므로).</li>
<li>Ampere 이상의 GPU를 사용하는 경우 bf16을 활성화하면 속도가 빨라집니다. 이러한 GPU가 없는 경우 오버플로 오류가 발생할 수 있으므로 bf16으로 사전 학습된 모델(T5 모델)을 사용하지 않는 한 fp16을 활성화할 수 있습니다.</li>
</ul>
<p>단일 GPU에 맞지 않는 모델에서 [<code>Trainer</code>] 없이 ZeRO 추론을 실행하는 방법에 대한 더 나은 아이디어를 얻으려면 다음 스크립트를 살펴보시기 바랍니다.</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-45-1"><a id="__codelineno-45-1" name="__codelineno-45-1" href="#__codelineno-45-1"></a><span class="ch">#!/usr/bin/env python</span>
</span><span id="__span-45-2"><a id="__codelineno-45-2" name="__codelineno-45-2" href="#__codelineno-45-2"></a>
</span><span id="__span-45-3"><a id="__codelineno-45-3" name="__codelineno-45-3" href="#__codelineno-45-3"></a><span class="c1"># 이 스크립트는 단일 GPU에 모델을 맞출 수 없을 때 추론 모드에서 Deepspeed ZeRO를 사용하는 방법을 보여줍니다.</span>
</span><span id="__span-45-4"><a id="__codelineno-45-4" name="__codelineno-45-4" href="#__codelineno-45-4"></a><span class="c1">#</span>
</span><span id="__span-45-5"><a id="__codelineno-45-5" name="__codelineno-45-5" href="#__codelineno-45-5"></a><span class="c1"># 1. CPU 오프로드와 함께 1개의 GPU 사용</span>
</span><span id="__span-45-6"><a id="__codelineno-45-6" name="__codelineno-45-6" href="#__codelineno-45-6"></a><span class="c1"># 2. 또는 여러 GPU 사용</span>
</span><span id="__span-45-7"><a id="__codelineno-45-7" name="__codelineno-45-7" href="#__codelineno-45-7"></a><span class="c1">#</span>
</span><span id="__span-45-8"><a id="__codelineno-45-8" name="__codelineno-45-8" href="#__codelineno-45-8"></a><span class="c1"># 먼저 deepspeed를 설치해야 합니다: pip install deepspeed</span>
</span><span id="__span-45-9"><a id="__codelineno-45-9" name="__codelineno-45-9" href="#__codelineno-45-9"></a><span class="c1">#</span>
</span><span id="__span-45-10"><a id="__codelineno-45-10" name="__codelineno-45-10" href="#__codelineno-45-10"></a><span class="c1"># 여기서는 약 15GB의 GPU RAM이 필요한 3B &quot;bigscience/T0_3B&quot; 모델을 사용합니다 - 따라서 1개의 큰 GPU나 2개의</span>
</span><span id="__span-45-11"><a id="__codelineno-45-11" name="__codelineno-45-11" href="#__codelineno-45-11"></a><span class="c1"># 작은 GPU로 처리할 수 있습니다. 또는 1개의 작은 GPU와 많은 CPU 메모리로도 가능합니다.</span>
</span><span id="__span-45-12"><a id="__codelineno-45-12" name="__codelineno-45-12" href="#__codelineno-45-12"></a><span class="c1">#</span>
</span><span id="__span-45-13"><a id="__codelineno-45-13" name="__codelineno-45-13" href="#__codelineno-45-13"></a><span class="c1"># 약 50GB가 필요한 &quot;bigscience/T0&quot;와 같은 더 큰 모델을 사용하려면, 80GB GPU가 없는 한</span>
</span><span id="__span-45-14"><a id="__codelineno-45-14" name="__codelineno-45-14" href="#__codelineno-45-14"></a><span class="c1"># 2-4개의 GPU가 필요할 것입니다. 그리고 여러 입력을 한 번에 처리하고 싶다면</span>
</span><span id="__span-45-15"><a id="__codelineno-45-15" name="__codelineno-45-15" href="#__codelineno-45-15"></a><span class="c1"># 스크립트를 수정하여 더 많은 GPU를 처리할 수 있습니다.</span>
</span><span id="__span-45-16"><a id="__codelineno-45-16" name="__codelineno-45-16" href="#__codelineno-45-16"></a><span class="c1">#</span>
</span><span id="__span-45-17"><a id="__codelineno-45-17" name="__codelineno-45-17" href="#__codelineno-45-17"></a><span class="c1"># 제공된 deepspeed 설정은 CPU 메모리 오프로딩도 활성화하므로, 사용 가능한 CPU 메모리가 많고</span>
</span><span id="__span-45-18"><a id="__codelineno-45-18" name="__codelineno-45-18" href="#__codelineno-45-18"></a><span class="c1"># 속도 저하를 감수할 수 있다면 일반적으로 단일 GPU에 맞지 않는 모델을 로드할 수 있을 것입니다.</span>
</span><span id="__span-45-19"><a id="__codelineno-45-19" name="__codelineno-45-19" href="#__codelineno-45-19"></a><span class="c1"># GPU 메모리가 충분하다면 CPU로의 오프로드를 원하지 않을 때 프로그램이 더 빠르게 실행될 것입니다 - 그럴 때는 해당 섹션을 비활성화하세요.</span>
</span><span id="__span-45-20"><a id="__codelineno-45-20" name="__codelineno-45-20" href="#__codelineno-45-20"></a><span class="c1">#</span>
</span><span id="__span-45-21"><a id="__codelineno-45-21" name="__codelineno-45-21" href="#__codelineno-45-21"></a><span class="c1"># 1개의 GPU에 배포하려면:</span>
</span><span id="__span-45-22"><a id="__codelineno-45-22" name="__codelineno-45-22" href="#__codelineno-45-22"></a><span class="c1">#</span>
</span><span id="__span-45-23"><a id="__codelineno-45-23" name="__codelineno-45-23" href="#__codelineno-45-23"></a><span class="c1"># deepspeed --num_gpus 1 t0.py</span>
</span><span id="__span-45-24"><a id="__codelineno-45-24" name="__codelineno-45-24" href="#__codelineno-45-24"></a><span class="c1"># 또는:</span>
</span><span id="__span-45-25"><a id="__codelineno-45-25" name="__codelineno-45-25" href="#__codelineno-45-25"></a><span class="c1"># python -m torch.distributed.run --nproc_per_node=1 t0.py</span>
</span><span id="__span-45-26"><a id="__codelineno-45-26" name="__codelineno-45-26" href="#__codelineno-45-26"></a><span class="c1">#</span>
</span><span id="__span-45-27"><a id="__codelineno-45-27" name="__codelineno-45-27" href="#__codelineno-45-27"></a><span class="c1"># 2개의 GPU에 배포하려면:</span>
</span><span id="__span-45-28"><a id="__codelineno-45-28" name="__codelineno-45-28" href="#__codelineno-45-28"></a><span class="c1">#</span>
</span><span id="__span-45-29"><a id="__codelineno-45-29" name="__codelineno-45-29" href="#__codelineno-45-29"></a><span class="c1"># deepspeed --num_gpus 2 t0.py</span>
</span><span id="__span-45-30"><a id="__codelineno-45-30" name="__codelineno-45-30" href="#__codelineno-45-30"></a><span class="c1"># 또는:</span>
</span><span id="__span-45-31"><a id="__codelineno-45-31" name="__codelineno-45-31" href="#__codelineno-45-31"></a><span class="c1"># python -m torch.distributed.run --nproc_per_node=2 t0.py</span>
</span><span id="__span-45-32"><a id="__codelineno-45-32" name="__codelineno-45-32" href="#__codelineno-45-32"></a>
</span><span id="__span-45-33"><a id="__codelineno-45-33" name="__codelineno-45-33" href="#__codelineno-45-33"></a><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoConfig</span><span class="p">,</span> <span class="n">AutoModelForSeq2SeqLM</span>
</span><span id="__span-45-34"><a id="__codelineno-45-34" name="__codelineno-45-34" href="#__codelineno-45-34"></a><span class="kn">from</span><span class="w"> </span><span class="nn">transformers.integrations</span><span class="w"> </span><span class="kn">import</span> <span class="n">HfDeepSpeedConfig</span>
</span><span id="__span-45-35"><a id="__codelineno-45-35" name="__codelineno-45-35" href="#__codelineno-45-35"></a><span class="kn">import</span><span class="w"> </span><span class="nn">deepspeed</span>
</span><span id="__span-45-36"><a id="__codelineno-45-36" name="__codelineno-45-36" href="#__codelineno-45-36"></a><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
</span><span id="__span-45-37"><a id="__codelineno-45-37" name="__codelineno-45-37" href="#__codelineno-45-37"></a><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="__span-45-38"><a id="__codelineno-45-38" name="__codelineno-45-38" href="#__codelineno-45-38"></a>
</span><span id="__span-45-39"><a id="__codelineno-45-39" name="__codelineno-45-39" href="#__codelineno-45-39"></a><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;TOKENIZERS_PARALLELISM&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;false&quot;</span>  <span class="c1"># 토크나이저의 병렬 처리에 관한 경고를 피하기 위함입니다.</span>
</span><span id="__span-45-40"><a id="__codelineno-45-40" name="__codelineno-45-40" href="#__codelineno-45-40"></a>
</span><span id="__span-45-41"><a id="__codelineno-45-41" name="__codelineno-45-41" href="#__codelineno-45-41"></a><span class="c1"># 분산 환경 설정</span>
</span><span id="__span-45-42"><a id="__codelineno-45-42" name="__codelineno-45-42" href="#__codelineno-45-42"></a><span class="n">local_rank</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;LOCAL_RANK&quot;</span><span class="p">,</span> <span class="s2">&quot;0&quot;</span><span class="p">))</span>
</span><span id="__span-45-43"><a id="__codelineno-45-43" name="__codelineno-45-43" href="#__codelineno-45-43"></a><span class="n">world_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;WORLD_SIZE&quot;</span><span class="p">,</span> <span class="s2">&quot;1&quot;</span><span class="p">))</span>
</span><span id="__span-45-44"><a id="__codelineno-45-44" name="__codelineno-45-44" href="#__codelineno-45-44"></a><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">set_device</span><span class="p">(</span><span class="n">local_rank</span><span class="p">)</span>
</span><span id="__span-45-45"><a id="__codelineno-45-45" name="__codelineno-45-45" href="#__codelineno-45-45"></a><span class="n">deepspeed</span><span class="o">.</span><span class="n">init_distributed</span><span class="p">()</span>
</span><span id="__span-45-46"><a id="__codelineno-45-46" name="__codelineno-45-46" href="#__codelineno-45-46"></a>
</span><span id="__span-45-47"><a id="__codelineno-45-47" name="__codelineno-45-47" href="#__codelineno-45-47"></a><span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;bigscience/T0_3B&quot;</span>
</span><span id="__span-45-48"><a id="__codelineno-45-48" name="__codelineno-45-48" href="#__codelineno-45-48"></a>
</span><span id="__span-45-49"><a id="__codelineno-45-49" name="__codelineno-45-49" href="#__codelineno-45-49"></a><span class="n">config</span> <span class="o">=</span> <span class="n">AutoConfig</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
</span><span id="__span-45-50"><a id="__codelineno-45-50" name="__codelineno-45-50" href="#__codelineno-45-50"></a><span class="n">model_hidden_size</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">d_model</span>
</span><span id="__span-45-51"><a id="__codelineno-45-51" name="__codelineno-45-51" href="#__codelineno-45-51"></a>
</span><span id="__span-45-52"><a id="__codelineno-45-52" name="__codelineno-45-52" href="#__codelineno-45-52"></a><span class="c1"># 배치 크기는 world_size로 나누어 떨어져야 하지만, world_size보다 클 수 있습니다</span>
</span><span id="__span-45-53"><a id="__codelineno-45-53" name="__codelineno-45-53" href="#__codelineno-45-53"></a><span class="n">train_batch_size</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">*</span> <span class="n">world_size</span>
</span><span id="__span-45-54"><a id="__codelineno-45-54" name="__codelineno-45-54" href="#__codelineno-45-54"></a>
</span><span id="__span-45-55"><a id="__codelineno-45-55" name="__codelineno-45-55" href="#__codelineno-45-55"></a><span class="c1"># ds_config 참고사항</span>
</span><span id="__span-45-56"><a id="__codelineno-45-56" name="__codelineno-45-56" href="#__codelineno-45-56"></a><span class="c1">#</span>
</span><span id="__span-45-57"><a id="__codelineno-45-57" name="__codelineno-45-57" href="#__codelineno-45-57"></a><span class="c1"># - Ampere 이상의 GPU를 사용하는 경우 bf16을 활성화하세요 - 이는 혼합 정밀도로 실행되어</span>
</span><span id="__span-45-58"><a id="__codelineno-45-58" name="__codelineno-45-58" href="#__codelineno-45-58"></a><span class="c1"># 더 빠를 것입니다.</span>
</span><span id="__span-45-59"><a id="__codelineno-45-59" name="__codelineno-45-59" href="#__codelineno-45-59"></a><span class="c1">#</span>
</span><span id="__span-45-60"><a id="__codelineno-45-60" name="__codelineno-45-60" href="#__codelineno-45-60"></a><span class="c1"># - 오래된 GPU의 경우 fp16을 활성화할 수 있지만, bf16으로 사전 훈련되지 않은 모델에서만 작동합니다 - 예를 들어</span>
</span><span id="__span-45-61"><a id="__codelineno-45-61" name="__codelineno-45-61" href="#__codelineno-45-61"></a><span class="c1"># 모든 공식 t5 모델은 bf16으로 사전 훈련되었습니다</span>
</span><span id="__span-45-62"><a id="__codelineno-45-62" name="__codelineno-45-62" href="#__codelineno-45-62"></a><span class="c1">#</span>
</span><span id="__span-45-63"><a id="__codelineno-45-63" name="__codelineno-45-63" href="#__codelineno-45-63"></a><span class="c1"># - CPU 오프로드를 원하지 않는다면 offload_param.device를 &quot;none&quot;으로 설정하거나 `offload_param` 섹션을</span>
</span><span id="__span-45-64"><a id="__codelineno-45-64" name="__codelineno-45-64" href="#__codelineno-45-64"></a><span class="c1"># 완전히 제거하세요</span>
</span><span id="__span-45-65"><a id="__codelineno-45-65" name="__codelineno-45-65" href="#__codelineno-45-65"></a><span class="c1">#</span>
</span><span id="__span-45-66"><a id="__codelineno-45-66" name="__codelineno-45-66" href="#__codelineno-45-66"></a><span class="c1"># - `offload_param`을 사용하는 경우, stage3_param_persistence_threshold를 수동으로 미세 조정하여</span>
</span><span id="__span-45-67"><a id="__codelineno-45-67" name="__codelineno-45-67" href="#__codelineno-45-67"></a><span class="c1"># 어떤 매개변수가 GPU에 남아있어야 하는지 제어할 수 있습니다 - 값이 클수록 오프로드 크기가 작아집니다</span>
</span><span id="__span-45-68"><a id="__codelineno-45-68" name="__codelineno-45-68" href="#__codelineno-45-68"></a><span class="c1">#</span>
</span><span id="__span-45-69"><a id="__codelineno-45-69" name="__codelineno-45-69" href="#__codelineno-45-69"></a><span class="c1"># Deepspeed 설정에 대한 자세한 정보는 다음을 참조하세요</span>
</span><span id="__span-45-70"><a id="__codelineno-45-70" name="__codelineno-45-70" href="#__codelineno-45-70"></a><span class="c1"># https://huggingface.co/docs/transformers/main/main_classes/deepspeed</span>
</span><span id="__span-45-71"><a id="__codelineno-45-71" name="__codelineno-45-71" href="#__codelineno-45-71"></a>
</span><span id="__span-45-72"><a id="__codelineno-45-72" name="__codelineno-45-72" href="#__codelineno-45-72"></a><span class="c1"># 일관성을 위해 json과 동일한 형식을 유지하되, true/false에는 소문자를 사용합니다</span>
</span><span id="__span-45-73"><a id="__codelineno-45-73" name="__codelineno-45-73" href="#__codelineno-45-73"></a><span class="c1"># fmt: off</span>
</span><span id="__span-45-74"><a id="__codelineno-45-74" name="__codelineno-45-74" href="#__codelineno-45-74"></a><span class="n">ds_config</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="__span-45-75"><a id="__codelineno-45-75" name="__codelineno-45-75" href="#__codelineno-45-75"></a>    <span class="s2">&quot;fp16&quot;</span><span class="p">:</span> <span class="p">{</span>
</span><span id="__span-45-76"><a id="__codelineno-45-76" name="__codelineno-45-76" href="#__codelineno-45-76"></a>        <span class="s2">&quot;enabled&quot;</span><span class="p">:</span> <span class="kc">False</span>
</span><span id="__span-45-77"><a id="__codelineno-45-77" name="__codelineno-45-77" href="#__codelineno-45-77"></a>    <span class="p">},</span>
</span><span id="__span-45-78"><a id="__codelineno-45-78" name="__codelineno-45-78" href="#__codelineno-45-78"></a>    <span class="s2">&quot;bf16&quot;</span><span class="p">:</span> <span class="p">{</span>
</span><span id="__span-45-79"><a id="__codelineno-45-79" name="__codelineno-45-79" href="#__codelineno-45-79"></a>        <span class="s2">&quot;enabled&quot;</span><span class="p">:</span> <span class="kc">False</span>
</span><span id="__span-45-80"><a id="__codelineno-45-80" name="__codelineno-45-80" href="#__codelineno-45-80"></a>    <span class="p">},</span>
</span><span id="__span-45-81"><a id="__codelineno-45-81" name="__codelineno-45-81" href="#__codelineno-45-81"></a>    <span class="s2">&quot;zero_optimization&quot;</span><span class="p">:</span> <span class="p">{</span>
</span><span id="__span-45-82"><a id="__codelineno-45-82" name="__codelineno-45-82" href="#__codelineno-45-82"></a>        <span class="s2">&quot;stage&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
</span><span id="__span-45-83"><a id="__codelineno-45-83" name="__codelineno-45-83" href="#__codelineno-45-83"></a>        <span class="s2">&quot;offload_param&quot;</span><span class="p">:</span> <span class="p">{</span>
</span><span id="__span-45-84"><a id="__codelineno-45-84" name="__codelineno-45-84" href="#__codelineno-45-84"></a>            <span class="s2">&quot;device&quot;</span><span class="p">:</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
</span><span id="__span-45-85"><a id="__codelineno-45-85" name="__codelineno-45-85" href="#__codelineno-45-85"></a>            <span class="s2">&quot;pin_memory&quot;</span><span class="p">:</span> <span class="kc">True</span>
</span><span id="__span-45-86"><a id="__codelineno-45-86" name="__codelineno-45-86" href="#__codelineno-45-86"></a>        <span class="p">},</span>
</span><span id="__span-45-87"><a id="__codelineno-45-87" name="__codelineno-45-87" href="#__codelineno-45-87"></a>        <span class="s2">&quot;overlap_comm&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="__span-45-88"><a id="__codelineno-45-88" name="__codelineno-45-88" href="#__codelineno-45-88"></a>        <span class="s2">&quot;contiguous_gradients&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="__span-45-89"><a id="__codelineno-45-89" name="__codelineno-45-89" href="#__codelineno-45-89"></a>        <span class="s2">&quot;reduce_bucket_size&quot;</span><span class="p">:</span> <span class="n">model_hidden_size</span> <span class="o">*</span> <span class="n">model_hidden_size</span><span class="p">,</span>
</span><span id="__span-45-90"><a id="__codelineno-45-90" name="__codelineno-45-90" href="#__codelineno-45-90"></a>        <span class="s2">&quot;stage3_prefetch_bucket_size&quot;</span><span class="p">:</span> <span class="mf">0.9</span> <span class="o">*</span> <span class="n">model_hidden_size</span> <span class="o">*</span> <span class="n">model_hidden_size</span><span class="p">,</span>
</span><span id="__span-45-91"><a id="__codelineno-45-91" name="__codelineno-45-91" href="#__codelineno-45-91"></a>        <span class="s2">&quot;stage3_param_persistence_threshold&quot;</span><span class="p">:</span> <span class="mi">10</span> <span class="o">*</span> <span class="n">model_hidden_size</span>
</span><span id="__span-45-92"><a id="__codelineno-45-92" name="__codelineno-45-92" href="#__codelineno-45-92"></a>    <span class="p">},</span>
</span><span id="__span-45-93"><a id="__codelineno-45-93" name="__codelineno-45-93" href="#__codelineno-45-93"></a>    <span class="s2">&quot;steps_per_print&quot;</span><span class="p">:</span> <span class="mi">2000</span><span class="p">,</span>
</span><span id="__span-45-94"><a id="__codelineno-45-94" name="__codelineno-45-94" href="#__codelineno-45-94"></a>    <span class="s2">&quot;train_batch_size&quot;</span><span class="p">:</span> <span class="n">train_batch_size</span><span class="p">,</span>
</span><span id="__span-45-95"><a id="__codelineno-45-95" name="__codelineno-45-95" href="#__codelineno-45-95"></a>    <span class="s2">&quot;train_micro_batch_size_per_gpu&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
</span><span id="__span-45-96"><a id="__codelineno-45-96" name="__codelineno-45-96" href="#__codelineno-45-96"></a>    <span class="s2">&quot;wall_clock_breakdown&quot;</span><span class="p">:</span> <span class="kc">False</span>
</span><span id="__span-45-97"><a id="__codelineno-45-97" name="__codelineno-45-97" href="#__codelineno-45-97"></a><span class="p">}</span>
</span><span id="__span-45-98"><a id="__codelineno-45-98" name="__codelineno-45-98" href="#__codelineno-45-98"></a><span class="c1"># fmt: on</span>
</span><span id="__span-45-99"><a id="__codelineno-45-99" name="__codelineno-45-99" href="#__codelineno-45-99"></a>
</span><span id="__span-45-100"><a id="__codelineno-45-100" name="__codelineno-45-100" href="#__codelineno-45-100"></a><span class="c1"># 다음 줄은 모델의 `from_pretrained` 메소드가 호출될 때</span>
</span><span id="__span-45-101"><a id="__codelineno-45-101" name="__codelineno-45-101" href="#__codelineno-45-101"></a><span class="c1"># deepspeed.zero.Init를 사용하여 모델을 여러 GPU에 직접 분할하도록 transformers에 지시합니다.</span>
</span><span id="__span-45-102"><a id="__codelineno-45-102" name="__codelineno-45-102" href="#__codelineno-45-102"></a><span class="c1">#</span>
</span><span id="__span-45-103"><a id="__codelineno-45-103" name="__codelineno-45-103" href="#__codelineno-45-103"></a><span class="c1"># **이는 AutoModelForSeq2SeqLM.from_pretrained(model_name)로 모델을 로드하기 전에 실행되어야 합니다**</span>
</span><span id="__span-45-104"><a id="__codelineno-45-104" name="__codelineno-45-104" href="#__codelineno-45-104"></a><span class="c1">#</span>
</span><span id="__span-45-105"><a id="__codelineno-45-105" name="__codelineno-45-105" href="#__codelineno-45-105"></a><span class="c1"># 그렇지 않으면 모델이 먼저 정상적으로 로드된 후 포워드 시에만 분할되는데, 이는</span>
</span><span id="__span-45-106"><a id="__codelineno-45-106" name="__codelineno-45-106" href="#__codelineno-45-106"></a><span class="c1"># 덜 효율적이며 CPU RAM이 부족할 경우 실패할 수 있습니다</span>
</span><span id="__span-45-107"><a id="__codelineno-45-107" name="__codelineno-45-107" href="#__codelineno-45-107"></a><span class="n">dschf</span> <span class="o">=</span> <span class="n">HfDeepSpeedConfig</span><span class="p">(</span><span class="n">ds_config</span><span class="p">)</span>  <span class="c1"># 이 객체를 유지하세요</span>
</span><span id="__span-45-108"><a id="__codelineno-45-108" name="__codelineno-45-108" href="#__codelineno-45-108"></a>
</span><span id="__span-45-109"><a id="__codelineno-45-109" name="__codelineno-45-109" href="#__codelineno-45-109"></a><span class="c1"># 이제 모델을 로드할 수 있습니다.</span>
</span><span id="__span-45-110"><a id="__codelineno-45-110" name="__codelineno-45-110" href="#__codelineno-45-110"></a><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSeq2SeqLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
</span><span id="__span-45-111"><a id="__codelineno-45-111" name="__codelineno-45-111" href="#__codelineno-45-111"></a>
</span><span id="__span-45-112"><a id="__codelineno-45-112" name="__codelineno-45-112" href="#__codelineno-45-112"></a><span class="c1"># Deepspeed ZeRO를 초기화하고 엔진 객체만 저장</span>
</span><span id="__span-45-113"><a id="__codelineno-45-113" name="__codelineno-45-113" href="#__codelineno-45-113"></a><span class="n">ds_engine</span> <span class="o">=</span> <span class="n">deepspeed</span><span class="o">.</span><span class="n">initialize</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">config_params</span><span class="o">=</span><span class="n">ds_config</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="__span-45-114"><a id="__codelineno-45-114" name="__codelineno-45-114" href="#__codelineno-45-114"></a><span class="n">ds_engine</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># inference</span>
</span><span id="__span-45-115"><a id="__codelineno-45-115" name="__codelineno-45-115" href="#__codelineno-45-115"></a>
</span><span id="__span-45-116"><a id="__codelineno-45-116" name="__codelineno-45-116" href="#__codelineno-45-116"></a><span class="c1"># Deepspeed ZeRO는 각 GPU에서 서로 관련 없는 입력을 처리할 수 있습니다. 따라서 2개의 GPU를 사용하면 한 번에 2개의 입력을 처리할 수 있습니다.</span>
</span><span id="__span-45-117"><a id="__codelineno-45-117" name="__codelineno-45-117" href="#__codelineno-45-117"></a><span class="c1"># GPU를 더 많이 사용하는 경우 그에 맞게 조정하세요.</span>
</span><span id="__span-45-118"><a id="__codelineno-45-118" name="__codelineno-45-118" href="#__codelineno-45-118"></a>
</span><span id="__span-45-119"><a id="__codelineno-45-119" name="__codelineno-45-119" href="#__codelineno-45-119"></a><span class="c1"># 물론 처리할 입력이 하나뿐이라면 두 GPU에 동일한 문자열을 전달해야 합니다.</span>
</span><span id="__span-45-120"><a id="__codelineno-45-120" name="__codelineno-45-120" href="#__codelineno-45-120"></a><span class="c1"># GPU를 하나만 사용하는 경우에는 rank 0만 갖게 됩니다.</span>
</span><span id="__span-45-121"><a id="__codelineno-45-121" name="__codelineno-45-121" href="#__codelineno-45-121"></a><span class="n">rank</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_rank</span><span class="p">()</span>
</span><span id="__span-45-122"><a id="__codelineno-45-122" name="__codelineno-45-122" href="#__codelineno-45-122"></a><span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="__span-45-123"><a id="__codelineno-45-123" name="__codelineno-45-123" href="#__codelineno-45-123"></a>    <span class="n">text_in</span> <span class="o">=</span> <span class="s2">&quot;Is this review positive or negative? Review: this is the best cast iron skillet you will ever buy&quot;</span>
</span><span id="__span-45-124"><a id="__codelineno-45-124" name="__codelineno-45-124" href="#__codelineno-45-124"></a><span class="k">elif</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="__span-45-125"><a id="__codelineno-45-125" name="__codelineno-45-125" href="#__codelineno-45-125"></a>    <span class="n">text_in</span> <span class="o">=</span> <span class="s2">&quot;Is this review positive or negative? Review: this is the worst restaurant ever&quot;</span>
</span><span id="__span-45-126"><a id="__codelineno-45-126" name="__codelineno-45-126" href="#__codelineno-45-126"></a>
</span><span id="__span-45-127"><a id="__codelineno-45-127" name="__codelineno-45-127" href="#__codelineno-45-127"></a><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
</span><span id="__span-45-128"><a id="__codelineno-45-128" name="__codelineno-45-128" href="#__codelineno-45-128"></a><span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">text_in</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">local_rank</span><span class="p">)</span>
</span><span id="__span-45-129"><a id="__codelineno-45-129" name="__codelineno-45-129" href="#__codelineno-45-129"></a><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span><span id="__span-45-130"><a id="__codelineno-45-130" name="__codelineno-45-130" href="#__codelineno-45-130"></a>    <span class="n">outputs</span> <span class="o">=</span> <span class="n">ds_engine</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">synced_gpus</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="__span-45-131"><a id="__codelineno-45-131" name="__codelineno-45-131" href="#__codelineno-45-131"></a><span class="n">text_out</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="__span-45-132"><a id="__codelineno-45-132" name="__codelineno-45-132" href="#__codelineno-45-132"></a><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;rank</span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2">:</span><span class="se">\n</span><span class="s2">   in=</span><span class="si">{</span><span class="n">text_in</span><span class="si">}</span><span class="se">\n</span><span class="s2">  out=</span><span class="si">{</span><span class="n">text_out</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span></code></pre></div>
<p>스크립트를 t0.py로 저장하고 실행합니다:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-46-1"><a id="__codelineno-46-1" name="__codelineno-46-1" href="#__codelineno-46-1"></a>$<span class="w"> </span>deepspeed<span class="w"> </span>--num_gpus<span class="w"> </span><span class="m">2</span><span class="w"> </span>t0.py
</span><span id="__span-46-2"><a id="__codelineno-46-2" name="__codelineno-46-2" href="#__codelineno-46-2"></a>rank0:
</span><span id="__span-46-3"><a id="__codelineno-46-3" name="__codelineno-46-3" href="#__codelineno-46-3"></a><span class="w">   </span><span class="k">in</span><span class="o">=</span>Is<span class="w"> </span>this<span class="w"> </span>review<span class="w"> </span>positive<span class="w"> </span>or<span class="w"> </span>negative?<span class="w"> </span>Review:<span class="w"> </span>this<span class="w"> </span>is<span class="w"> </span>the<span class="w"> </span>best<span class="w"> </span>cast<span class="w"> </span>iron<span class="w"> </span>skillet<span class="w"> </span>you<span class="w"> </span>will<span class="w"> </span>ever<span class="w"> </span>buy
</span><span id="__span-46-4"><a id="__codelineno-46-4" name="__codelineno-46-4" href="#__codelineno-46-4"></a><span class="w">  </span><span class="nv">out</span><span class="o">=</span>Positive
</span><span id="__span-46-5"><a id="__codelineno-46-5" name="__codelineno-46-5" href="#__codelineno-46-5"></a>rank1:
</span><span id="__span-46-6"><a id="__codelineno-46-6" name="__codelineno-46-6" href="#__codelineno-46-6"></a><span class="w">   </span><span class="k">in</span><span class="o">=</span>Is<span class="w"> </span>this<span class="w"> </span>review<span class="w"> </span>positive<span class="w"> </span>or<span class="w"> </span>negative?<span class="w"> </span>Review:<span class="w"> </span>this<span class="w"> </span>is<span class="w"> </span>the<span class="w"> </span>worst<span class="w"> </span>restaurant<span class="w"> </span>ever
</span><span id="__span-46-7"><a id="__codelineno-46-7" name="__codelineno-46-7" href="#__codelineno-46-7"></a><span class="w">  </span><span class="nv">out</span><span class="o">=</span>negative
</span></code></pre></div>
<p>이것은 매우 기본적인 예시이므로 사용 사례에 맞게 조정할 수 있습니다.</p>
<h3 id="generate">생성[[generate]]</h3>
<p>생성에 ZeRO-3와 함께 여러 개의 GPU를 사용하려면 [<code>~GenerationMixin.generate</code>] 메서드에서 <code>synced_gpus=True</code>를 설정하여 GPU를 동기화해야 합니다. 그렇지 않으면 한 GPU가 다른 GPU보다 먼저 생성을 완료하면 나머지 GPU가 먼저 완료한 GPU로부터 가중치 샤드를 받지 못하여 전체 시스템이 중단됩니다.</p>
<p>트랜스포머&gt;=4.28의 경우, 생성 중에 여러 개의 GPU가 감지되면 <code>synced_gpus</code>가 자동으로 <code>True</code>로 설정됩니다.</p>
<h2 id="troubleshoot">트러블슈팅[[troubleshoot]]</h2>
<p>문제가 발생하면 DeepSpeed가 문제의 원인이 아닌 경우가 많으므로(아주 명백하고 예외적으로 DeepSpeed 모듈을 볼 수 있는 경우가 아니라면) DeepSpeed가 문제의 원인인지 고려해야 합니다! 첫 번째 단계는 DeepSpeed 없이 설정을 다시 시도하고 문제가 지속되면 문제를 신고하는 것입니다. 문제가 핵심적인 DeepSpeed 문제이고 transformers와 관련이 없는 경우, <a href="https://github.com/deepspeedai/DeepSpeed">DeepSpeed 리포지토리</a>에서 이슈를 개설하세요.</p>
<p>transformers와 관련된 이슈를 개설할 때에는 다음 정보를 제공해 주세요:</p>
<ul>
<li>전체 DeepSpeed 구성 파일</li>
</ul>
<p>*[<code>Trainer</code>]의 명령줄 인수, 또는[<code>Trainer</code>] 설정을 직접 작성하는 경우[<code>TrainingArguments</code>] 인수(관련 없는 항목이 수십 개 있는 [<code>TrainingArguments</code>]는 덤프하지 마세요).</p>
<ul>
<li>다음 코드의 출력 결과:</li>
</ul>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-47-1"><a id="__codelineno-47-1" name="__codelineno-47-1" href="#__codelineno-47-1"></a>python<span class="w"> </span>-c<span class="w"> </span><span class="s1">&#39;import torch; print(f&quot;torch: {torch.__version__}&quot;)&#39;</span>
</span><span id="__span-47-2"><a id="__codelineno-47-2" name="__codelineno-47-2" href="#__codelineno-47-2"></a>python<span class="w"> </span>-c<span class="w"> </span><span class="s1">&#39;import transformers; print(f&quot;transformers: {transformers.__version__}&quot;)&#39;</span>
</span><span id="__span-47-3"><a id="__codelineno-47-3" name="__codelineno-47-3" href="#__codelineno-47-3"></a>python<span class="w"> </span>-c<span class="w"> </span><span class="s1">&#39;import deepspeed; print(f&quot;deepspeed: {deepspeed.__version__}&quot;)&#39;</span>
</span></code></pre></div>
<ul>
<li>
<p>문제를 재현할 수 있는 Google Colab 노트북 링크</p>
</li>
<li>
<p>불가능할 경우 기존 예제를 사용하여 문제를 재현할 수 있는 표준 및 사용자 지정이 아닌 데이터 집합을 사용할 수 있습니다.</p>
</li>
</ul>
<p>다음 섹션에서는 가장 일반적인 두 가지 문제를 해결하기 위한 가이드를 제공합니다.</p>
<h3 id="deepspeed-deepspeed-process-killed-at-startup">DeepSpeed 프로세스가 시작 단계에서 종료되었을 경우[[deepspeed-process-killed-at-startup]]</h3>
<p>실행 중에 트레이스백 없이 DeepSpeed 프로세스가 종료되면 일반적으로 프로그램이 시스템보다 많은 CPU 메모리를 할당하려고 시도했거나 프로세스가 허용된 것보다 많은 CPU 메모리를 할당하려고 시도하여 OS 커널이 프로세스를 종료했음을 의미합니다. 이 경우 구성 파일에 <code>offload_optimizer</code>, <code>offload_param</code> 또는 둘 다 CPU로 오프로드하도록 구성되어 있는지 확인하세요.</p>
<p>NVMe 및 ZeRO-3를 설정한 경우 NVMe로 오프로드를 실험해 보세요(모델의 메모리 요구 사항을 <a href="https://deepspeed.readthedocs.io/en/latest/memory.html">확인</a>하세요).</p>
<h3 id="nan-nan-loss">NaN 손실[[nan-loss]]</h3>
<p>모델을 bf16으로 사전 훈련한 다음 fp16으로 사용하려고 할 때 NaN 손실이 발생하는 경우가 많습니다(특히 TPU 훈련 모델에 해당). 이 문제를 해결하려면 하드웨어가 이를 지원하는 경우(TPU, Ampere GPU 이상) fp32 또는 bf16을 사용하세요.</p>
<p>다른 문제는 fp16 사용과 관련이 있을 수 있습니다. 예를 들어 이것이 fp16 구성인 경우입니다:</p>
<div class="language-yaml highlight"><pre><span></span><code><span id="__span-48-1"><a id="__codelineno-48-1" name="__codelineno-48-1" href="#__codelineno-48-1"></a><span class="p p-Indicator">{</span>
</span><span id="__span-48-2"><a id="__codelineno-48-2" name="__codelineno-48-2" href="#__codelineno-48-2"></a><span class="w">    </span><span class="s">&quot;fp16&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="p p-Indicator">{</span>
</span><span id="__span-48-3"><a id="__codelineno-48-3" name="__codelineno-48-3" href="#__codelineno-48-3"></a><span class="w">        </span><span class="s">&quot;enabled&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="s">&quot;auto&quot;</span><span class="p p-Indicator">,</span>
</span><span id="__span-48-4"><a id="__codelineno-48-4" name="__codelineno-48-4" href="#__codelineno-48-4"></a><span class="w">        </span><span class="s">&quot;loss_scale&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="nv">0</span><span class="p p-Indicator">,</span>
</span><span id="__span-48-5"><a id="__codelineno-48-5" name="__codelineno-48-5" href="#__codelineno-48-5"></a><span class="w">        </span><span class="s">&quot;loss_scale_window&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="nv">1000</span><span class="p p-Indicator">,</span>
</span><span id="__span-48-6"><a id="__codelineno-48-6" name="__codelineno-48-6" href="#__codelineno-48-6"></a><span class="w">        </span><span class="s">&quot;initial_scale_power&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="nv">16</span><span class="p p-Indicator">,</span>
</span><span id="__span-48-7"><a id="__codelineno-48-7" name="__codelineno-48-7" href="#__codelineno-48-7"></a><span class="w">        </span><span class="s">&quot;hysteresis&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="nv">2</span><span class="p p-Indicator">,</span>
</span><span id="__span-48-8"><a id="__codelineno-48-8" name="__codelineno-48-8" href="#__codelineno-48-8"></a><span class="w">        </span><span class="s">&quot;min_loss_scale&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="nv">1</span>
</span><span id="__span-48-9"><a id="__codelineno-48-9" name="__codelineno-48-9" href="#__codelineno-48-9"></a><span class="w">    </span><span class="p p-Indicator">}</span>
</span><span id="__span-48-10"><a id="__codelineno-48-10" name="__codelineno-48-10" href="#__codelineno-48-10"></a><span class="p p-Indicator">}</span>
</span></code></pre></div>
<p>로그에 다음과 같은 <code>OVERFLOW!</code> 메시지가 표시될 수 있습니다:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-49-1"><a id="__codelineno-49-1" name="__codelineno-49-1" href="#__codelineno-49-1"></a><span class="m">0</span>%<span class="p">|</span><span class="w">                                                                                                                             </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>/189<span class="w"> </span><span class="o">[</span><span class="m">00</span>:00&lt;?,<span class="w"> </span>?it/s<span class="o">]</span>
</span><span id="__span-49-2"><a id="__codelineno-49-2" name="__codelineno-49-2" href="#__codelineno-49-2"></a><span class="w"> </span><span class="o">[</span>deepscale<span class="o">]</span><span class="w"> </span>OVERFLOW!<span class="w"> </span>Rank<span class="w"> </span><span class="m">0</span><span class="w"> </span>Skipping<span class="w"> </span>step.<span class="w"> </span>Attempted<span class="w"> </span>loss<span class="w"> </span>scale:<span class="w"> </span><span class="m">262144</span>,<span class="w"> </span>reducing<span class="w"> </span>to<span class="w"> </span><span class="m">262144</span>
</span><span id="__span-49-3"><a id="__codelineno-49-3" name="__codelineno-49-3" href="#__codelineno-49-3"></a><span class="w">  </span><span class="m">1</span>%<span class="p">|</span>▌<span class="w">                                                                                                                    </span><span class="p">|</span><span class="w"> </span><span class="m">1</span>/189<span class="w"> </span><span class="o">[</span><span class="m">00</span>:00&lt;<span class="m">01</span>:26,<span class="w">  </span><span class="m">2</span>.17it/s<span class="o">]</span>
</span><span id="__span-49-4"><a id="__codelineno-49-4" name="__codelineno-49-4" href="#__codelineno-49-4"></a><span class="w"> </span><span class="o">[</span>deepscale<span class="o">]</span><span class="w"> </span>OVERFLOW!<span class="w"> </span>Rank<span class="w"> </span><span class="m">0</span><span class="w"> </span>Skipping<span class="w"> </span>step.<span class="w"> </span>Attempted<span class="w"> </span>loss<span class="w"> </span>scale:<span class="w"> </span><span class="m">262144</span>,<span class="w"> </span>reducing<span class="w"> </span>to<span class="w"> </span><span class="m">131072</span>.0
</span><span id="__span-49-5"><a id="__codelineno-49-5" name="__codelineno-49-5" href="#__codelineno-49-5"></a><span class="w">  </span><span class="m">1</span>%<span class="p">|</span>█▏
</span><span id="__span-49-6"><a id="__codelineno-49-6" name="__codelineno-49-6" href="#__codelineno-49-6"></a><span class="w"> </span><span class="o">[</span>...<span class="o">]</span>
</span><span id="__span-49-7"><a id="__codelineno-49-7" name="__codelineno-49-7" href="#__codelineno-49-7"></a><span class="w"> </span><span class="o">[</span>deepscale<span class="o">]</span><span class="w"> </span>OVERFLOW!<span class="w"> </span>Rank<span class="w"> </span><span class="m">0</span><span class="w"> </span>Skipping<span class="w"> </span>step.<span class="w"> </span>Attempted<span class="w"> </span>loss<span class="w"> </span>scale:<span class="w"> </span><span class="m">1</span>,<span class="w"> </span>reducing<span class="w"> </span>to<span class="w"> </span><span class="m">1</span>
</span><span id="__span-49-8"><a id="__codelineno-49-8" name="__codelineno-49-8" href="#__codelineno-49-8"></a><span class="w"> </span><span class="m">14</span>%<span class="p">|</span>████████████████▌<span class="w">                                                                                                   </span><span class="p">|</span><span class="w"> </span><span class="m">27</span>/189<span class="w"> </span><span class="o">[</span><span class="m">00</span>:14&lt;<span class="m">01</span>:13,<span class="w">  </span><span class="m">2</span>.21it/s<span class="o">]</span>
</span><span id="__span-49-9"><a id="__codelineno-49-9" name="__codelineno-49-9" href="#__codelineno-49-9"></a><span class="w"> </span><span class="o">[</span>deepscale<span class="o">]</span><span class="w"> </span>OVERFLOW!<span class="w"> </span>Rank<span class="w"> </span><span class="m">0</span><span class="w"> </span>Skipping<span class="w"> </span>step.<span class="w"> </span>Attempted<span class="w"> </span>loss<span class="w"> </span>scale:<span class="w"> </span><span class="m">1</span>,<span class="w"> </span>reducing<span class="w"> </span>to<span class="w"> </span><span class="m">1</span>
</span><span id="__span-49-10"><a id="__codelineno-49-10" name="__codelineno-49-10" href="#__codelineno-49-10"></a><span class="w"> </span><span class="m">15</span>%<span class="p">|</span>█████████████████▏<span class="w">                                                                                                  </span><span class="p">|</span><span class="w"> </span><span class="m">28</span>/189<span class="w"> </span><span class="o">[</span><span class="m">00</span>:14&lt;<span class="m">01</span>:13,<span class="w">  </span><span class="m">2</span>.18it/s<span class="o">]</span>
</span><span id="__span-49-11"><a id="__codelineno-49-11" name="__codelineno-49-11" href="#__codelineno-49-11"></a><span class="w"> </span><span class="o">[</span>deepscale<span class="o">]</span><span class="w"> </span>OVERFLOW!<span class="w"> </span>Rank<span class="w"> </span><span class="m">0</span><span class="w"> </span>Skipping<span class="w"> </span>step.<span class="w"> </span>Attempted<span class="w"> </span>loss<span class="w"> </span>scale:<span class="w"> </span><span class="m">1</span>,<span class="w"> </span>reducing<span class="w"> </span>to<span class="w"> </span><span class="m">1</span>
</span><span id="__span-49-12"><a id="__codelineno-49-12" name="__codelineno-49-12" href="#__codelineno-49-12"></a><span class="w"> </span><span class="m">15</span>%<span class="p">|</span>█████████████████▊<span class="w">                                                                                                  </span><span class="p">|</span><span class="w"> </span><span class="m">29</span>/189<span class="w"> </span><span class="o">[</span><span class="m">00</span>:15&lt;<span class="m">01</span>:13,<span class="w">  </span><span class="m">2</span>.18it/s<span class="o">]</span>
</span><span id="__span-49-13"><a id="__codelineno-49-13" name="__codelineno-49-13" href="#__codelineno-49-13"></a><span class="w"> </span><span class="o">[</span>deepscale<span class="o">]</span><span class="w"> </span>OVERFLOW!<span class="w"> </span>Rank<span class="w"> </span><span class="m">0</span><span class="w"> </span>Skipping<span class="w"> </span>step.<span class="w"> </span>Attempted<span class="w"> </span>loss<span class="w"> </span>scale:<span class="w"> </span><span class="m">1</span>,<span class="w"> </span>reducing<span class="w"> </span>to<span class="w"> </span><span class="m">1</span>
</span><span id="__span-49-14"><a id="__codelineno-49-14" name="__codelineno-49-14" href="#__codelineno-49-14"></a><span class="o">[</span>...<span class="o">]</span>
</span></code></pre></div>
<p>이는 DeepSpeed 손실 스케일러가 손실 오버플로를 극복할 수 있는 스케일링 계수를 찾을 수 없음을 의미합니다. 이 문제를 해결하려면 <code>initial_scale_power</code> 값을 더 높게 설정하세요(일반적으로 32가 적절합니다).</p>
<h2 id="resources">리소스[[resources]]</h2>
<p>DeepSpeed ZeRO는 제한된 GPU 리소스로 추론을 위해 매우 큰 모델을 훈련하고 로드하는 강력한 기술로, 누구나 쉽게 사용할 수 있습니다. DeepSpeed에 대해 자세히 알아보려면 <a href="https://www.microsoft.com/en-us/research/search/?q=deepspeed">블로그 포스트</a>, <a href="https://www.deepspeed.ai/getting-started/">공식 문서</a>, <a href="https://github.com/deepspeedai/DeepSpeed">깃허브 리포지토리</a>를 참조하세요.</p>
<p>다음 문서도 ZeRO에 대해 자세히 알아볼 수 있는 훌륭한 자료입니다:</p>
<ul>
<li><a href="https://hf.co/papers/1910.02054">ZeRO: Memory Optimizations Toward Training Trillion Parameter Models</a></li>
<li><a href="https://hf.co/papers/2101.06840">ZeRO-Offload: Democratizing Billion-Scale Model Training</a></li>
<li><a href="https://hf.co/papers/2104.07857">ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep Learning</a></li>
</ul>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../../../../../..", "features": ["navigation.tabs", "navigation.indexes", "navigation.instant", "navigation.sections", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow", "content.tabs.link", "content.code.copy"], "search": "../../../../../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../../../../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
    
  </body>
</html>