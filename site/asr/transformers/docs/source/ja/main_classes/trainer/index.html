
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../../../../../../../assets/favicon.ico">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.22">
    
    
      
        <title>Trainer - Ohayou</title>
      
    
    
      <link rel="stylesheet" href="../../../../../../../assets/stylesheets/main.84d31ad4.min.css">
      
        
        <link rel="stylesheet" href="../../../../../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../../../../../assets/extra.css">
    
    <script>__md_scope=new URL("../../../../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#trainer" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../../../../.." title="Ohayou" class="md-header__button md-logo" aria-label="Ohayou" data-md-component="logo">
      
  <img src="../../../../../../../assets/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Ohayou
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Trainer
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../../../ohayou/" class="md-tabs__link">
        
  
  
    
  
  Ohayou

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../../../../vllm/open_ai_vllm_example_a_v_t/" class="md-tabs__link">
          
  
  
    
  
  vLLM

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../../../../llm/speculative_decoding/" class="md-tabs__link">
          
  
  
    
  
  LLM

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../../../../vlm/qwen3_vl_4B_object_detection/" class="md-tabs__link">
          
  
  
    
  
  VLM

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../../../md_format_helpers/" class="md-tabs__link">
        
  
  
    
  
  MD format helpers

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../../../docker/" class="md-tabs__link">
        
  
  
    
  
  Docker

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../../../linux/" class="md-tabs__link">
        
  
  
    
  
  Linux

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../../../moe/" class="md-tabs__link">
        
  
  
    
  
  Mixture of Experts

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../../../slurm/" class="md-tabs__link">
        
  
  
    
  
  Slurm

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../../../../japanese-phrases/" class="md-tabs__link">
          
  
  
    
  
  Japanese Phrases

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../../../hackathon/index.md" class="md-tabs__link">
        
  
  
    
  
  Hack

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../../../../.." title="Ohayou" class="md-nav__button md-logo" aria-label="Ohayou" data-md-component="logo">
      
  <img src="../../../../../../../assets/logo.png" alt="logo">

    </a>
    Ohayou
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../../ohayou/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Ohayou
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    vLLM
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            vLLM
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../../vllm/open_ai_vllm_example_a_v_t/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Single Request
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../../vllm/bash_vllm_serve/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Bash online serve
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../../vllm/benchmarks/performance_eval/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Benchmarks
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    LLM
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            LLM
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../../llm/speculative_decoding/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Speculative Decoding
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    VLM
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            VLM
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../../vlm/qwen3_vl_4B_object_detection/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Qwen3VL_adema_grounding
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../../vlm/qwen3_vla_4B_audio_training_aspandiyar/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Qwen3VLA_aspandiyar_thinking
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../../md_format_helpers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    MD format helpers
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../../docker/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Docker
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../../linux/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Linux
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../../moe/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Mixture of Experts
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../../slurm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Slurm
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_11" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../../../../../japanese-phrases/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Japanese Phrases
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_11" id="__nav_11_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_11">
            <span class="md-nav__icon md-icon"></span>
            Japanese Phrases
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_11_2" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../../../../../japanese-phrases/daily-life/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Daily Life
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_11_2" id="__nav_11_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_11_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_11_2">
            <span class="md-nav__icon md-icon"></span>
            Daily Life
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../../japanese-phrases/daily-life/shopping/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Shopping
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_11_3" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../../../../../japanese-phrases/greetings/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Greetings
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_11_3" id="__nav_11_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_11_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_11_3">
            <span class="md-nav__icon md-icon"></span>
            Greetings
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../../japanese-phrases/greetings/casual/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Casual
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../../japanese-phrases/emotions/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Emotions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../../japanese-phrases/anime-manga/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Anime/Manga
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../../hackathon/index.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Hack
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#trainer_1" class="md-nav__link">
    <span class="md-ellipsis">
      Trainer
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#seq2seqtrainer" class="md-nav__link">
    <span class="md-ellipsis">
      Seq2SeqTrainer
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#trainingarguments" class="md-nav__link">
    <span class="md-ellipsis">
      TrainingArguments
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#seq2seqtrainingarguments" class="md-nav__link">
    <span class="md-ellipsis">
      Seq2SeqTrainingArguments
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#checkpoints" class="md-nav__link">
    <span class="md-ellipsis">
      Checkpoints
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#logging" class="md-nav__link">
    <span class="md-ellipsis">
      Logging
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#randomness" class="md-nav__link">
    <span class="md-ellipsis">
      Randomness
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#specific-gpus-selection" class="md-nav__link">
    <span class="md-ellipsis">
      Specific GPUs Selection
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#trainer-integrations" class="md-nav__link">
    <span class="md-ellipsis">
      Trainer Integrations
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Trainer Integrations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cuda-extension-installation-notes" class="md-nav__link">
    <span class="md-ellipsis">
      CUDA Extension Installation Notes
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CUDA Extension Installation Notes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#possible-problem-1" class="md-nav__link">
    <span class="md-ellipsis">
      Possible problem #1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#possible-problem-2" class="md-nav__link">
    <span class="md-ellipsis">
      Possible problem #2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#possible-problem-3" class="md-nav__link">
    <span class="md-ellipsis">
      Possible problem #3
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pytorch-fully-sharded-data-parallel" class="md-nav__link">
    <span class="md-ellipsis">
      PyTorch Fully Sharded Data parallel
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pytorchxla-fully-sharded-data-parallel" class="md-nav__link">
    <span class="md-ellipsis">
      PyTorch/XLA Fully Sharded Data parallel
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#using-trainer-for-accelerated-pytorch-training-on-mac" class="md-nav__link">
    <span class="md-ellipsis">
      Using Trainer for accelerated PyTorch Training on Mac
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#using-accelerate-launcher-with-trainer" class="md-nav__link">
    <span class="md-ellipsis">
      Using Accelerate Launcher with Trainer
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<!--Copyright 2020 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.

⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->

<h1 id="trainer">Trainer</h1>
<p>[<code>Trainer</code>] クラスは、ほとんどの標準的なユースケースに対して、PyTorch で機能を完全にトレーニングするための API を提供します。これは、<a href="https://github.com/huggingface/transformers/tree/main/examples">サンプル スクリプト</a> のほとんどで使用されています。</p>
<p>[<code>Trainer</code>] をインスタンス化する前に、トレーニング中にカスタマイズのすべてのポイントにアクセスするために [<code>TrainingArguments</code>] を作成します。</p>
<p>この API は、複数の GPU/TPU での分散トレーニング、PyTorch のネイティブ AMP による混合精度をサポートします。</p>
<p>[<code>Trainer</code>] には、上記の機能をサポートする基本的なトレーニング ループが含まれています。カスタム動作を挿入するには、それらをサブクラス化し、次のメソッドをオーバーライドします。</p>
<ul>
<li><strong>get_train_dataloader</strong> -- トレーニング データローダーを作成します。</li>
<li><strong>get_eval_dataloader</strong> -- 評価用データローダーを作成します。</li>
<li><strong>get_test_dataloader</strong> -- テスト データローダーを作成します。</li>
<li><strong>log</strong> -- トレーニングを監視しているさまざまなオブジェクトに関する情報をログに記録します。</li>
<li><strong>create_optimizer_and_scheduler</strong> -- オプティマイザと学習率スケジューラが渡されなかった場合にセットアップします。
  初期化。 <code>create_optimizer</code>メソッドと<code>create_scheduler</code>メソッドをサブクラス化またはオーバーライドすることもできることに注意してください。
  別々に。</li>
<li><strong>create_optimizer</strong> -- init で渡されなかった場合にオプティマイザーをセットアップします。</li>
<li><strong>create_scheduler</strong> -- init で渡されなかった場合、学習率スケジューラを設定します。</li>
<li><strong>compute_loss</strong> - トレーニング入力のバッチの損失を計算します。</li>
<li><strong>training_step</strong> -- トレーニング ステップを実行します。</li>
<li><strong>prediction_step</strong> -- 評価/テスト ステップを実行します。</li>
<li><strong>evaluate</strong> -- 評価ループを実行し、メトリクスを返します。</li>
<li><strong>predict</strong> -- テスト セットの予測 (ラベルが使用可能な場合はメトリクスも含む) を返します。</li>
</ul>
<p><Tip warning={true}></p>
<p>[<code>Trainer</code>] クラスは 🤗 Transformers モデル用に最適化されており、驚くべき動作をする可能性があります
他の機種で使用する場合。独自のモデルで使用する場合は、次の点を確認してください。</p>
<ul>
<li>モデルは常に [<code>~utils.ModelOutput</code>] のタプルまたはサブクラスを返します。</li>
<li><code>labels</code> 引数が指定され、その損失が最初の値として返される場合、モデルは損失を計算できます。
  タプルの要素 (モデルがタプルを返す場合)</li>
<li>モデルは複数のラベル引数を受け入れることができます ([<code>TrainingArguments</code>] で <code>label_names</code> を使用して、その名前を [<code>Trainer</code>] に示します) が、それらのいずれにも <code>"label"</code> という名前を付ける必要はありません。</li>
</ul>
<p></Tip></p>
<p>以下は、加重損失を使用するように [<code>Trainer</code>] をカスタマイズする方法の例です (不均衡なトレーニング セットがある場合に役立ちます)。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Trainer</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="k">class</span><span class="w"> </span><span class="nc">CustomTrainer</span><span class="p">(</span><span class="n">Trainer</span><span class="p">):</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">compute_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">return_outputs</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>        <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;labels&quot;</span><span class="p">)</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>        <span class="c1"># forward pass</span>
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>
</span><span id="__span-0-10"><a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>        <span class="n">logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;logits&quot;</span><span class="p">)</span>
</span><span id="__span-0-11"><a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>        <span class="c1"># compute custom loss (suppose one has 3 labels with different weights)</span>
</span><span id="__span-0-12"><a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>        <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">weight</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>
</span><span id="__span-0-13"><a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">num_labels</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="__span-0-14"><a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>        <span class="k">return</span> <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span> <span class="k">if</span> <span class="n">return_outputs</span> <span class="k">else</span> <span class="n">loss</span>
</span></code></pre></div>
<p>PyTorch [<code>Trainer</code>] のトレーニング ループの動作をカスタマイズするもう 1 つの方法は、トレーニング ループの状態を検査できる <a href="コールバック">callbacks</a> を使用することです (進行状況レポート、TensorBoard または他の ML プラットフォームでのログ記録など)。決定（早期停止など）。</p>
<h2 id="trainer_1">Trainer</h2>
<p>[[autodoc]] Trainer
    - all</p>
<h2 id="seq2seqtrainer">Seq2SeqTrainer</h2>
<p>[[autodoc]] Seq2SeqTrainer
    - evaluate
    - predict</p>
<h2 id="trainingarguments">TrainingArguments</h2>
<p>[[autodoc]] TrainingArguments
    - all</p>
<h2 id="seq2seqtrainingarguments">Seq2SeqTrainingArguments</h2>
<p>[[autodoc]] Seq2SeqTrainingArguments
    - all</p>
<h2 id="checkpoints">Checkpoints</h2>
<p>デフォルトでは、[<code>Trainer</code>] はすべてのチェックポイントを、
[<code>TrainingArguments</code>] を使用しています。これらは、xxx を含む<code>checkpoint-xxx</code>という名前のサブフォルダーに保存されます。
それはトレーニングの段階でした。</p>
<p>チェックポイントからトレーニングを再開するには、次のいずれかを使用して [<code>Trainer.train</code>] を呼び出します。</p>
<ul>
<li><code>resume_from_checkpoint=True</code> は最新のチェックポイントからトレーニングを再開します</li>
<li><code>resume_from_checkpoint=checkpoint_dir</code> ディレクトリ内の特定のチェックポイントからトレーニングを再開します
  合格した。</li>
</ul>
<p>さらに、<code>push_to_hub=True</code> を使用すると、モデル ハブにチェックポイントを簡単に保存できます。デフォルトでは、すべて
中間チェックポイントに保存されたモデルは別のコミットに保存されますが、オプティマイザーの状態は保存されません。適応できます
[<code>TrainingArguments</code>] の <code>hub-strategy</code> 値を次のいずれかにします。</p>
<ul>
<li><code>"checkpoint"</code>: 最新のチェックポイントも last-checkpoint という名前のサブフォルダーにプッシュされます。
  <code>trainer.train(resume_from_checkpoint="output_dir/last-checkpoint")</code> を使用してトレーニングを簡単に再開します。</li>
<li><code>"all_checkpoints"</code>: すべてのチェックポイントは、出力フォルダーに表示されるようにプッシュされます (したがって、1 つのチェックポイントが得られます)
  最終リポジトリ内のフォルダーごとのチェックポイント フォルダー)</li>
</ul>
<h2 id="logging">Logging</h2>
<p>デフォルトでは、[<code>Trainer</code>] はメインプロセスに <code>logging.INFO</code> を使用し、レプリカがある場合には <code>logging.WARNING</code> を使用します。</p>
<p>これらのデフォルトは、[<code>TrainingArguments</code>] の 5 つの <code>logging</code> レベルのいずれかを使用するようにオーバーライドできます。
引数:</p>
<ul>
<li><code>log_level</code> - メインプロセス用</li>
<li><code>log_level_replica</code> - レプリカ用</li>
</ul>
<p>さらに、[<code>TrainingArguments</code>] の <code>log_on_each_node</code> が <code>False</code> に設定されている場合、メイン ノードのみが
メイン プロセスのログ レベル設定を使用すると、他のすべてのノードはレプリカのログ レベル設定を使用します。</p>
<p>[<code>Trainer</code>] は、<code>transformers</code> のログ レベルをノードごとに個別に設定することに注意してください。
[<code>Trainer.__init__</code>]。したがって、他の機能を利用する場合は、これをより早く設定することをお勧めします (次の例を参照)。
[<code>Trainer</code>] オブジェクトを作成する前の <code>transformers</code> 機能。</p>
<p>これをアプリケーションで使用する方法の例を次に示します。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="p">[</span><span class="o">...</span><span class="p">]</span>
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a><span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a>
</span><span id="__span-1-4"><a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a><span class="c1"># Setup logging</span>
</span><span id="__span-1-5"><a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a><span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span>
</span><span id="__span-1-6"><a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a>    <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;</span><span class="si">%(asctime)s</span><span class="s2"> - </span><span class="si">%(levelname)s</span><span class="s2"> - </span><span class="si">%(name)s</span><span class="s2"> - </span><span class="si">%(message)s</span><span class="s2">&quot;</span><span class="p">,</span>
</span><span id="__span-1-7"><a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a>    <span class="n">datefmt</span><span class="o">=</span><span class="s2">&quot;%m/</span><span class="si">%d</span><span class="s2">/%Y %H:%M:%S&quot;</span><span class="p">,</span>
</span><span id="__span-1-8"><a id="__codelineno-1-8" name="__codelineno-1-8" href="#__codelineno-1-8"></a>    <span class="n">handlers</span><span class="o">=</span><span class="p">[</span><span class="n">logging</span><span class="o">.</span><span class="n">StreamHandler</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="p">)],</span>
</span><span id="__span-1-9"><a id="__codelineno-1-9" name="__codelineno-1-9" href="#__codelineno-1-9"></a><span class="p">)</span>
</span><span id="__span-1-10"><a id="__codelineno-1-10" name="__codelineno-1-10" href="#__codelineno-1-10"></a>
</span><span id="__span-1-11"><a id="__codelineno-1-11" name="__codelineno-1-11" href="#__codelineno-1-11"></a><span class="c1"># set the main code and the modules it uses to the same log-level according to the node</span>
</span><span id="__span-1-12"><a id="__codelineno-1-12" name="__codelineno-1-12" href="#__codelineno-1-12"></a><span class="n">log_level</span> <span class="o">=</span> <span class="n">training_args</span><span class="o">.</span><span class="n">get_process_log_level</span><span class="p">()</span>
</span><span id="__span-1-13"><a id="__codelineno-1-13" name="__codelineno-1-13" href="#__codelineno-1-13"></a><span class="n">logger</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">log_level</span><span class="p">)</span>
</span><span id="__span-1-14"><a id="__codelineno-1-14" name="__codelineno-1-14" href="#__codelineno-1-14"></a><span class="n">datasets</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">set_verbosity</span><span class="p">(</span><span class="n">log_level</span><span class="p">)</span>
</span><span id="__span-1-15"><a id="__codelineno-1-15" name="__codelineno-1-15" href="#__codelineno-1-15"></a><span class="n">transformers</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">set_verbosity</span><span class="p">(</span><span class="n">log_level</span><span class="p">)</span>
</span><span id="__span-1-16"><a id="__codelineno-1-16" name="__codelineno-1-16" href="#__codelineno-1-16"></a>
</span><span id="__span-1-17"><a id="__codelineno-1-17" name="__codelineno-1-17" href="#__codelineno-1-17"></a><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
</span></code></pre></div>
<p>そして、メイン ノードと他のすべてのノードで重複する可能性が高いものを出力しないように警告するだけを表示したい場合は、
警告: 次のように実行できます。</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a>my_app.py<span class="w"> </span>...<span class="w"> </span>--log_level<span class="w"> </span>warning<span class="w"> </span>--log_level_replica<span class="w"> </span>error
</span></code></pre></div>
<p>マルチノード環境で、各ノードのメインプロセスのログを繰り返したくない場合は、次のようにします。
上記を次のように変更します。</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a>my_app.py<span class="w"> </span>...<span class="w"> </span>--log_level<span class="w"> </span>warning<span class="w"> </span>--log_level_replica<span class="w"> </span>error<span class="w"> </span>--log_on_each_node<span class="w"> </span><span class="m">0</span>
</span></code></pre></div>
<p>その後、最初のノードのメイン プロセスのみが「警告」レベルでログに記録され、メイン ノード上の他のすべてのプロセスはログに記録されます。
ノードと他のノード上のすべてのプロセスは「エラー」レベルでログに記録されます。</p>
<p>アプリケーションをできるだけ静かにする必要がある場合は、次のようにします。</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a>my_app.py<span class="w"> </span>...<span class="w"> </span>--log_level<span class="w"> </span>error<span class="w"> </span>--log_level_replica<span class="w"> </span>error<span class="w"> </span>--log_on_each_node<span class="w"> </span><span class="m">0</span>
</span></code></pre></div>
<p>(マルチノード環境の場合は <code>--log_on_each_node 0</code> を追加します)</p>
<h2 id="randomness">Randomness</h2>
<p>[<code>Trainer</code>] によって生成されたチェックポイントから再開する場合、すべての努力がその状態を復元するために行われます。
<em>python</em>、<em>numpy</em>、および <em>pytorch</em> の RNG 状態は、そのチェックポイントを保存した時点と同じ状態になります。
これにより、「停止して再開」というスタイルのトレーニングが、ノンストップトレーニングに可能な限り近づけられるはずです。</p>
<p>ただし、さまざまなデフォルトの非決定的な pytorch 設定により、これは完全に機能しない可能性があります。フルをご希望の場合は
決定論については、<a href="https://pytorch.org/docs/stable/notes/randomness">ランダム性のソースの制御</a> を参照してください。ドキュメントで説明されているように、これらの設定の一部は
物事を決定論的にするもの (例: <code>torch.backends.cudnn.deterministic</code>) は物事を遅くする可能性があるため、これは
デフォルトでは実行できませんが、必要に応じて自分で有効にすることができます。</p>
<h2 id="specific-gpus-selection">Specific GPUs Selection</h2>
<p>どの GPU をどのような順序で使用するかをプログラムに指示する方法について説明します。</p>
<p><a href="https://pytorch.org/docs/stable/generated/torch.nn.Parallel.DistributedDataParallel.html"><code>DistributedDataParallel</code></a> を使用して GPU のサブセットのみを使用する場合、使用する GPU の数を指定するだけです。 。たとえば、GPU が 4 つあるが、最初の 2 つを使用したい場合は、次のようにします。</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a>torchrun<span class="w"> </span>--nproc_per_node<span class="o">=</span><span class="m">2</span><span class="w">  </span>trainer-program.py<span class="w"> </span>...
</span></code></pre></div>
<p><a href="https://github.com/huggingface/accelerate"><code>accelerate</code></a> または <a href="https://github.com/deepspeedai/DeepSpeed"><code>deepspeed</code></a> がインストールされている場合は、次を使用して同じことを達成することもできます。の一つ：</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a>accelerate<span class="w"> </span>launch<span class="w"> </span>--num_processes<span class="w"> </span><span class="m">2</span><span class="w"> </span>trainer-program.py<span class="w"> </span>...
</span></code></pre></div>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-7-1"><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a>deepspeed<span class="w"> </span>--num_gpus<span class="w"> </span><span class="m">2</span><span class="w"> </span>trainer-program.py<span class="w"> </span>...
</span></code></pre></div>
<p>これらのランチャーを使用するために、Accelerate または <a href="deepspeed">Deepspeed 統合</a> 機能を使用する必要はありません。</p>
<p>これまでは、プログラムに使用する GPU の数を指示できました。次に、特定の GPU を選択し、その順序を制御する方法について説明します。</p>
<p>次の環境変数は、使用する GPU とその順序を制御するのに役立ちます。</p>
<p><strong><code>CUDA_VISIBLE_DEVICES</code></strong></p>
<p>複数の GPU があり、そのうちの 1 つまたはいくつかの GPU だけを使用したい場合は、環境変数 <code>CUDA_VISIBLE_DEVICES</code> を使用する GPU のリストに設定します。</p>
<p>たとえば、4 つの GPU (0、1、2、3) があるとします。物理 GPU 0 と 2 のみで実行するには、次のようにします。</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-8-1"><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span>,2<span class="w"> </span>torchrun<span class="w"> </span>trainer-program.py<span class="w"> </span>...
</span></code></pre></div>
<p>したがって、pytorch は 2 つの GPU のみを認識し、物理 GPU 0 と 2 はそれぞれ <code>cuda:0</code> と <code>cuda:1</code> にマッピングされます。</p>
<p>順序を変更することもできます。</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-9-1"><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">2</span>,0<span class="w"> </span>torchrun<span class="w"> </span>trainer-program.py<span class="w"> </span>...
</span></code></pre></div>
<p>ここでは、物理 GPU 0 と 2 がそれぞれ<code>cuda:1</code>と<code>cuda:0</code>にマッピングされています。</p>
<p>上記の例はすべて <code>DistributedDataParallel</code> 使用パターンのものですが、同じ方法が <a href="https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html"><code>DataParallel</code></a> でも機能します。</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-10-1"><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">2</span>,0<span class="w"> </span>python<span class="w"> </span>trainer-program.py<span class="w"> </span>...
</span></code></pre></div>
<p>GPU のない環境をエミュレートするには、次のようにこの環境変数を空の値に設定するだけです。</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-11-1"><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="w"> </span>python<span class="w"> </span>trainer-program.py<span class="w"> </span>...
</span></code></pre></div>
<p>他の環境変数と同様に、これらをコマンド ラインに追加する代わりに、次のようにエクスポートすることもできます。</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-12-1"><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a><span class="nb">export</span><span class="w"> </span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span>,2
</span><span id="__span-12-2"><a id="__codelineno-12-2" name="__codelineno-12-2" href="#__codelineno-12-2"></a>torchrun<span class="w"> </span>trainer-program.py<span class="w"> </span>...
</span></code></pre></div>
<p>ただし、この方法では、以前に環境変数を設定したことを忘れて、なぜ間違った GPU が使用されているのか理解できない可能性があるため、混乱を招く可能性があります。したがって、このセクションのほとんどの例で示されているように、同じコマンド ラインで特定の実行に対してのみ環境変数を設定するのが一般的です。</p>
<p><strong><code>CUDA_DEVICE_ORDER</code></strong></p>
<p>物理デバイスの順序を制御する追加の環境変数 <code>CUDA_DEVICE_ORDER</code> があります。選択肢は次の 2 つです。</p>
<ol>
<li>PCIe バス ID 順 (<code>nvidia-smi</code> の順序と一致) - これがデフォルトです。</li>
</ol>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-13-1"><a id="__codelineno-13-1" name="__codelineno-13-1" href="#__codelineno-13-1"></a><span class="nb">export</span><span class="w"> </span><span class="nv">CUDA_DEVICE_ORDER</span><span class="o">=</span>PCI_BUS_ID
</span></code></pre></div>
<ol>
<li>GPU コンピューティング能力順に並べる</li>
</ol>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-14-1"><a id="__codelineno-14-1" name="__codelineno-14-1" href="#__codelineno-14-1"></a><span class="nb">export</span><span class="w"> </span><span class="nv">CUDA_DEVICE_ORDER</span><span class="o">=</span>FASTEST_FIRST
</span></code></pre></div>
<p>ほとんどの場合、この環境変数を気にする必要はありませんが、古い GPU と新しい GPU が物理的に挿入されているため、遅い古いカードが遅くなっているように見えるような偏ったセットアップを行っている場合には、非常に役立ちます。初め。これを解決する 1 つの方法は、カードを交換することです。ただし、カードを交換できない場合 (デバイスの冷却が影響を受けた場合など)、<code>CUDA_DEVICE_ORDER=FASTEST_FIRST</code>を設定すると、常に新しい高速カードが最初に配置されます。ただし、<code>nvidia-smi</code>は依然として PCIe の順序でレポートするため、多少混乱するでしょう。</p>
<p>順序を入れ替えるもう 1 つの解決策は、以下を使用することです。</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-15-1"><a id="__codelineno-15-1" name="__codelineno-15-1" href="#__codelineno-15-1"></a><span class="nb">export</span><span class="w"> </span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">1</span>,0
</span></code></pre></div>
<p>この例では 2 つの GPU だけを使用していますが、もちろん、コンピューターに搭載されている数の GPU にも同じことが当てはまります。</p>
<p>また、この環境変数を設定する場合は、<code>~/.bashrc</code> ファイルまたはその他の起動設定ファイルに設定して、忘れるのが最善です。</p>
<h2 id="trainer-integrations">Trainer Integrations</h2>
<p>[<code>Trainer</code>] は、トレーニングを劇的に改善する可能性のあるライブラリをサポートするように拡張されました。
時間とはるかに大きなモデルに適合します。</p>
<p>現在、サードパーティのソリューション <a href="https://github.com/deepspeedai/DeepSpeed">DeepSpeed</a> および <a href="https://pytorch.org/docs/stable/fsdp.html">PyTorch FSDP</a> をサポートしています。論文 <a href="https://huggingface.co/papers/1910.02054">ZeRO: メモリの最適化兆パラメータ モデルのトレーニングに向けて、Samyam Rajbhandari、Jeff Rasley、Olatunji Ruwase、Yuxiong He 著</a>。</p>
<p>この提供されるサポートは、この記事の執筆時点では新しくて実験的なものです。 DeepSpeed と PyTorch FSDP のサポートはアクティブであり、それに関する問題は歓迎しますが、FairScale 統合は PyTorch メインに統合されているため、もうサポートしていません (<a href="#pytorch-fully-sharded-data-parallel">PyTorch FSDP 統合</a>)</p>
<p><a id='zero-install-notes'></a></p>
<h3 id="cuda-extension-installation-notes">CUDA Extension Installation Notes</h3>
<p>この記事の執筆時点では、Deepspeed を使用するには、CUDA C++ コードをコンパイルする必要があります。</p>
<p>すべてのインストールの問題は、<a href="https://github.com/deepspeedai/DeepSpeed/issues">Deepspeed</a> の対応する GitHub の問題を通じて対処する必要がありますが、ビルド中に発生する可能性のある一般的な問題がいくつかあります。
CUDA 拡張機能を構築する必要がある PyTorch 拡張機能。</p>
<p>したがって、次の操作を実行中に CUDA 関連のビルドの問題が発生した場合は、次のとおりです。</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-16-1"><a id="__codelineno-16-1" name="__codelineno-16-1" href="#__codelineno-16-1"></a>pip<span class="w"> </span>install<span class="w"> </span>deepspeed
</span></code></pre></div>
<p>まず次の注意事項をお読みください。</p>
<p>これらのノートでは、<code>pytorch</code> が CUDA <code>10.2</code> でビルドされた場合に何をすべきかの例を示します。あなたの状況が次のような場合
異なる場合は、バージョン番号を目的のバージョンに調整することを忘れないでください。</p>
<h4 id="possible-problem-1">Possible problem #1</h4>
<p>Pytorch には独自の CUDA ツールキットが付属していますが、これら 2 つのプロジェクトをビルドするには、同一バージョンの CUDA が必要です。
システム全体にインストールされます。</p>
<p>たとえば、Python 環境に <code>cudatoolkit==10.2</code> を指定して <code>pytorch</code> をインストールした場合は、次のものも必要です。
CUDA <code>10.2</code> がシステム全体にインストールされました。</p>
<p>正確な場所はシステムによって異なる場合がありますが、多くのシステムでは<code>/usr/local/cuda-10.2</code>が最も一般的な場所です。
Unix システム。 CUDA が正しく設定され、<code>PATH</code>環境変数に追加されると、
次のようにしてインストール場所を指定します。</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-17-1"><a id="__codelineno-17-1" name="__codelineno-17-1" href="#__codelineno-17-1"></a>which<span class="w"> </span>nvcc
</span></code></pre></div>
<p>CUDA がシステム全体にインストールされていない場合は、最初にインストールしてください。お気に入りを使用して手順を見つけることができます
検索エンジン。たとえば、Ubuntu を使用している場合は、<a href="https://www.google.com/search?q=ubuntu+cuda+10.2+install">ubuntu cuda 10.2 install</a> を検索するとよいでしょう。</p>
<h4 id="possible-problem-2">Possible problem #2</h4>
<p>もう 1 つの考えられる一般的な問題は、システム全体に複数の CUDA ツールキットがインストールされている可能性があることです。たとえばあなた
がある可能性があり：</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-18-1"><a id="__codelineno-18-1" name="__codelineno-18-1" href="#__codelineno-18-1"></a>/usr/local/cuda-10.2
</span><span id="__span-18-2"><a id="__codelineno-18-2" name="__codelineno-18-2" href="#__codelineno-18-2"></a>/usr/local/cuda-11.0
</span></code></pre></div>
<p>この状況では、<code>PATH</code> および <code>LD_LIBRARY_PATH</code> 環境変数に以下が含まれていることを確認する必要があります。
目的の CUDA バージョンへの正しいパス。通常、パッケージ インストーラーは、これらに、
最後のバージョンがインストールされました。適切なパッケージが見つからないためにパッケージのビルドが失敗するという問題が発生した場合は、
CUDA バージョンがシステム全体にインストールされているにもかかわらず、前述の 2 つを調整する必要があることを意味します
環境変数。</p>
<p>まず、その内容を見てみましょう。</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-19-1"><a id="__codelineno-19-1" name="__codelineno-19-1" href="#__codelineno-19-1"></a><span class="nb">echo</span><span class="w"> </span><span class="nv">$PATH</span>
</span><span id="__span-19-2"><a id="__codelineno-19-2" name="__codelineno-19-2" href="#__codelineno-19-2"></a><span class="nb">echo</span><span class="w"> </span><span class="nv">$LD_LIBRARY_PATH</span>
</span></code></pre></div>
<p>それで、中に何が入っているかがわかります。</p>
<p><code>LD_LIBRARY_PATH</code> が空である可能性があります。</p>
<p><code>PATH</code> は実行可能ファイルが存在する場所をリストし、<code>LD_LIBRARY_PATH</code> は共有ライブラリの場所を示します。
探すことです。どちらの場合も、前のエントリが後のエントリより優先されます。 <code>:</code> は複数を区切るために使用されます
エントリ。</p>
<p>ここで、ビルド プログラムに特定の CUDA ツールキットの場所を指示するには、最初にリストされる希望のパスを挿入します。
やっていること：</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-20-1"><a id="__codelineno-20-1" name="__codelineno-20-1" href="#__codelineno-20-1"></a><span class="nb">export</span><span class="w"> </span><span class="nv">PATH</span><span class="o">=</span>/usr/local/cuda-10.2/bin:<span class="nv">$PATH</span>
</span><span id="__span-20-2"><a id="__codelineno-20-2" name="__codelineno-20-2" href="#__codelineno-20-2"></a><span class="nb">export</span><span class="w"> </span><span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span>/usr/local/cuda-10.2/lib64:<span class="nv">$LD_LIBRARY_PATH</span>
</span></code></pre></div>
<p>既存の値を上書きするのではなく、先頭に追加することに注意してください。</p>
<p>もちろん、必要に応じてバージョン番号やフルパスを調整します。割り当てたディレクトリが実際に機能することを確認してください
存在する。 <code>lib64</code> サブディレクトリは、<code>libcudart.so</code> などのさまざまな CUDA <code>.so</code> オブジェクトが存在する場所です。
システムでは別の名前が付けられますが、現実を反映するように調整してください。</p>
<h4 id="possible-problem-3">Possible problem #3</h4>
<p>一部の古い CUDA バージョンは、新しいコンパイラでのビルドを拒否する場合があります。たとえば、あなたは<code>gcc-9</code>を持っていますが、それが必要です
<code>gcc-7</code>。</p>
<p>それにはさまざまな方法があります。</p>
<p>最新の CUDA ツールキットをインストールできる場合は、通常、新しいコンパイラがサポートされているはずです。</p>
<p>あるいは、既に所有しているコンパイラに加えて、下位バージョンのコンパイラをインストールすることもできます。
すでに存在しますが、デフォルトではないため、ビルドシステムはそれを認識できません。 「gcc-7」がインストールされているが、
ビルドシステムが見つからないというメッセージを表示する場合は、次の方法で解決できる可能性があります。</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-21-1"><a id="__codelineno-21-1" name="__codelineno-21-1" href="#__codelineno-21-1"></a>sudo<span class="w"> </span>ln<span class="w"> </span>-s<span class="w"> </span>/usr/bin/gcc-7<span class="w">  </span>/usr/local/cuda-10.2/bin/gcc
</span><span id="__span-21-2"><a id="__codelineno-21-2" name="__codelineno-21-2" href="#__codelineno-21-2"></a>sudo<span class="w"> </span>ln<span class="w"> </span>-s<span class="w"> </span>/usr/bin/g++-7<span class="w">  </span>/usr/local/cuda-10.2/bin/g++
</span></code></pre></div>
<p>ここでは、<code>/usr/local/cuda-10.2/bin/gcc</code> から <code>gcc-7</code> へのシンボリックリンクを作成しています。
<code>/usr/local/cuda-10.2/bin/</code> は <code>PATH</code> 環境変数内にある必要があります (前の問題の解決策を参照)。
<code>gcc-7</code> (および <code>g++7</code>) が見つかるはずで、ビルドは成功します。</p>
<p>いつものように、状況に合わせて例のパスを編集してください。</p>
<h3 id="pytorch-fully-sharded-data-parallel">PyTorch Fully Sharded Data parallel</h3>
<p>より大きなバッチ サイズで巨大なモデルのトレーニングを高速化するには、完全にシャード化されたデータ並列モデルを使用できます。
このタイプのデータ並列パラダイムでは、オプティマイザーの状態、勾配、パラメーターをシャーディングすることで、より多くのデータと大規模なモデルをフィッティングできます。
この機能とその利点の詳細については、<a href="https://pytorch.org/blog/introducing-pytorch-full-sharded-data-Parallel-api/">完全シャーディング データ並列ブログ</a> をご覧ください。
最新の PyTorch の Fully Sharded Data Parallel (FSDP) トレーニング機能を統合しました。
必要なのは、設定を通じて有効にすることだけです。</p>
<p><strong>FSDP サポートに必要な PyTorch バージョン</strong>: PyTorch Nightly (リリース後にこれを読んだ場合は 1.12.0)
FSDP を有効にしたモデルの保存は、最近の修正でのみ利用できるためです。</p>
<p><strong>使用法</strong>：</p>
<ul>
<li>
<p>配布されたランチャーが追加されていることを確認してください
まだ使用していない場合は、<code>-m torch.distributed.launch --nproc_per_node=NUMBER_OF_GPUS_YOU_HAVE</code>を使用します。</p>
</li>
<li>
<p><strong>シャーディング戦略</strong>:</p>
</li>
<li>FULL_SHARD : データ並列ワーカー/GPU にわたるシャード オプティマイザーの状態 + 勾配 + モデル パラメーター。
    このためには、コマンドライン引数に<code>--fsdp full_shard</code>を追加します。</li>
<li>SHARD_GRAD_OP : シャード オプティマイザーの状態 + データ並列ワーカー/GPU 全体の勾配。
    このためには、コマンドライン引数に<code>--fsdp shard_grad_op</code>を追加します。</li>
<li>NO_SHARD : シャーディングなし。このためには、コマンドライン引数に<code>--fsdp no_shard</code>を追加します。</li>
<li>パラメータと勾配を CPU にオフロードするには、
  コマンドライン引数に<code>--fsdp "full_shard offload"</code>または<code>--fsdp "shard_grad_op offload"</code>を追加します。</li>
<li><code>default_auto_wrap_policy</code> を使用して FSDP でレイヤーを自動的に再帰的にラップするには、
  コマンドライン引数に<code>--fsdp "full_shard auto_wrap"</code>または<code>--fsdp "shard_grad_op auto_wrap"</code>を追加します。</li>
<li>CPU オフロードと自動ラッピングの両方を有効にするには、
  コマンドライン引数に<code>--fsdp "full_shard offload auto_wrap"</code>または<code>--fsdp "shard_grad_op offload auto_wrap"</code>を追加します。</li>
<li>残りの FSDP 構成は、<code>--fsdp_config &lt;path_to_fsdp_config.json&gt;</code>を介して渡されます。それは、次のいずれかの場所です。
  FSDP json 構成ファイル (例: <code>fsdp_config.json</code>)、またはすでにロードされている json ファイルを <code>dict</code> として使用します。</li>
<li>自動ラッピングが有効な場合は、トランスベースの自動ラップ ポリシーまたはサイズ ベースの自動ラップ ポリシーを使用できます。<ul>
<li>トランスフォーマーベースの自動ラップポリシーの場合、構成ファイルで <code>fsdp_transformer_layer_cls_to_wrap</code> を指定することをお勧めします。指定しない場合、使用可能な場合、デフォルト値は <code>model._no_split_modules</code> になります。
  これは、ラップするトランスフォーマー層クラス名のリスト (大文字と小文字を区別) を指定します (例: [<code>BertLayer</code>]、[<code>GPTJBlock</code>]、[<code>T5Block</code>] ...)。
  重みを共有するサブモジュール (埋め込み層など) が異なる FSDP ラップされたユニットにならないようにする必要があるため、これは重要です。
  このポリシーを使用すると、マルチヘッド アテンションとそれに続くいくつかの MLP レイヤーを含むブロックごとにラッピングが発生します。
  共有埋め込みを含む残りの層は、同じ最も外側の FSDP ユニットにラップされるのが便利です。
  したがって、トランスベースのモデルにはこれを使用してください。</li>
<li>サイズベースの自動ラップポリシーの場合は、設定ファイルに<code>fsdp_min_num_params</code>を追加してください。
  自動ラッピングのための FSDP のパラメータの最小数を指定します。</li>
</ul>
</li>
<li>設定ファイルで <code>fsdp_backward_prefetch</code> を指定できるようになりました。次のパラメータのセットをいつプリフェッチするかを制御します。
    <code>backward_pre</code> と <code>backward_pos</code> が利用可能なオプションです。
    詳細については、<code>torch.distributed.fsdp.full_sharded_data_Parallel.BackwardPrefetch</code>を参照してください。</li>
<li>設定ファイルで <code>fsdp_forward_prefetch</code> を指定できるようになりました。次のパラメータのセットをいつプリフェッチするかを制御します。
    <code>True</code>の場合、FSDP はフォワード パスでの実行中に、次に来るオールギャザーを明示的にプリフェッチします。</li>
<li>設定ファイルで <code>limit_all_gathers</code> を指定できるようになりました。
    <code>True</code>の場合、FSDP は CPU スレッドを明示的に同期して、実行中のオールギャザが多すぎるのを防ぎます。</li>
<li><code>activation_checkpointing</code>を設定ファイルで指定できるようになりました。
    <code>True</code>の場合、FSDP アクティベーション チェックポイントは、FSDP のアクティベーションをクリアすることでメモリ使用量を削減する手法です。
    特定のレイヤーを処理し、バックワード パス中にそれらを再計算します。事実上、これは余分な計算時間を犠牲にします
    メモリ使用量を削減します。</li>
</ul>
<p><strong>注意すべき注意点がいくつかあります</strong>
- これは <code>generate</code> と互換性がないため、 <code>--predict_with_generate</code> とも互換性がありません
  すべての seq2seq/clm スクリプト (翻訳/要約/clm など)。
  問題 <a href="https://github.com/huggingface/transformers/issues/21667">#21667</a> を参照してください。</p>
<h3 id="pytorchxla-fully-sharded-data-parallel">PyTorch/XLA Fully Sharded Data parallel</h3>
<p>TPU ユーザーの皆様に朗報です。 PyTorch/XLA は FSDP をサポートするようになりました。
最新の Fully Sharded Data Parallel (FSDP) トレーニングがすべてサポートされています。
詳細については、<a href="https://pytorch.org/blog/scaling-pytorch-models-on-cloud-tpus-with-fsdp/">FSDP を使用した Cloud TPU での PyTorch モデルのスケーリング</a> および <a href="https://github.com/pytorch/xla/tree/master/torch_xla/distributed/fsdp">PyTorch/XLA 実装 を参照してください。 FSDP の</a>
必要なのは、設定を通じて有効にすることだけです。</p>
<p><strong>FSDP サポートに必要な PyTorch/XLA バージョン</strong>: &gt;=2.0</p>
<p><strong>使用法</strong>：</p>
<p><code>--fsdp "full shard"</code> を、<code>--fsdp_config &lt;path_to_fsdp_config.json&gt;</code> に加えられる次の変更とともに渡します。
- PyTorch/XLA FSDP を有効にするには、<code>xla</code>を<code>True</code>に設定する必要があります。
- <code>xla_fsdp_settings</code> 値は、XLA FSDP ラッピング パラメータを格納する辞書です。
  オプションの完全なリストについては、<a href="https://github.com/pytorch/xla/blob/master/torch_xla/distributed/fsdp/xla_full_sharded_data_Parallel.py">こちら</a>。
- <code>xla_fsdp_grad_ckpt</code>。 <code>True</code>の場合、ネストされた XLA FSDP でラップされた各レイヤー上で勾配チェックポイントを使用します。
  この設定は、xla フラグが true に設定されており、自動ラッピング ポリシーが指定されている場合にのみ使用できます。
  <code>fsdp_min_num_params</code> または <code>fsdp_transformer_layer_cls_to_wrap</code>。
- トランスフォーマー ベースの自動ラップ ポリシーまたはサイズ ベースの自動ラップ ポリシーのいずれかを使用できます。
  - トランスフォーマーベースの自動ラップポリシーの場合、構成ファイルで <code>fsdp_transformer_layer_cls_to_wrap</code> を指定することをお勧めします。指定しない場合、使用可能な場合、デフォルト値は <code>model._no_split_modules</code> になります。
    これは、ラップするトランスフォーマー層クラス名のリスト (大文字と小文字を区別) を指定します (例: [<code>BertLayer</code>]、[<code>GPTJBlock</code>]、[<code>T5Block</code>] ...)。
    重みを共有するサブモジュール (埋め込み層など) が異なる FSDP ラップされたユニットにならないようにする必要があるため、これは重要です。
    このポリシーを使用すると、マルチヘッド アテンションとそれに続くいくつかの MLP レイヤーを含むブロックごとにラッピングが発生します。
    共有埋め込みを含む残りの層は、同じ最も外側の FSDP ユニットにラップされるのが便利です。
    したがって、トランスベースのモデルにはこれを使用してください。
  - サイズベースの自動ラップポリシーの場合は、設定ファイルに<code>fsdp_min_num_params</code>を追加してください。
    自動ラッピングのための FSDP のパラメータの最小数を指定します。</p>
<h3 id="using-trainer-for-accelerated-pytorch-training-on-mac">Using Trainer for accelerated PyTorch Training on Mac</h3>
<p>PyTorch v1.12 リリースにより、開発者と研究者は Apple シリコン GPU を利用してモデル トレーニングを大幅に高速化できます。
これにより、プロトタイピングや微調整などの機械学習ワークフローを Mac 上でローカルで実行できるようになります。
PyTorch のバックエンドとしての Apple の Metal Performance Shaders (MPS) はこれを可能にし、新しい <code>"mps"</code> デバイス経由で使用できます。
これにより、計算グラフとプリミティブが MPS Graph フレームワークと MPS によって提供される調整されたカーネルにマッピングされます。
詳細については、公式ドキュメント <a href="https://pytorch.org/blog/introducing-accelerated-pytorch-training-on-mac/">Mac での Accelerated PyTorch Training の紹介</a> を参照してください。
および <a href="https://pytorch.org/docs/stable/notes/mps.html">MPS バックエンド</a>。</p>
<p><Tip warning={false}></p>
<p>MacOS マシンに PyTorch &gt;= 1.13 (執筆時点ではナイトリー バージョン) をインストールすることを強くお勧めします。
トランスベースのモデルのモデルの正確性とパフォーマンスの向上に関連する主要な修正が行われています。
詳細については、https://github.com/pytorch/pytorch/issues/82707 を参照してください。</p>
<p></Tip></p>
<p><strong>Apple Silicon チップを使用したトレーニングと推論の利点</strong></p>
<ol>
<li>ユーザーがローカルで大規模なネットワークやバッチ サイズをトレーニングできるようにします</li>
<li>ユニファイド メモリ アーキテクチャにより、データ取得の遅延が短縮され、GPU がメモリ ストア全体に直接アクセスできるようになります。
したがって、エンドツーエンドのパフォーマンスが向上します。</li>
<li>クラウドベースの開発に関連するコストや追加のローカル GPU の必要性を削減します。</li>
</ol>
<p><strong>前提条件</strong>: mps サポートを備えたトーチをインストールするには、
この素晴らしいメディア記事 <a href="https://medium.com/towards-data-science/gpu-acceleration-comes-to-pytorch-on-m1-macs-195c399efcc1">GPU アクセラレーションが M1 Mac の PyTorch に登場</a> に従ってください。 。</p>
<p><strong>使用法</strong>：
<code>mps</code> デバイスは、<code>cuda</code> デバイスが使用される方法と同様に利用可能な場合、デフォルトで使用されます。
したがって、ユーザーによるアクションは必要ありません。
たとえば、以下のコマンドを使用して、Apple Silicon GPU を使用して公式の Glue テキスト分類タスクを (ルート フォルダーから) 実行できます。</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-22-1"><a id="__codelineno-22-1" name="__codelineno-22-1" href="#__codelineno-22-1"></a><span class="nb">export</span><span class="w"> </span><span class="nv">TASK_NAME</span><span class="o">=</span>mrpc
</span><span id="__span-22-2"><a id="__codelineno-22-2" name="__codelineno-22-2" href="#__codelineno-22-2"></a>
</span><span id="__span-22-3"><a id="__codelineno-22-3" name="__codelineno-22-3" href="#__codelineno-22-3"></a>python<span class="w"> </span>examples/pytorch/text-classification/run_glue.py<span class="w"> </span><span class="se">\</span>
</span><span id="__span-22-4"><a id="__codelineno-22-4" name="__codelineno-22-4" href="#__codelineno-22-4"></a><span class="w">  </span>--model_name_or_path<span class="w"> </span>google-bert/bert-base-cased<span class="w"> </span><span class="se">\</span>
</span><span id="__span-22-5"><a id="__codelineno-22-5" name="__codelineno-22-5" href="#__codelineno-22-5"></a><span class="w">  </span>--task_name<span class="w"> </span><span class="nv">$TASK_NAME</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-22-6"><a id="__codelineno-22-6" name="__codelineno-22-6" href="#__codelineno-22-6"></a><span class="w">  </span>--do_train<span class="w"> </span><span class="se">\</span>
</span><span id="__span-22-7"><a id="__codelineno-22-7" name="__codelineno-22-7" href="#__codelineno-22-7"></a><span class="w">  </span>--do_eval<span class="w"> </span><span class="se">\</span>
</span><span id="__span-22-8"><a id="__codelineno-22-8" name="__codelineno-22-8" href="#__codelineno-22-8"></a><span class="w">  </span>--max_seq_length<span class="w"> </span><span class="m">128</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-22-9"><a id="__codelineno-22-9" name="__codelineno-22-9" href="#__codelineno-22-9"></a><span class="w">  </span>--per_device_train_batch_size<span class="w"> </span><span class="m">32</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-22-10"><a id="__codelineno-22-10" name="__codelineno-22-10" href="#__codelineno-22-10"></a><span class="w">  </span>--learning_rate<span class="w"> </span>2e-5<span class="w"> </span><span class="se">\</span>
</span><span id="__span-22-11"><a id="__codelineno-22-11" name="__codelineno-22-11" href="#__codelineno-22-11"></a><span class="w">  </span>--num_train_epochs<span class="w"> </span><span class="m">3</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-22-12"><a id="__codelineno-22-12" name="__codelineno-22-12" href="#__codelineno-22-12"></a><span class="w">  </span>--output_dir<span class="w"> </span>/tmp/<span class="nv">$TASK_NAME</span>/<span class="w"> </span><span class="se">\</span>
</span></code></pre></div>
<p><strong>注意すべきいくつかの注意事項</strong></p>
<ol>
<li>一部の PyTorch 操作は mps に実装されていないため、エラーがスローされます。
これを回避する 1 つの方法は、環境変数 <code>PYTORCH_ENABLE_MPS_FALLBACK=1</code> を設定することです。
これらの操作では CPU にフォールバックします。ただし、それでも UserWarning がスローされます。</li>
<li>分散セットアップ<code>gloo</code>および<code>nccl</code>は、<code>mps</code>デバイスでは動作しません。
これは、現在「mps」デバイス タイプの単一 GPU のみを使用できることを意味します。</li>
</ol>
<p>最後に、覚えておいてください。 🤗 <code>Trainer</code> は MPS バックエンドのみを統合するため、
MPS バックエンドの使用に関して問題や質問がある場合は、
<a href="https://github.com/pytorch/pytorch/issues">PyTorch GitHub</a> に問題を提出してください。</p>
<h2 id="using-accelerate-launcher-with-trainer">Using Accelerate Launcher with Trainer</h2>
<p>加速してトレーナーにパワーを与えましょう。ユーザーが期待することに関しては、次のとおりです。
- トレーナー引数に対して FSDP、DeepSpeed などのトレーナー インテレーションを変更せずに使用し続けることができます。
- トレーナーで Accelerate Launcher を使用できるようになりました (推奨)。</p>
<p>トレーナーで Accelerate Launcher を使用する手順:
1. 🤗 Accelerate がインストールされていることを確認してください。Accelerate がないと <code>Trainer</code> を使用することはできません。そうでない場合は、<code>pip install accelerate</code>してください。 Accelerate のバージョンを更新する必要がある場合もあります: <code>pip install activate --upgrade</code>
2. <code>accelerate config</code>を実行し、アンケートに記入します。以下は加速設定の例です。
  ａ． DDP マルチノード マルチ GPU 構成:
    <div class="language-yaml highlight"><pre><span></span><code><span id="__span-23-1"><a id="__codelineno-23-1" name="__codelineno-23-1" href="#__codelineno-23-1"></a><span class="nt">compute_environment</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">LOCAL_MACHINE</span><span class="w">                                                                                             </span>
</span><span id="__span-23-2"><a id="__codelineno-23-2" name="__codelineno-23-2" href="#__codelineno-23-2"></a><span class="nt">distributed_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">MULTI_GPU</span><span class="w">                                                                                                    </span>
</span><span id="__span-23-3"><a id="__codelineno-23-3" name="__codelineno-23-3" href="#__codelineno-23-3"></a><span class="nt">downcast_bf16</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;no&#39;</span>
</span><span id="__span-23-4"><a id="__codelineno-23-4" name="__codelineno-23-4" href="#__codelineno-23-4"></a><span class="nt">gpu_ids</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">all</span>
</span><span id="__span-23-5"><a id="__codelineno-23-5" name="__codelineno-23-5" href="#__codelineno-23-5"></a><span class="nt">machine_rank</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span><span class="w"> </span><span class="c1">#change rank as per the node</span>
</span><span id="__span-23-6"><a id="__codelineno-23-6" name="__codelineno-23-6" href="#__codelineno-23-6"></a><span class="nt">main_process_ip</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">192.168.20.1</span>
</span><span id="__span-23-7"><a id="__codelineno-23-7" name="__codelineno-23-7" href="#__codelineno-23-7"></a><span class="nt">main_process_port</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">9898</span>
</span><span id="__span-23-8"><a id="__codelineno-23-8" name="__codelineno-23-8" href="#__codelineno-23-8"></a><span class="nt">main_training_function</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">main</span>
</span><span id="__span-23-9"><a id="__codelineno-23-9" name="__codelineno-23-9" href="#__codelineno-23-9"></a><span class="nt">mixed_precision</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">fp16</span>
</span><span id="__span-23-10"><a id="__codelineno-23-10" name="__codelineno-23-10" href="#__codelineno-23-10"></a><span class="nt">num_machines</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
</span><span id="__span-23-11"><a id="__codelineno-23-11" name="__codelineno-23-11" href="#__codelineno-23-11"></a><span class="nt">num_processes</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8</span>
</span><span id="__span-23-12"><a id="__codelineno-23-12" name="__codelineno-23-12" href="#__codelineno-23-12"></a><span class="nt">rdzv_backend</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">static</span>
</span><span id="__span-23-13"><a id="__codelineno-23-13" name="__codelineno-23-13" href="#__codelineno-23-13"></a><span class="nt">same_network</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
</span><span id="__span-23-14"><a id="__codelineno-23-14" name="__codelineno-23-14" href="#__codelineno-23-14"></a><span class="nt">tpu_env</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[]</span>
</span><span id="__span-23-15"><a id="__codelineno-23-15" name="__codelineno-23-15" href="#__codelineno-23-15"></a><span class="nt">tpu_use_cluster</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
</span><span id="__span-23-16"><a id="__codelineno-23-16" name="__codelineno-23-16" href="#__codelineno-23-16"></a><span class="nt">tpu_use_sudo</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
</span><span id="__span-23-17"><a id="__codelineno-23-17" name="__codelineno-23-17" href="#__codelineno-23-17"></a><span class="nt">use_cpu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
</span></code></pre></div></p>
<p>b. FSDP config:
    <div class="language-yaml highlight"><pre><span></span><code><span id="__span-24-1"><a id="__codelineno-24-1" name="__codelineno-24-1" href="#__codelineno-24-1"></a><span class="nt">compute_environment</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">LOCAL_MACHINE</span>
</span><span id="__span-24-2"><a id="__codelineno-24-2" name="__codelineno-24-2" href="#__codelineno-24-2"></a><span class="nt">distributed_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">FSDP</span>
</span><span id="__span-24-3"><a id="__codelineno-24-3" name="__codelineno-24-3" href="#__codelineno-24-3"></a><span class="nt">downcast_bf16</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;no&#39;</span>
</span><span id="__span-24-4"><a id="__codelineno-24-4" name="__codelineno-24-4" href="#__codelineno-24-4"></a><span class="nt">fsdp_config</span><span class="p">:</span>
</span><span id="__span-24-5"><a id="__codelineno-24-5" name="__codelineno-24-5" href="#__codelineno-24-5"></a><span class="w">  </span><span class="nt">fsdp_auto_wrap_policy</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">TRANSFORMER_BASED_WRAP</span>
</span><span id="__span-24-6"><a id="__codelineno-24-6" name="__codelineno-24-6" href="#__codelineno-24-6"></a><span class="w">  </span><span class="nt">fsdp_backward_prefetch_policy</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">BACKWARD_PRE</span>
</span><span id="__span-24-7"><a id="__codelineno-24-7" name="__codelineno-24-7" href="#__codelineno-24-7"></a><span class="w">  </span><span class="nt">fsdp_forward_prefetch</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
</span><span id="__span-24-8"><a id="__codelineno-24-8" name="__codelineno-24-8" href="#__codelineno-24-8"></a><span class="w">  </span><span class="nt">fsdp_offload_params</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
</span><span id="__span-24-9"><a id="__codelineno-24-9" name="__codelineno-24-9" href="#__codelineno-24-9"></a><span class="w">  </span><span class="nt">fsdp_sharding_strategy</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
</span><span id="__span-24-10"><a id="__codelineno-24-10" name="__codelineno-24-10" href="#__codelineno-24-10"></a><span class="w">  </span><span class="nt">fsdp_state_dict_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">FULL_STATE_DICT</span>
</span><span id="__span-24-11"><a id="__codelineno-24-11" name="__codelineno-24-11" href="#__codelineno-24-11"></a><span class="w">  </span><span class="nt">fsdp_sync_module_states</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
</span><span id="__span-24-12"><a id="__codelineno-24-12" name="__codelineno-24-12" href="#__codelineno-24-12"></a><span class="w">  </span><span class="nt">fsdp_transformer_layer_cls_to_wrap</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">BertLayer</span>
</span><span id="__span-24-13"><a id="__codelineno-24-13" name="__codelineno-24-13" href="#__codelineno-24-13"></a><span class="w">  </span><span class="nt">fsdp_use_orig_params</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
</span><span id="__span-24-14"><a id="__codelineno-24-14" name="__codelineno-24-14" href="#__codelineno-24-14"></a><span class="nt">machine_rank</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
</span><span id="__span-24-15"><a id="__codelineno-24-15" name="__codelineno-24-15" href="#__codelineno-24-15"></a><span class="nt">main_training_function</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">main</span>
</span><span id="__span-24-16"><a id="__codelineno-24-16" name="__codelineno-24-16" href="#__codelineno-24-16"></a><span class="nt">mixed_precision</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">bf16</span>
</span><span id="__span-24-17"><a id="__codelineno-24-17" name="__codelineno-24-17" href="#__codelineno-24-17"></a><span class="nt">num_machines</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
</span><span id="__span-24-18"><a id="__codelineno-24-18" name="__codelineno-24-18" href="#__codelineno-24-18"></a><span class="nt">num_processes</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
</span><span id="__span-24-19"><a id="__codelineno-24-19" name="__codelineno-24-19" href="#__codelineno-24-19"></a><span class="nt">rdzv_backend</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">static</span>
</span><span id="__span-24-20"><a id="__codelineno-24-20" name="__codelineno-24-20" href="#__codelineno-24-20"></a><span class="nt">same_network</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
</span><span id="__span-24-21"><a id="__codelineno-24-21" name="__codelineno-24-21" href="#__codelineno-24-21"></a><span class="nt">tpu_env</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[]</span>
</span><span id="__span-24-22"><a id="__codelineno-24-22" name="__codelineno-24-22" href="#__codelineno-24-22"></a><span class="nt">tpu_use_cluster</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
</span><span id="__span-24-23"><a id="__codelineno-24-23" name="__codelineno-24-23" href="#__codelineno-24-23"></a><span class="nt">tpu_use_sudo</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
</span><span id="__span-24-24"><a id="__codelineno-24-24" name="__codelineno-24-24" href="#__codelineno-24-24"></a><span class="nt">use_cpu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
</span></code></pre></div>
  c.ファイルを指す DeepSpeed 構成:
    <div class="language-yaml highlight"><pre><span></span><code><span id="__span-25-1"><a id="__codelineno-25-1" name="__codelineno-25-1" href="#__codelineno-25-1"></a><span class="nt">compute_environment</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">LOCAL_MACHINE</span>
</span><span id="__span-25-2"><a id="__codelineno-25-2" name="__codelineno-25-2" href="#__codelineno-25-2"></a><span class="nt">deepspeed_config</span><span class="p">:</span>
</span><span id="__span-25-3"><a id="__codelineno-25-3" name="__codelineno-25-3" href="#__codelineno-25-3"></a><span class="w">  </span><span class="nt">deepspeed_config_file</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">/home/user/configs/ds_zero3_config.json</span>
</span><span id="__span-25-4"><a id="__codelineno-25-4" name="__codelineno-25-4" href="#__codelineno-25-4"></a><span class="w">  </span><span class="nt">zero3_init_flag</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
</span><span id="__span-25-5"><a id="__codelineno-25-5" name="__codelineno-25-5" href="#__codelineno-25-5"></a><span class="nt">distributed_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">DEEPSPEED</span>
</span><span id="__span-25-6"><a id="__codelineno-25-6" name="__codelineno-25-6" href="#__codelineno-25-6"></a><span class="nt">downcast_bf16</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;no&#39;</span>
</span><span id="__span-25-7"><a id="__codelineno-25-7" name="__codelineno-25-7" href="#__codelineno-25-7"></a><span class="nt">machine_rank</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
</span><span id="__span-25-8"><a id="__codelineno-25-8" name="__codelineno-25-8" href="#__codelineno-25-8"></a><span class="nt">main_training_function</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">main</span>
</span><span id="__span-25-9"><a id="__codelineno-25-9" name="__codelineno-25-9" href="#__codelineno-25-9"></a><span class="nt">num_machines</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
</span><span id="__span-25-10"><a id="__codelineno-25-10" name="__codelineno-25-10" href="#__codelineno-25-10"></a><span class="nt">num_processes</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">4</span>
</span><span id="__span-25-11"><a id="__codelineno-25-11" name="__codelineno-25-11" href="#__codelineno-25-11"></a><span class="nt">rdzv_backend</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">static</span>
</span><span id="__span-25-12"><a id="__codelineno-25-12" name="__codelineno-25-12" href="#__codelineno-25-12"></a><span class="nt">same_network</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
</span><span id="__span-25-13"><a id="__codelineno-25-13" name="__codelineno-25-13" href="#__codelineno-25-13"></a><span class="nt">tpu_env</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[]</span>
</span><span id="__span-25-14"><a id="__codelineno-25-14" name="__codelineno-25-14" href="#__codelineno-25-14"></a><span class="nt">tpu_use_cluster</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
</span><span id="__span-25-15"><a id="__codelineno-25-15" name="__codelineno-25-15" href="#__codelineno-25-15"></a><span class="nt">tpu_use_sudo</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
</span><span id="__span-25-16"><a id="__codelineno-25-16" name="__codelineno-25-16" href="#__codelineno-25-16"></a><span class="nt">use_cpu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
</span></code></pre></div></p>
<p>d.加速プラグインを使用した DeepSpeed 構成:</p>
<div class="language-bash highlight"><pre><span></span><code><span class="sb">```</span>yaml
compute_environment:<span class="w"> </span>LOCAL_MACHINE<span class="w">                                                                                             </span>
deepspeed_config:<span class="w">                                                                                                              </span>
<span class="w">  </span>gradient_accumulation_steps:<span class="w"> </span><span class="m">1</span>
<span class="w">  </span>gradient_clipping:<span class="w"> </span><span class="m">0</span>.7
<span class="w">  </span>offload_optimizer_device:<span class="w"> </span>cpu
<span class="w">  </span>offload_param_device:<span class="w"> </span>cpu
<span class="w">  </span>zero3_init_flag:<span class="w"> </span><span class="nb">true</span>
<span class="w">  </span>zero_stage:<span class="w"> </span><span class="m">2</span>
distributed_type:<span class="w"> </span>DEEPSPEED
downcast_bf16:<span class="w"> </span><span class="s1">&#39;no&#39;</span>
machine_rank:<span class="w"> </span><span class="m">0</span>
main_training_function:<span class="w"> </span>main
mixed_precision:<span class="w"> </span>bf16
num_machines:<span class="w"> </span><span class="m">1</span>
num_processes:<span class="w"> </span><span class="m">4</span>
rdzv_backend:<span class="w"> </span>static
same_network:<span class="w"> </span><span class="nb">true</span>
tpu_env:<span class="w"> </span><span class="o">[]</span>
tpu_use_cluster:<span class="w"> </span><span class="nb">false</span>
tpu_use_sudo:<span class="w"> </span><span class="nb">false</span>
use_cpu:<span class="w"> </span><span class="nb">false</span>
<span class="sb">```</span>
</code></pre></div>
<ol>
<li>加速設定またはランチャー引数によって上記で処理された引数以外の引数を使用して、トレーナー スクリプトを実行します。
以下は、上記の FSDP 構成で<code>accelerate launcher</code>を使用して<code>run_glue.py</code>を実行する例です。 </li>
</ol>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-27-1"><a id="__codelineno-27-1" name="__codelineno-27-1" href="#__codelineno-27-1"></a><span class="nb">cd</span><span class="w"> </span>transformers
</span><span id="__span-27-2"><a id="__codelineno-27-2" name="__codelineno-27-2" href="#__codelineno-27-2"></a>
</span><span id="__span-27-3"><a id="__codelineno-27-3" name="__codelineno-27-3" href="#__codelineno-27-3"></a>accelerate<span class="w"> </span>launch<span class="w"> </span><span class="se">\</span>
</span><span id="__span-27-4"><a id="__codelineno-27-4" name="__codelineno-27-4" href="#__codelineno-27-4"></a>./examples/pytorch/text-classification/run_glue.py<span class="w"> </span><span class="se">\</span>
</span><span id="__span-27-5"><a id="__codelineno-27-5" name="__codelineno-27-5" href="#__codelineno-27-5"></a>--model_name_or_path<span class="w"> </span>google-bert/bert-base-cased<span class="w"> </span><span class="se">\</span>
</span><span id="__span-27-6"><a id="__codelineno-27-6" name="__codelineno-27-6" href="#__codelineno-27-6"></a>--task_name<span class="w"> </span><span class="nv">$TASK_NAME</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-27-7"><a id="__codelineno-27-7" name="__codelineno-27-7" href="#__codelineno-27-7"></a>--do_train<span class="w"> </span><span class="se">\</span>
</span><span id="__span-27-8"><a id="__codelineno-27-8" name="__codelineno-27-8" href="#__codelineno-27-8"></a>--do_eval<span class="w"> </span><span class="se">\</span>
</span><span id="__span-27-9"><a id="__codelineno-27-9" name="__codelineno-27-9" href="#__codelineno-27-9"></a>--max_seq_length<span class="w"> </span><span class="m">128</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-27-10"><a id="__codelineno-27-10" name="__codelineno-27-10" href="#__codelineno-27-10"></a>--per_device_train_batch_size<span class="w"> </span><span class="m">16</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-27-11"><a id="__codelineno-27-11" name="__codelineno-27-11" href="#__codelineno-27-11"></a>--learning_rate<span class="w"> </span>5e-5<span class="w"> </span><span class="se">\</span>
</span><span id="__span-27-12"><a id="__codelineno-27-12" name="__codelineno-27-12" href="#__codelineno-27-12"></a>--num_train_epochs<span class="w"> </span><span class="m">3</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-27-13"><a id="__codelineno-27-13" name="__codelineno-27-13" href="#__codelineno-27-13"></a>--output_dir<span class="w"> </span>/tmp/<span class="nv">$TASK_NAME</span>/<span class="w"> </span><span class="se">\</span>
</span></code></pre></div>
<ol>
<li><code>accelerate launch</code>するための cmd 引数を直接使用することもできます。上の例は次のようにマッピングされます。</li>
</ol>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-28-1"><a id="__codelineno-28-1" name="__codelineno-28-1" href="#__codelineno-28-1"></a><span class="nb">cd</span><span class="w"> </span>transformers
</span><span id="__span-28-2"><a id="__codelineno-28-2" name="__codelineno-28-2" href="#__codelineno-28-2"></a>
</span><span id="__span-28-3"><a id="__codelineno-28-3" name="__codelineno-28-3" href="#__codelineno-28-3"></a>accelerate<span class="w"> </span>launch<span class="w"> </span>--num_processes<span class="o">=</span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-28-4"><a id="__codelineno-28-4" name="__codelineno-28-4" href="#__codelineno-28-4"></a>--use_fsdp<span class="w"> </span><span class="se">\</span>
</span><span id="__span-28-5"><a id="__codelineno-28-5" name="__codelineno-28-5" href="#__codelineno-28-5"></a>--mixed_precision<span class="o">=</span>bf16<span class="w"> </span><span class="se">\</span>
</span><span id="__span-28-6"><a id="__codelineno-28-6" name="__codelineno-28-6" href="#__codelineno-28-6"></a>--fsdp_auto_wrap_policy<span class="o">=</span>TRANSFORMER_BASED_WRAP<span class="w">  </span><span class="se">\</span>
</span><span id="__span-28-7"><a id="__codelineno-28-7" name="__codelineno-28-7" href="#__codelineno-28-7"></a>--fsdp_transformer_layer_cls_to_wrap<span class="o">=</span><span class="s2">&quot;BertLayer&quot;</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-28-8"><a id="__codelineno-28-8" name="__codelineno-28-8" href="#__codelineno-28-8"></a>--fsdp_sharding_strategy<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-28-9"><a id="__codelineno-28-9" name="__codelineno-28-9" href="#__codelineno-28-9"></a>--fsdp_state_dict_type<span class="o">=</span>FULL_STATE_DICT<span class="w"> </span><span class="se">\</span>
</span><span id="__span-28-10"><a id="__codelineno-28-10" name="__codelineno-28-10" href="#__codelineno-28-10"></a>./examples/pytorch/text-classification/run_glue.py
</span><span id="__span-28-11"><a id="__codelineno-28-11" name="__codelineno-28-11" href="#__codelineno-28-11"></a>--model_name_or_path<span class="w"> </span>google-bert/bert-base-cased<span class="w"> </span><span class="se">\</span>
</span><span id="__span-28-12"><a id="__codelineno-28-12" name="__codelineno-28-12" href="#__codelineno-28-12"></a>--task_name<span class="w"> </span><span class="nv">$TASK_NAME</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-28-13"><a id="__codelineno-28-13" name="__codelineno-28-13" href="#__codelineno-28-13"></a>--do_train<span class="w"> </span><span class="se">\</span>
</span><span id="__span-28-14"><a id="__codelineno-28-14" name="__codelineno-28-14" href="#__codelineno-28-14"></a>--do_eval<span class="w"> </span><span class="se">\</span>
</span><span id="__span-28-15"><a id="__codelineno-28-15" name="__codelineno-28-15" href="#__codelineno-28-15"></a>--max_seq_length<span class="w"> </span><span class="m">128</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-28-16"><a id="__codelineno-28-16" name="__codelineno-28-16" href="#__codelineno-28-16"></a>--per_device_train_batch_size<span class="w"> </span><span class="m">16</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-28-17"><a id="__codelineno-28-17" name="__codelineno-28-17" href="#__codelineno-28-17"></a>--learning_rate<span class="w"> </span>5e-5<span class="w"> </span><span class="se">\</span>
</span><span id="__span-28-18"><a id="__codelineno-28-18" name="__codelineno-28-18" href="#__codelineno-28-18"></a>--num_train_epochs<span class="w"> </span><span class="m">3</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-28-19"><a id="__codelineno-28-19" name="__codelineno-28-19" href="#__codelineno-28-19"></a>--output_dir<span class="w"> </span>/tmp/<span class="nv">$TASK_NAME</span>/<span class="w"> </span><span class="se">\</span>
</span></code></pre></div>
<p>詳細については、🤗 Accelerate CLI ガイドを参照してください: <a href="https://huggingface.co/docs/accelerate/basic_tutorials/launch">🤗 Accelerate スクリプトの起動</a>。</p>
<p>移動されたセクション:</p>
<p>[ <a href="./deepspeed#deepspeed-trainer-integration">DeepSpeed</a><a id="deepspeed"></a>
| <a href="./deepspeed#deepspeed-installation">Installation</a><a id="installation"></a>
| <a href="./deepspeed#deepspeed-multi-gpu">Deployment with multiple GPUs</a><a id="deployment-with-multiple-gpus"></a>
| <a href="./deepspeed#deepspeed-one-gpu">Deployment with one GPU</a><a id="deployment-with-one-gpu"></a>
| <a href="./deepspeed#deepspeed-notebook">Deployment in Notebooks</a><a id="deployment-in-notebooks"></a>
| <a href="./deepspeed#deepspeed-config">Configuration</a><a id="configuration"></a>
| <a href="./deepspeed#deepspeed-config-passing">Passing Configuration</a><a id="passing-configuration"></a>
| <a href="./deepspeed#deepspeed-config-shared">Shared Configuration</a><a id="shared-configuration"></a>
| <a href="./deepspeed#deepspeed-zero">ZeRO</a><a id="zero"></a>
| <a href="./deepspeed#deepspeed-zero2-config">ZeRO-2 Config</a><a id="zero-2-config"></a>
| <a href="./deepspeed#deepspeed-zero3-config">ZeRO-3 Config</a><a id="zero-3-config"></a>
| <a href="./deepspeed#deepspeed-nvme">NVMe Support</a><a id="nvme-support"></a>
| <a href="./deepspeed#deepspeed-zero2-zero3-performance">ZeRO-2 vs ZeRO-3 Performance</a><a id="zero-2-vs-zero-3-performance"></a>
| <a href="./deepspeed#deepspeed-zero2-example">ZeRO-2 Example</a><a id="zero-2-example"></a>
| <a href="./deepspeed#deepspeed-zero3-example">ZeRO-3 Example</a><a id="zero-3-example"></a>
| <a href="./deepspeed#deepspeed-optimizer">Optimizer</a><a id="optimizer"></a>
| <a href="./deepspeed#deepspeed-scheduler">Scheduler</a><a id="scheduler"></a>
| <a href="./deepspeed#deepspeed-fp32">fp32 Precision</a><a id="fp32-precision"></a>
| <a href="./deepspeed#deepspeed-amp">Automatic Mixed Precision</a><a id="automatic-mixed-precision"></a>
| <a href="./deepspeed#deepspeed-bs">Batch Size</a><a id="batch-size"></a>
| <a href="./deepspeed#deepspeed-grad-acc">Gradient Accumulation</a><a id="gradient-accumulation"></a>
| <a href="./deepspeed#deepspeed-grad-clip">Gradient Clipping</a><a id="gradient-clipping"></a>
| <a href="./deepspeed#deepspeed-weight-extraction">Getting The Model Weights Out</a><a id="getting-the-model-weights-out"></a>
]</p>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../../../../../../..", "features": ["navigation.tabs", "navigation.indexes", "navigation.instant", "navigation.sections", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow", "content.tabs.link", "content.code.copy"], "search": "../../../../../../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../../../../../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
    
  </body>
</html>