
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../../../../../../../assets/favicon.ico">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.22">
    
    
      
        <title>Quantization - Ohayou</title>
      
    
    
      <link rel="stylesheet" href="../../../../../../../assets/stylesheets/main.84d31ad4.min.css">
      
        
        <link rel="stylesheet" href="../../../../../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../../../../../assets/extra.css">
    
    <script>__md_scope=new URL("../../../../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#quantize-transformers-models" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../../../../.." title="Ohayou" class="md-header__button md-logo" aria-label="Ohayou" data-md-component="logo">
      
  <img src="../../../../../../../assets/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Ohayou
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Quantization
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../../../ohayou/" class="md-tabs__link">
        
  
  
    
  
  Ohayou

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../../../../vllm/open_ai_vllm_example_a_v_t/" class="md-tabs__link">
          
  
  
    
  
  vLLM

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../../../../llm/speculative_decoding/" class="md-tabs__link">
          
  
  
    
  
  LLM

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../../../../vlm/qwen3_vl_4B_object_detection/" class="md-tabs__link">
          
  
  
    
  
  VLM

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../../../md_format_helpers/" class="md-tabs__link">
        
  
  
    
  
  MD format helpers

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../../../docker/" class="md-tabs__link">
        
  
  
    
  
  Docker

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../../../linux/" class="md-tabs__link">
        
  
  
    
  
  Linux

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../../../moe/" class="md-tabs__link">
        
  
  
    
  
  Mixture of Experts

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../../../slurm/" class="md-tabs__link">
        
  
  
    
  
  Slurm

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../../../../japanese-phrases/" class="md-tabs__link">
          
  
  
    
  
  Japanese Phrases

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../../../hackathon/index.md" class="md-tabs__link">
        
  
  
    
  
  Hack

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../../../../.." title="Ohayou" class="md-nav__button md-logo" aria-label="Ohayou" data-md-component="logo">
      
  <img src="../../../../../../../assets/logo.png" alt="logo">

    </a>
    Ohayou
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../../ohayou/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Ohayou
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    vLLM
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            vLLM
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../../vllm/open_ai_vllm_example_a_v_t/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Single Request
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../../vllm/bash_vllm_serve/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Bash online serve
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../../vllm/benchmarks/performance_eval/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Benchmarks
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    LLM
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            LLM
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../../llm/speculative_decoding/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Speculative Decoding
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    VLM
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            VLM
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../../vlm/qwen3_vl_4B_object_detection/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Qwen3VL_adema_grounding
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../../vlm/qwen3_vla_4B_audio_training_aspandiyar/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Qwen3VLA_aspandiyar_thinking
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../../md_format_helpers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    MD format helpers
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../../docker/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Docker
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../../linux/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Linux
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../../moe/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Mixture of Experts
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../../slurm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Slurm
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_11" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../../../../../japanese-phrases/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Japanese Phrases
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_11" id="__nav_11_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_11">
            <span class="md-nav__icon md-icon"></span>
            Japanese Phrases
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_11_2" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../../../../../japanese-phrases/daily-life/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Daily Life
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_11_2" id="__nav_11_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_11_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_11_2">
            <span class="md-nav__icon md-icon"></span>
            Daily Life
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../../japanese-phrases/daily-life/shopping/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Shopping
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_11_3" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../../../../../japanese-phrases/greetings/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Greetings
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_11_3" id="__nav_11_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_11_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_11_3">
            <span class="md-nav__icon md-icon"></span>
            Greetings
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../../japanese-phrases/greetings/casual/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Casual
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../../japanese-phrases/emotions/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Emotions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../../japanese-phrases/anime-manga/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Anime/Manga
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../../../hackathon/index.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Hack
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#autogptq-integration" class="md-nav__link">
    <span class="md-ellipsis">
      AutoGPTQ Integration
    </span>
  </a>
  
    <nav class="md-nav" aria-label="AutoGPTQ Integration">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#requirements" class="md-nav__link">
    <span class="md-ellipsis">
      Requirements
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#load-and-quantize-a-model" class="md-nav__link">
    <span class="md-ellipsis">
      Load and quantize a model
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Load and quantize a model">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#gptq-configuration" class="md-nav__link">
    <span class="md-ellipsis">
      GPTQ Configuration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#quantization" class="md-nav__link">
    <span class="md-ellipsis">
      Quantization
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#push-quantized-model-to-hub" class="md-nav__link">
    <span class="md-ellipsis">
      Push quantized model to ğŸ¤— Hub
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#load-a-quantized-model-from-the-hub" class="md-nav__link">
    <span class="md-ellipsis">
      Load a quantized model from the ğŸ¤— Hub
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#exllama-kernels-for-faster-inference" class="md-nav__link">
    <span class="md-ellipsis">
      Exllama kernels for faster inference
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Exllama kernels for faster inference">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#fine-tune-a-quantized-model" class="md-nav__link">
    <span class="md-ellipsis">
      Fine-tune a quantized model
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-demo" class="md-nav__link">
    <span class="md-ellipsis">
      Example demo
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gptqconfig" class="md-nav__link">
    <span class="md-ellipsis">
      GPTQConfig
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bitsandbytes-integration" class="md-nav__link">
    <span class="md-ellipsis">
      bitsandbytes Integration
    </span>
  </a>
  
    <nav class="md-nav" aria-label="bitsandbytes Integration">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#general-usage" class="md-nav__link">
    <span class="md-ellipsis">
      General usage
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fp4-quantization" class="md-nav__link">
    <span class="md-ellipsis">
      FP4 quantization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="FP4 quantization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#requirements_1" class="md-nav__link">
    <span class="md-ellipsis">
      Requirements
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tips-and-best-practices" class="md-nav__link">
    <span class="md-ellipsis">
      Tips and best practices
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#load-a-large-model-in-4bit" class="md-nav__link">
    <span class="md-ellipsis">
      Load a large model in 4bit
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#load-a-large-model-in-8bit" class="md-nav__link">
    <span class="md-ellipsis">
      Load a large model in 8bit
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Load a large model in 8bit">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#advanced-use-cases" class="md-nav__link">
    <span class="md-ellipsis">
      Advanced use cases
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Advanced use cases">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#change-the-compute-dtype" class="md-nav__link">
    <span class="md-ellipsis">
      Change the compute dtype
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#using-nf4-normal-float-4-data-type" class="md-nav__link">
    <span class="md-ellipsis">
      Using NF4 (Normal Float 4) data type
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#use-nested-quantization-for-more-memory-efficient-inference" class="md-nav__link">
    <span class="md-ellipsis">
      Use nested quantization for more memory efficient inference
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#push-quantized-models-on-the-hub" class="md-nav__link">
    <span class="md-ellipsis">
      Push quantized models on the ğŸ¤— Hub
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#load-a-quantized-model-from-the-hub_1" class="md-nav__link">
    <span class="md-ellipsis">
      Load a quantized model from the ğŸ¤— Hub
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#advanced-use-cases_1" class="md-nav__link">
    <span class="md-ellipsis">
      Advanced use cases
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Advanced use cases">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#offload-between-cpu-and-gpu" class="md-nav__link">
    <span class="md-ellipsis">
      Offload between cpu and gpu
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#play-with-llm_int8_threshold" class="md-nav__link">
    <span class="md-ellipsis">
      Play with llm_int8_threshold
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#skip-the-conversion-of-some-modules" class="md-nav__link">
    <span class="md-ellipsis">
      Skip the conversion of some modules
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fine-tune-a-model-that-has-been-loaded-in-8-bit" class="md-nav__link">
    <span class="md-ellipsis">
      Fine-tune a model that has been loaded in 8-bit
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bitsandbytesconfig" class="md-nav__link">
    <span class="md-ellipsis">
      BitsAndBytesConfig
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#quantization-with-optimum" class="md-nav__link">
    <span class="md-ellipsis">
      Quantization with ğŸ¤— optimum
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<!--Copyright 2023 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.

âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->

<h1 id="quantize-transformers-models">Quantize ğŸ¤— Transformers models</h1>
<h2 id="autogptq-integration"><code>AutoGPTQ</code> Integration</h2>
<p>ğŸ¤— Transformers ã«ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã§ GPTQ é‡å­åŒ–ã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã® <code>optimum</code> API ãŒçµ±åˆã•ã‚Œã¦ã„ã¾ã™ã€‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å¤§å¹…ã«ä½ä¸‹ã•ã›ã‚‹ã“ã¨ãªãã€æ¨è«–é€Ÿåº¦ã‚’é«˜é€ŸåŒ–ã™ã‚‹ã“ã¨ãªãã€ãƒ¢ãƒ‡ãƒ«ã‚’ 8ã€4ã€3ã€ã•ã‚‰ã«ã¯ 2 ãƒ“ãƒƒãƒˆã§ãƒ­ãƒ¼ãƒ‰ãŠã‚ˆã³é‡å­åŒ–ã§ãã¾ã™ã€‚ã“ã‚Œã¯ã€ã»ã¨ã‚“ã©ã® GPU ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã§ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã™ã€‚</p>
<p>é‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã®è©³ç´°ã«ã¤ã„ã¦ã¯ã€ä»¥ä¸‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚
- <a href="https://huggingface.co/papers/2210.17323">GPTQ</a> è«–æ–‡
- GPTQ é‡å­åŒ–ã«é–¢ã™ã‚‹ <code>optimum</code> <a href="https://huggingface.co/docs/optimum/llm_quantization/usage_guides/quantization">ã‚¬ã‚¤ãƒ‰</a>
- ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã¨ã—ã¦ä½¿ç”¨ã•ã‚Œã‚‹ <a href="https://github.com/PanQiWei/AutoGPTQ"><code>AutoGPTQ</code></a> ãƒ©ã‚¤ãƒ–ãƒ©ãƒª</p>
<h3 id="requirements">Requirements</h3>
<p>ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹ã«ã¯ã€ä»¥ä¸‹ã®è¦ä»¶ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼š </p>
<ul>
<li>
<p>æœ€æ–°ã® <code>AutoGPTQ</code> ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã€‚
<code>pip install auto-gptq</code> ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã€‚</p>
</li>
<li>
<p>æœ€æ–°ã® <code>optimum</code> ã‚’ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã€‚
<code>git+https://github.com/huggingface/optimum.git</code> ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã€‚</p>
</li>
<li>
<p>æœ€æ–°ã® <code>transformers</code> ã‚’ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã€‚
æœ€æ–°ã® <code>transformers</code> ã‚’ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ <code>pip install git+https://github.com/huggingface/transformers.git</code></p>
</li>
<li>
<p>æœ€æ–°ã® <code>accelerate</code> ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã€‚
<code>pip install --upgrade accelerate</code> ã‚’å®Ÿè¡Œã™ã‚‹ã€‚</p>
</li>
</ul>
<p>GPTQçµ±åˆã¯ä»Šã®ã¨ã“ã‚ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã®ã¿ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ã®ã§ã€è¦–è¦šã€éŸ³å£°ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã§ã¯äºˆæœŸã›ã¬æŒ™å‹•ã«é­é‡ã™ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚</p>
<h3 id="load-and-quantize-a-model">Load and quantize a model</h3>
<p>GPTQ ã¯ã€é‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹å‰ã«é‡ã¿ã®ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å¿…è¦ã¨ã™ã‚‹é‡å­åŒ–æ–¹æ³•ã§ã™ã€‚ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ ãƒ¢ãƒ‡ãƒ«ã‚’æœ€åˆã‹ã‚‰é‡å­åŒ–ã™ã‚‹å ´åˆã¯ã€é‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã™ã‚‹ã¾ã§ã«æ™‚é–“ãŒã‹ã‹ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ (<code>facebook/opt-350m</code>ãƒ¢ãƒ‡ãƒ«ã® Google colab ã§ã¯ç´„ 5 åˆ†)ã€‚</p>
<p>ã—ãŸãŒã£ã¦ã€GPTQ é‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã‚·ãƒŠãƒªã‚ªã¯ 2 ã¤ã‚ã‚Šã¾ã™ã€‚æœ€åˆã®ä½¿ç”¨ä¾‹ã¯ã€ãƒãƒ–ã§åˆ©ç”¨å¯èƒ½ãªä»–ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ã™ã§ã«é‡å­åŒ–ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã“ã¨ã§ã™ã€‚2 ç•ªç›®ã®ä½¿ç”¨ä¾‹ã¯ã€ãƒ¢ãƒ‡ãƒ«ã‚’æœ€åˆã‹ã‚‰é‡å­åŒ–ã—ã€ä¿å­˜ã™ã‚‹ã‹ãƒãƒ–ã«ãƒ—ãƒƒã‚·ãƒ¥ã—ã¦ã€ä»–ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒä½¿ç”¨ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã“ã¨ã§ã™ã€‚ãã‚Œã‚‚ä½¿ã£ã¦ãã ã•ã„ã€‚</p>
<h4 id="gptq-configuration">GPTQ Configuration</h4>
<p>ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦é‡å­åŒ–ã™ã‚‹ã«ã¯ã€[<code>GPTQConfig</code>] ã‚’ä½œæˆã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æº–å‚™ã™ã‚‹ã«ã¯ã€<code>bits</code>ã®æ•°ã€é‡å­åŒ–ã‚’èª¿æ•´ã™ã‚‹ãŸã‚ã®<code>dataset</code>ã€ãŠã‚ˆã³ãƒ¢ãƒ‡ãƒ«ã®<code>Tokenizer</code>ã‚’æ¸¡ã™å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">model_id</span> <span class="o">=</span> <span class="s2">&quot;facebook/opt-125m&quot;</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_id</span><span class="p">)</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="n">gptq_config</span> <span class="o">=</span> <span class="n">GPTQConfig</span><span class="p">(</span><span class="n">bits</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">dataset</span> <span class="o">=</span> <span class="s2">&quot;c4&quot;</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">)</span>
</span></code></pre></div>
<p>ç‹¬è‡ªã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ–‡å­—åˆ—ã®ãƒªã‚¹ãƒˆã¨ã—ã¦æ¸¡ã™ã“ã¨ãŒã§ãã‚‹ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚ãŸã ã—ã€GPTQ è«–æ–‡ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’å¼·ããŠå‹§ã‚ã—ã¾ã™ã€‚</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="n">dataset</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;auto-gptq is an easy-to-use model quantization library with user-friendly apis, based on GPTQ algorithm.&quot;</span><span class="p">]</span>
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a><span class="n">quantization</span> <span class="o">=</span> <span class="n">GPTQConfig</span><span class="p">(</span><span class="n">bits</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">)</span>
</span></code></pre></div>
<h4 id="quantization">Quantization</h4>
<p><code>from_pretrained</code> ã‚’ä½¿ç”¨ã—ã€<code>quantization_config</code> ã‚’è¨­å®šã™ã‚‹ã“ã¨ã§ãƒ¢ãƒ‡ãƒ«ã‚’é‡å­åŒ–ã§ãã¾ã™ã€‚</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span>
</span><span id="__span-2-2"><a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_id</span><span class="p">,</span> <span class="n">quantization_config</span><span class="o">=</span><span class="n">gptq_config</span><span class="p">)</span>
</span></code></pre></div>
<p>ãƒ¢ãƒ‡ãƒ«ã‚’é‡å­åŒ–ã™ã‚‹ã«ã¯ GPU ãŒå¿…è¦ã§ã‚ã‚‹ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚ãƒ¢ãƒ‡ãƒ«ã‚’ CPU ã«é…ç½®ã—ã€é‡å­åŒ–ã™ã‚‹ãŸã‚ã«ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ GPU ã«å‰å¾Œã«ç§»å‹•ã•ã›ã¾ã™ã€‚</p>
<p>CPU ã‚ªãƒ•ãƒ­ãƒ¼ãƒ‰ã®ä½¿ç”¨ä¸­ã« GPU ã®ä½¿ç”¨é‡ã‚’æœ€å¤§åŒ–ã—ãŸã„å ´åˆã¯ã€<code>device_map = "auto"</code> ã‚’è¨­å®šã§ãã¾ã™ã€‚</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span>
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_id</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="n">quantization_config</span><span class="o">=</span><span class="n">gptq_config</span><span class="p">)</span>
</span></code></pre></div>
<p>ãƒ‡ã‚£ã‚¹ã‚¯ ã‚ªãƒ•ãƒ­ãƒ¼ãƒ‰ã¯ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚ã•ã‚‰ã«ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒåŸå› ã§ãƒ¡ãƒ¢ãƒªãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆã¯ã€<code>from_pretained</code> ã§ <code>max_memory</code> ã‚’æ¸¡ã™å¿…è¦ãŒã‚ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚ <code>device_map</code>ã¨<code>max_memory</code>ã®è©³ç´°ã«ã¤ã„ã¦ã¯ã€ã“ã® <a href="https://huggingface.co/docs/accelerate/usage_guides/big_modeling#designing-a-device-map">ã‚¬ã‚¤ãƒ‰</a> ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚</p>
<p><Tip warning={true}>
GPTQ é‡å­åŒ–ã¯ã€ç¾æ™‚ç‚¹ã§ã¯ãƒ†ã‚­ã‚¹ãƒˆ ãƒ¢ãƒ‡ãƒ«ã§ã®ã¿æ©Ÿèƒ½ã—ã¾ã™ã€‚ã•ã‚‰ã«ã€é‡å­åŒ–ãƒ—ãƒ­ã‚»ã‚¹ã¯ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã«ã‚ˆã£ã¦ã¯é•·æ™‚é–“ã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ (NVIDIA A100 ã‚’ä½¿ç”¨ã—ãŸå ´åˆã€175B ãƒ¢ãƒ‡ãƒ« = 4 gpu æ™‚é–“)ã€‚ãƒ¢ãƒ‡ãƒ«ã® GPTQ é‡å­åŒ–ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã€ãƒãƒ–ã§ç¢ºèªã—ã¦ãã ã•ã„ã€‚ãã†ã§ãªã„å ´åˆã¯ã€github ã§è¦æ±‚ã‚’é€ä¿¡ã§ãã¾ã™ã€‚
</Tip></p>
<h3 id="push-quantized-model-to-hub">Push quantized model to ğŸ¤— Hub</h3>
<p>ä»–ã® ğŸ¤— ãƒ¢ãƒ‡ãƒ«ã¨åŒæ§˜ã«ã€<code>push_to_hub</code> ã‚’ä½¿ç”¨ã—ã¦é‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã‚’ãƒãƒ–ã«ãƒ—ãƒƒã‚·ãƒ¥ã§ãã¾ã™ã€‚é‡å­åŒ–æ§‹æˆã¯ä¿å­˜ã•ã‚Œã€ãƒ¢ãƒ‡ãƒ«ã«æ²¿ã£ã¦ãƒ—ãƒƒã‚·ãƒ¥ã•ã‚Œã¾ã™ã€‚</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a><span class="n">quantized_model</span><span class="o">.</span><span class="n">push_to_hub</span><span class="p">(</span><span class="s2">&quot;opt-125m-gptq&quot;</span><span class="p">)</span>
</span><span id="__span-4-2"><a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a><span class="n">tokenizer</span><span class="o">.</span><span class="n">push_to_hub</span><span class="p">(</span><span class="s2">&quot;opt-125m-gptq&quot;</span><span class="p">)</span>
</span></code></pre></div>
<p>é‡å­åŒ–ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ã‚«ãƒ« ãƒã‚·ãƒ³ã«ä¿å­˜ã—ãŸã„å ´åˆã¯ã€<code>save_pretrained</code> ã‚’ä½¿ç”¨ã—ã¦è¡Œã†ã“ã¨ã‚‚ã§ãã¾ã™ã€‚</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a><span class="n">quantized_model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="s2">&quot;opt-125m-gptq&quot;</span><span class="p">)</span>
</span><span id="__span-5-2"><a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a><span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="s2">&quot;opt-125m-gptq&quot;</span><span class="p">)</span>
</span></code></pre></div>
<p><code>device_map</code> ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’é‡å­åŒ–ã—ãŸå ´åˆã¯ã€ä¿å­˜ã™ã‚‹å‰ã«ãƒ¢ãƒ‡ãƒ«å…¨ä½“ã‚’ GPU ã¾ãŸã¯ <code>cpu</code> ã®ã„ãšã‚Œã‹ã«ç§»å‹•ã—ã¦ãã ã•ã„ã€‚</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a><span class="n">quantized_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
</span><span id="__span-6-2"><a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a><span class="n">quantized_model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="s2">&quot;opt-125m-gptq&quot;</span><span class="p">)</span>
</span></code></pre></div>
<h3 id="load-a-quantized-model-from-the-hub">Load a quantized model from the ğŸ¤— Hub</h3>
<p><code>from_pretrained</code>ã‚’ä½¿ç”¨ã—ã¦ã€é‡å­åŒ–ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ãƒãƒ–ã‹ã‚‰ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚
å±æ€§ <code>quantization_config</code> ãŒãƒ¢ãƒ‡ãƒ«è¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ã€ãƒ—ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸé‡ã¿ãŒé‡å­åŒ–ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¾ã™ã€‚</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-7-1"><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span>
</span><span id="__span-7-2"><a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{your_username}</span><span class="s2">/opt-125m-gptq&quot;</span><span class="p">)</span>
</span></code></pre></div>
<p>å¿…è¦ä»¥ä¸Šã®ãƒ¡ãƒ¢ãƒªã‚’å‰²ã‚Šå½“ã¦ãšã«ãƒ¢ãƒ‡ãƒ«ã‚’ã‚ˆã‚Šé€Ÿããƒ­ãƒ¼ãƒ‰ã—ãŸã„å ´åˆã¯ã€<code>device_map</code> å¼•æ•°ã¯é‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã§ã‚‚æ©Ÿèƒ½ã—ã¾ã™ã€‚ <code>accelerate</code>ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-8-1"><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span>
</span><span id="__span-8-2"><a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{your_username}</span><span class="s2">/opt-125m-gptq&quot;</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>
</span></code></pre></div>
<h3 id="exllama-kernels-for-faster-inference">Exllama kernels for faster inference</h3>
<p>4 ãƒ“ãƒƒãƒˆ ãƒ¢ãƒ‡ãƒ«ã®å ´åˆã€æ¨è«–é€Ÿåº¦ã‚’é«˜ã‚ã‚‹ãŸã‚ã« exllama ã‚«ãƒ¼ãƒãƒ«ã‚’ä½¿ç”¨ã§ãã¾ã™ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§æœ‰åŠ¹ã«ãªã£ã¦ã„ã¾ã™ã€‚ [<code>GPTQConfig</code>] ã§ <code>disable_exllama</code> ã‚’æ¸¡ã™ã“ã¨ã§ã€ãã®å‹•ä½œã‚’å¤‰æ›´ã§ãã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è¨­å®šã«ä¿å­˜ã•ã‚Œã¦ã„ã‚‹é‡å­åŒ–è¨­å®šãŒä¸Šæ›¸ãã•ã‚Œã¾ã™ã€‚ã‚«ãƒ¼ãƒãƒ«ã«é–¢é€£ã™ã‚‹å±æ€§ã®ã¿ã‚’ä¸Šæ›¸ãã§ãã‚‹ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚ã•ã‚‰ã«ã€exllama ã‚«ãƒ¼ãƒãƒ«ã‚’ä½¿ç”¨ã—ãŸã„å ´åˆã¯ã€ãƒ¢ãƒ‡ãƒ«å…¨ä½“ã‚’ GPU ä¸Šã«ç½®ãå¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚</p>
<div class="language-py highlight"><pre><span></span><code><span id="__span-9-1"><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="__span-9-2"><a id="__codelineno-9-2" name="__codelineno-9-2" href="#__codelineno-9-2"></a><span class="n">gptq_config</span> <span class="o">=</span> <span class="n">GPTQConfig</span><span class="p">(</span><span class="n">bits</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">disable_exllama</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="__span-9-3"><a id="__codelineno-9-3" name="__codelineno-9-3" href="#__codelineno-9-3"></a><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{your_username}</span><span class="s2">/opt-125m-gptq&quot;</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="n">quantization_config</span> <span class="o">=</span> <span class="n">gptq_config</span><span class="p">)</span>
</span></code></pre></div>
<p>ç¾æ™‚ç‚¹ã§ã¯ 4 ãƒ“ãƒƒãƒˆ ãƒ¢ãƒ‡ãƒ«ã®ã¿ãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚ã•ã‚‰ã«ã€peft ã‚’ä½¿ç”¨ã—ã¦é‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã—ã¦ã„ã‚‹å ´åˆã¯ã€exllama ã‚«ãƒ¼ãƒãƒ«ã‚’éã‚¢ã‚¯ãƒ†ã‚£ãƒ–åŒ–ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚</p>
<h4 id="fine-tune-a-quantized-model">Fine-tune a quantized model</h4>
<p>Hugging Face ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã®å…¬å¼ã‚µãƒãƒ¼ãƒˆã«ã‚ˆã‚Šã€GPTQ ã§é‡å­åŒ–ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã§ãã¾ã™ã€‚
è©³ç´°ã«ã¤ã„ã¦ã¯ã€<a href="https://github.com/huggingface/peft"><code>peft</code></a> ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã”è¦§ãã ã•ã„ã€‚</p>
<h3 id="example-demo">Example demo</h3>
<p>GPTQ ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’é‡å­åŒ–ã™ã‚‹æ–¹æ³•ã¨ã€peft ã‚’ä½¿ç”¨ã—ã¦é‡å­åŒ–ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã™ã‚‹æ–¹æ³•ã«ã¤ã„ã¦ã¯ã€Google Colab <a href="https://colab.research.google.com/drive/1_TIrmuKOFhuRRiTWN94iLKUFu6ZX4ceb?usp=sharing">ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯</a> ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚</p>
<h3 id="gptqconfig">GPTQConfig</h3>
<p>[[autodoc]] GPTQConfig</p>
<h2 id="bitsandbytes-integration"><code>bitsandbytes</code> Integration</h2>
<p>ğŸ¤— Transformers ã¯ã€<code>bitsandbytes</code> ã§æœ€ã‚‚ã‚ˆãä½¿ç”¨ã•ã‚Œã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¨ç·Šå¯†ã«çµ±åˆã•ã‚Œã¦ã„ã¾ã™ã€‚æ•°è¡Œã®ã‚³ãƒ¼ãƒ‰ã§ãƒ¢ãƒ‡ãƒ«ã‚’ 8 ãƒ“ãƒƒãƒˆç²¾åº¦ã§ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚
ã“ã‚Œã¯ã€<code>bitsandbytes</code>ã® <code>0.37.0</code>ãƒªãƒªãƒ¼ã‚¹ä»¥é™ã€ã»ã¨ã‚“ã©ã® GPU ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã§ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã™ã€‚</p>
<p>é‡å­åŒ–æ–¹æ³•ã®è©³ç´°ã«ã¤ã„ã¦ã¯ã€<a href="https://huggingface.co/papers/2208.07339">LLM.int8()</a> è«–æ–‡ã€ã¾ãŸã¯ <a href="https://huggingface.co/blog/hf-bitsandbytes-">ãƒ–ãƒ­ã‚°æŠ•ç¨¿</a> ã‚’ã”è¦§ãã ã•ã„ã€‚çµ±åˆï¼‰ã‚³ãƒ©ãƒœãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«ã¤ã„ã¦ã€‚</p>
<p><code>0.39.0</code>ãƒªãƒªãƒ¼ã‚¹ä»¥é™ã€FP4 ãƒ‡ãƒ¼ã‚¿å‹ã‚’æ´»ç”¨ã—ã€4 ãƒ“ãƒƒãƒˆé‡å­åŒ–ã‚’ä½¿ç”¨ã—ã¦<code>device_map</code>ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ä»»æ„ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚</p>
<p>ç‹¬è‡ªã® pytorch ãƒ¢ãƒ‡ãƒ«ã‚’é‡å­åŒ–ã—ãŸã„å ´åˆã¯ã€ğŸ¤— Accelerate ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã® <a href="https://huggingface.co/docs/accelerate/main/en/usage_guides/quantization">ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ</a> ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚</p>
<p><code>bitsandbytes</code>çµ±åˆã‚’ä½¿ç”¨ã—ã¦ã§ãã‚‹ã“ã¨ã¯æ¬¡ã®ã¨ãŠã‚Šã§ã™</p>
<h3 id="general-usage">General usage</h3>
<p>ãƒ¢ãƒ‡ãƒ«ãŒ ğŸ¤— Accelerate ã«ã‚ˆã‚‹èª­ã¿è¾¼ã¿ã‚’ã‚µãƒãƒ¼ãƒˆã—ã€<code>torch.nn.Linear</code> ãƒ¬ã‚¤ãƒ¤ãƒ¼ãŒå«ã¾ã‚Œã¦ã„ã‚‹é™ã‚Šã€ [<code>~PreTrainedModel.from_pretrained</code>] ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å‘¼ã³å‡ºã™ã¨ãã« <code>load_in_8bit</code> ã¾ãŸã¯ <code>load_in_4bit</code> å¼•æ•°ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’é‡å­åŒ–ã§ãã¾ã™ã€‚ã“ã‚Œã¯ã©ã®ã‚ˆã†ãªãƒ¢ãƒ€ãƒªãƒ†ã‚£ã§ã‚‚åŒæ§˜ã«æ©Ÿèƒ½ã™ã‚‹ã¯ãšã§ã™ã€‚</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-10-1"><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">BitsAndBytesConfig</span>
</span><span id="__span-10-2"><a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a>
</span><span id="__span-10-3"><a id="__codelineno-10-3" name="__codelineno-10-3" href="#__codelineno-10-3"></a><span class="n">model_8bit</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;facebook/opt-350m&quot;</span><span class="p">,</span> <span class="n">quantization_config</span><span class="o">=</span><span class="n">BitsAndBytesConfig</span><span class="p">(</span><span class="n">load_in_8bit</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</span><span id="__span-10-4"><a id="__codelineno-10-4" name="__codelineno-10-4" href="#__codelineno-10-4"></a><span class="n">model_4bit</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;facebook/opt-350m&quot;</span><span class="p">,</span> <span class="n">quantization_config</span><span class="o">=</span><span class="n">BitsAndBytesConfig</span><span class="p">(</span><span class="n">load_in_4bit</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</span></code></pre></div>
<p>ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯ã€ä»–ã®ã™ã¹ã¦ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« (ä¾‹: <code>torch.nn.LayerNorm</code>) ã¯ <code>torch.float16</code> ã«å¤‰æ›ã•ã‚Œã¾ã™ãŒã€ãã® <code>dtype</code> ã‚’å¤‰æ›´ã—ãŸã„å ´åˆã¯ã€<code>dtype</code> å¼•æ•°ã‚’ä¸Šæ›¸ãã§ãã¾ã™ã€‚</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-11-1"><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="__span-11-2"><a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span>
</span><span id="__span-11-3"><a id="__codelineno-11-3" name="__codelineno-11-3" href="#__codelineno-11-3"></a>
</span><span id="__span-11-4"><a id="__codelineno-11-4" name="__codelineno-11-4" href="#__codelineno-11-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">model_8bit</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;facebook/opt-350m&quot;</span><span class="p">,</span> <span class="n">quantization_config</span><span class="o">=</span><span class="n">BitsAndBytesConfig</span><span class="p">(</span><span class="n">load_in_8bit</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="__span-11-5"><a id="__codelineno-11-5" name="__codelineno-11-5" href="#__codelineno-11-5"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">model_8bit</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">final_layer_norm</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span>
</span><span id="__span-11-6"><a id="__codelineno-11-6" name="__codelineno-11-6" href="#__codelineno-11-6"></a><span class="n">torch</span><span class="o">.</span><span class="n">float32</span>
</span></code></pre></div>
<h3 id="fp4-quantization">FP4 quantization</h3>
<h4 id="requirements_1">Requirements</h4>
<p>ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ ã‚¹ãƒ‹ãƒšãƒƒãƒˆã‚’å®Ÿè¡Œã™ã‚‹å‰ã«ã€ä»¥ä¸‹ã®è¦ä»¶ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚</p>
<ul>
<li>
<p>æœ€æ–°ã®<code>bitsandbytes</code>ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
<code>pip install bitsandbytes&gt;=0.39.0</code></p>
</li>
<li>
<p>æœ€æ–°ã®<code>accelerate</code>ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹
<code>pip install --upgrade accelerate</code></p>
</li>
<li>
<p>æœ€æ–°ã® <code>transformers</code> ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹
<code>pip install --upgrade transformers</code></p>
</li>
</ul>
<h4 id="tips-and-best-practices">Tips and best practices</h4>
<ul>
<li>
<p><strong>é«˜åº¦ãªä½¿ç”¨æ³•:</strong> å¯èƒ½ãªã™ã¹ã¦ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ä½¿ç”¨ã—ãŸ 4 ãƒ“ãƒƒãƒˆé‡å­åŒ–ã®é«˜åº¦ãªä½¿ç”¨æ³•ã«ã¤ã„ã¦ã¯ã€<a href="https://colab.research.google.com/drive/1ge2F1QSK8Q7h0hn3YKuBCOAS0bK8E0wf">ã“ã® Google Colab ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯</a> ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚</p>
</li>
<li>
<p><strong><code>batch_size=1</code> ã«ã‚ˆã‚‹é«˜é€Ÿæ¨è«– :</strong> bitsandbytes ã® <code>0.40.0</code> ãƒªãƒªãƒ¼ã‚¹ä»¥é™ã€<code>batch_size=1</code> ã§ã¯é«˜é€Ÿæ¨è«–ã®æ©æµã‚’å—ã‘ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ <a href="https://github.com/TimDettmers/bitsandbytes/releases/tag/0.40.0">ã“ã‚Œã‚‰ã®ãƒªãƒªãƒ¼ã‚¹ ãƒãƒ¼ãƒˆ</a> ã‚’ç¢ºèªã—ã€ã“ã®æ©Ÿèƒ½ã‚’æ´»ç”¨ã™ã‚‹ã«ã¯<code>0.40.0</code>ä»¥é™ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚ç®±ã®ã€‚</p>
</li>
<li>
<p><strong>ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°:</strong> <a href="https://huggingface.co/papers/2305.14314">QLoRA è«–æ–‡</a> ã«ã‚ˆã‚‹ã¨ã€4 ãƒ“ãƒƒãƒˆåŸºæœ¬ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹å ´åˆ (ä¾‹: LoRA ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã‚’ä½¿ç”¨)ã€<code>bnb_4bit_quant_type='nf4'</code> ã‚’ä½¿ç”¨ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ ã€‚</p>
</li>
<li>
<p><strong>æ¨è«–:</strong> æ¨è«–ã®å ´åˆã€<code>bnb_4bit_quant_type</code> ã¯ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«å¤§ããªå½±éŸ¿ã‚’ä¸ãˆã¾ã›ã‚“ã€‚ãŸã ã—ã€ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã¨ã®ä¸€è²«æ€§ã‚’ä¿ã¤ãŸã‚ã«ã€å¿…ãšåŒã˜ <code>bnb_4bit_compute_dtype</code> ãŠã‚ˆã³ <code>dtype</code> å¼•æ•°ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚</p>
</li>
</ul>
<h4 id="load-a-large-model-in-4bit">Load a large model in 4bit</h4>
<p><code>.from_pretrained</code> ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å‘¼ã³å‡ºã™ã¨ãã« <code>load_in_4bit=True</code> ã‚’ä½¿ç”¨ã™ã‚‹ã¨ã€ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’ (ãŠãŠã‚ˆã) 4 ã§å‰²ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-12-1"><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a><span class="c1"># pip install transformers accelerate bitsandbytes</span>
</span><span id="__span-12-2"><a id="__codelineno-12-2" name="__codelineno-12-2" href="#__codelineno-12-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span>
</span><span id="__span-12-3"><a id="__codelineno-12-3" name="__codelineno-12-3" href="#__codelineno-12-3"></a>
</span><span id="__span-12-4"><a id="__codelineno-12-4" name="__codelineno-12-4" href="#__codelineno-12-4"></a><span class="n">model_id</span> <span class="o">=</span> <span class="s2">&quot;bigscience/bloom-1b7&quot;</span>
</span><span id="__span-12-5"><a id="__codelineno-12-5" name="__codelineno-12-5" href="#__codelineno-12-5"></a>
</span><span id="__span-12-6"><a id="__codelineno-12-6" name="__codelineno-12-6" href="#__codelineno-12-6"></a><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_id</span><span class="p">)</span>
</span><span id="__span-12-7"><a id="__codelineno-12-7" name="__codelineno-12-7" href="#__codelineno-12-7"></a><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_id</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="n">quantization_config</span><span class="o">=</span><span class="n">BitsAndBytesConfig</span><span class="p">(</span><span class="n">load_in_4bit</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</span></code></pre></div>
<p><Tip warning={true}></p>
<p>ãƒ¢ãƒ‡ãƒ«ãŒ 4 ãƒ“ãƒƒãƒˆã§ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã‚‹ã¨ã€ç¾æ™‚ç‚¹ã§ã¯é‡å­åŒ–ã•ã‚ŒãŸé‡ã¿ã‚’ãƒãƒ–ã«ãƒ—ãƒƒã‚·ãƒ¥ã™ã‚‹ã“ã¨ã¯ã§ããªã„ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚ 4 ãƒ“ãƒƒãƒˆã®é‡ã¿ã¯ã¾ã ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãŸã‚ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã§ããªã„ã“ã¨ã«ã‚‚æ³¨æ„ã—ã¦ãã ã•ã„ã€‚ãŸã ã—ã€4 ãƒ“ãƒƒãƒˆ ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦è¿½åŠ ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚ã“ã‚Œã«ã¤ã„ã¦ã¯æ¬¡ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§èª¬æ˜ã—ã¾ã™ã€‚</p>
<p></Tip></p>
<h3 id="load-a-large-model-in-8bit">Load a large model in 8bit</h3>
<p><code>.from_pretrained</code> ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å‘¼ã³å‡ºã™ã¨ãã« <code>load_in_8bit=True</code> å¼•æ•°ã‚’ä½¿ç”¨ã™ã‚‹ã¨ã€ãƒ¡ãƒ¢ãƒªè¦ä»¶ã‚’ãŠã‚ˆãåŠåˆ†ã«ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-13-1"><a id="__codelineno-13-1" name="__codelineno-13-1" href="#__codelineno-13-1"></a><span class="c1"># pip install transformers accelerate bitsandbytes</span>
</span><span id="__span-13-2"><a id="__codelineno-13-2" name="__codelineno-13-2" href="#__codelineno-13-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">BitsAndBytesConfig</span>
</span><span id="__span-13-3"><a id="__codelineno-13-3" name="__codelineno-13-3" href="#__codelineno-13-3"></a>
</span><span id="__span-13-4"><a id="__codelineno-13-4" name="__codelineno-13-4" href="#__codelineno-13-4"></a><span class="n">model_id</span> <span class="o">=</span> <span class="s2">&quot;bigscience/bloom-1b7&quot;</span>
</span><span id="__span-13-5"><a id="__codelineno-13-5" name="__codelineno-13-5" href="#__codelineno-13-5"></a>
</span><span id="__span-13-6"><a id="__codelineno-13-6" name="__codelineno-13-6" href="#__codelineno-13-6"></a><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_id</span><span class="p">)</span>
</span><span id="__span-13-7"><a id="__codelineno-13-7" name="__codelineno-13-7" href="#__codelineno-13-7"></a><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_id</span><span class="p">,</span> <span class="n">quantization_config</span><span class="o">=</span><span class="n">BitsAndBytesConfig</span><span class="p">(</span><span class="n">load_in_8bit</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</span></code></pre></div>
<p>æ¬¡ã«ã€é€šå¸¸ [<code>PreTrainedModel</code>] ã‚’ä½¿ç”¨ã™ã‚‹ã®ã¨åŒã˜ã‚ˆã†ã«ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚</p>
<p><code>get_memory_footprint</code> ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ¡ãƒ¢ãƒª ãƒ•ãƒƒãƒˆãƒ—ãƒªãƒ³ãƒˆã‚’ç¢ºèªã§ãã¾ã™ã€‚</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-14-1"><a id="__codelineno-14-1" name="__codelineno-14-1" href="#__codelineno-14-1"></a><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">get_memory_footprint</span><span class="p">())</span>
</span></code></pre></div>
<p>ã“ã®çµ±åˆã«ã‚ˆã‚Šã€å¤§ããªãƒ¢ãƒ‡ãƒ«ã‚’å°ã•ãªãƒ‡ãƒã‚¤ã‚¹ã«ãƒ­ãƒ¼ãƒ‰ã—ã€å•é¡Œãªãå®Ÿè¡Œã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚</p>
<p><Tip warning={true}>
ãƒ¢ãƒ‡ãƒ«ãŒ 8 ãƒ“ãƒƒãƒˆã§ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã‚‹ã¨ã€æœ€æ–°ã® <code>transformers</code>ã¨<code>bitsandbytes</code>ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã‚’é™¤ãã€é‡å­åŒ–ã•ã‚ŒãŸé‡ã¿ã‚’ãƒãƒ–ã«ãƒ—ãƒƒã‚·ãƒ¥ã™ã‚‹ã“ã¨ã¯ç¾åœ¨ä¸å¯èƒ½ã§ã‚ã‚‹ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚ 8 ãƒ“ãƒƒãƒˆã®é‡ã¿ã¯ã¾ã ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãŸã‚ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã§ããªã„ã“ã¨ã«ã‚‚æ³¨æ„ã—ã¦ãã ã•ã„ã€‚ãŸã ã—ã€8 ãƒ“ãƒƒãƒˆ ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦è¿½åŠ ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚ã“ã‚Œã«ã¤ã„ã¦ã¯æ¬¡ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§èª¬æ˜ã—ã¾ã™ã€‚
ã¾ãŸã€<code>device_map</code> ã¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ã™ãŒã€åˆ©ç”¨å¯èƒ½ãªãƒªã‚½ãƒ¼ã‚¹ä¸Šã§ãƒ¢ãƒ‡ãƒ«ã‚’åŠ¹ç‡çš„ã«ãƒ‡ã‚£ã‚¹ãƒ‘ãƒƒãƒã™ã‚‹ãŸã‚ã€æ¨è«–ã«ã¯ <code>device_map = 'auto'</code> ã‚’è¨­å®šã™ã‚‹ã“ã¨ãŒæ¨å¥¨ã•ã‚Œã¾ã™ã€‚</p>
<p></Tip></p>
<h4 id="advanced-use-cases">Advanced use cases</h4>
<p>ã“ã“ã§ã¯ã€FP4 é‡å­åŒ–ã‚’ä½¿ç”¨ã—ã¦å®Ÿè¡Œã§ãã‚‹ã„ãã¤ã‹ã®é«˜åº¦ãªä½¿ç”¨ä¾‹ã«ã¤ã„ã¦èª¬æ˜ã—ã¾ã™ã€‚</p>
<h5 id="change-the-compute-dtype">Change the compute dtype</h5>
<p>compute dtype ã¯ã€è¨ˆç®—ä¸­ã«ä½¿ç”¨ã•ã‚Œã‚‹ dtype ã‚’å¤‰æ›´ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚ãŸã¨ãˆã°ã€éš ã—çŠ¶æ…‹ã¯<code>float32</code>ã«ã‚ã‚Šã¾ã™ãŒã€é«˜é€ŸåŒ–ã®ãŸã‚ã«è¨ˆç®—ã‚’ bf16 ã«è¨­å®šã§ãã¾ã™ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯ã€compute dtype ã¯ <code>float32</code> ã«è¨­å®šã•ã‚Œã¾ã™ã€‚</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-15-1"><a id="__codelineno-15-1" name="__codelineno-15-1" href="#__codelineno-15-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="__span-15-2"><a id="__codelineno-15-2" name="__codelineno-15-2" href="#__codelineno-15-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">BitsAndBytesConfig</span>
</span><span id="__span-15-3"><a id="__codelineno-15-3" name="__codelineno-15-3" href="#__codelineno-15-3"></a>
</span><span id="__span-15-4"><a id="__codelineno-15-4" name="__codelineno-15-4" href="#__codelineno-15-4"></a><span class="n">quantization_config</span> <span class="o">=</span> <span class="n">BitsAndBytesConfig</span><span class="p">(</span><span class="n">load_in_4bit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">bnb_4bit_compute_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">)</span>
</span></code></pre></div>
<h5 id="using-nf4-normal-float-4-data-type">Using NF4 (Normal Float 4) data type</h5>
<p>NF4 ãƒ‡ãƒ¼ã‚¿å‹ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚ã“ã‚Œã¯ã€æ­£è¦åˆ†å¸ƒã‚’ä½¿ç”¨ã—ã¦åˆæœŸåŒ–ã•ã‚ŒãŸé‡ã¿ã«é©åˆã—ãŸæ–°ã—ã„ 4 ãƒ“ãƒƒãƒˆ ãƒ‡ãƒ¼ã‚¿å‹ã§ã™ã€‚ãã®å®Ÿè¡Œã®ãŸã‚ã«:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-16-1"><a id="__codelineno-16-1" name="__codelineno-16-1" href="#__codelineno-16-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">BitsAndBytesConfig</span>
</span><span id="__span-16-2"><a id="__codelineno-16-2" name="__codelineno-16-2" href="#__codelineno-16-2"></a>
</span><span id="__span-16-3"><a id="__codelineno-16-3" name="__codelineno-16-3" href="#__codelineno-16-3"></a><span class="n">nf4_config</span> <span class="o">=</span> <span class="n">BitsAndBytesConfig</span><span class="p">(</span>
</span><span id="__span-16-4"><a id="__codelineno-16-4" name="__codelineno-16-4" href="#__codelineno-16-4"></a>    <span class="n">load_in_4bit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="__span-16-5"><a id="__codelineno-16-5" name="__codelineno-16-5" href="#__codelineno-16-5"></a>    <span class="n">bnb_4bit_quant_type</span><span class="o">=</span><span class="s2">&quot;nf4&quot;</span><span class="p">,</span>
</span><span id="__span-16-6"><a id="__codelineno-16-6" name="__codelineno-16-6" href="#__codelineno-16-6"></a><span class="p">)</span>
</span><span id="__span-16-7"><a id="__codelineno-16-7" name="__codelineno-16-7" href="#__codelineno-16-7"></a>
</span><span id="__span-16-8"><a id="__codelineno-16-8" name="__codelineno-16-8" href="#__codelineno-16-8"></a><span class="n">model_nf4</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_id</span><span class="p">,</span> <span class="n">quantization_config</span><span class="o">=</span><span class="n">nf4_config</span><span class="p">)</span>
</span></code></pre></div>
<h5 id="use-nested-quantization-for-more-memory-efficient-inference">Use nested quantization for more memory efficient inference</h5>
<p>ã¾ãŸã€ãƒã‚¹ãƒˆã•ã‚ŒãŸé‡å­åŒ–æ‰‹æ³•ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ãªãã€ã‚ˆã‚Šå¤šãã®ãƒ¡ãƒ¢ãƒªãŒç¯€ç´„ã•ã‚Œã¾ã™ã€‚çµŒé¨“çš„ãªè¦³å¯Ÿã‹ã‚‰ã€ã“ã‚Œã«ã‚ˆã‚Šã€NVIDIA-T4 16GB ä¸Šã§ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•· 1024ã€ãƒãƒƒãƒ ã‚µã‚¤ã‚º 1ã€å‹¾é…ç´¯ç©ã‚¹ãƒ†ãƒƒãƒ— 4 ã® llama-13b ãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã™ã‚‹ã“ã¨ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-17-1"><a id="__codelineno-17-1" name="__codelineno-17-1" href="#__codelineno-17-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">BitsAndBytesConfig</span>
</span><span id="__span-17-2"><a id="__codelineno-17-2" name="__codelineno-17-2" href="#__codelineno-17-2"></a>
</span><span id="__span-17-3"><a id="__codelineno-17-3" name="__codelineno-17-3" href="#__codelineno-17-3"></a><span class="n">double_quant_config</span> <span class="o">=</span> <span class="n">BitsAndBytesConfig</span><span class="p">(</span>
</span><span id="__span-17-4"><a id="__codelineno-17-4" name="__codelineno-17-4" href="#__codelineno-17-4"></a>    <span class="n">load_in_4bit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="__span-17-5"><a id="__codelineno-17-5" name="__codelineno-17-5" href="#__codelineno-17-5"></a>    <span class="n">bnb_4bit_use_double_quant</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="__span-17-6"><a id="__codelineno-17-6" name="__codelineno-17-6" href="#__codelineno-17-6"></a><span class="p">)</span>
</span><span id="__span-17-7"><a id="__codelineno-17-7" name="__codelineno-17-7" href="#__codelineno-17-7"></a>
</span><span id="__span-17-8"><a id="__codelineno-17-8" name="__codelineno-17-8" href="#__codelineno-17-8"></a><span class="n">model_double_quant</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_id</span><span class="p">,</span> <span class="n">quantization_config</span><span class="o">=</span><span class="n">double_quant_config</span><span class="p">)</span>
</span></code></pre></div>
<h3 id="push-quantized-models-on-the-hub">Push quantized models on the ğŸ¤— Hub</h3>
<p><code>push_to_hub</code>ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å˜ç´”ã«ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€é‡å­åŒ–ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ãƒãƒ–ã«ãƒ—ãƒƒã‚·ãƒ¥ã§ãã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æœ€åˆã«é‡å­åŒ–æ§‹æˆãƒ•ã‚¡ã‚¤ãƒ«ãŒãƒ—ãƒƒã‚·ãƒ¥ã•ã‚Œã€æ¬¡ã«é‡å­åŒ–ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ãŒãƒ—ãƒƒã‚·ãƒ¥ã•ã‚Œã¾ã™ã€‚
ã“ã®æ©Ÿèƒ½ã‚’ä½¿ç”¨ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã«ã¯ã€å¿…ãš <code>bitsandbytes&gt;0.37.2</code> ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ (ã“ã®è¨˜äº‹ã®åŸ·ç­†æ™‚ç‚¹ã§ã¯ã€<code>bitsandbytes==0.38.0.post1</code> ã§ãƒ†ã‚¹ãƒˆã—ã¾ã—ãŸ)ã€‚</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-18-1"><a id="__codelineno-18-1" name="__codelineno-18-1" href="#__codelineno-18-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">BitsAndBytesConfig</span>
</span><span id="__span-18-2"><a id="__codelineno-18-2" name="__codelineno-18-2" href="#__codelineno-18-2"></a>
</span><span id="__span-18-3"><a id="__codelineno-18-3" name="__codelineno-18-3" href="#__codelineno-18-3"></a><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;bigscience/bloom-560m&quot;</span><span class="p">,</span> <span class="n">quantization_config</span><span class="o">=</span><span class="n">BitsAndBytesConfig</span><span class="p">(</span><span class="n">load_in_8bit</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</span><span id="__span-18-4"><a id="__codelineno-18-4" name="__codelineno-18-4" href="#__codelineno-18-4"></a><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;bigscience/bloom-560m&quot;</span><span class="p">)</span>
</span><span id="__span-18-5"><a id="__codelineno-18-5" name="__codelineno-18-5" href="#__codelineno-18-5"></a>
</span><span id="__span-18-6"><a id="__codelineno-18-6" name="__codelineno-18-6" href="#__codelineno-18-6"></a><span class="n">model</span><span class="o">.</span><span class="n">push_to_hub</span><span class="p">(</span><span class="s2">&quot;bloom-560m-8bit&quot;</span><span class="p">)</span>
</span></code></pre></div>
<p><Tip warning={true}></p>
<p>å¤§è¦æ¨¡ãªãƒ¢ãƒ‡ãƒ«ã§ã¯ã€ãƒãƒ–ä¸Šã§ 8 ãƒ“ãƒƒãƒˆ ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ—ãƒƒã‚·ãƒ¥ã™ã‚‹ã“ã¨ãŒå¼·ãæ¨å¥¨ã•ã‚Œã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã¯ãƒ¡ãƒ¢ãƒª ãƒ•ãƒƒãƒˆãƒ—ãƒªãƒ³ãƒˆã®å‰Šæ¸›ã¨ã€ãŸã¨ãˆã° Google Colab ã§ã®å¤§è¦æ¨¡ãªãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«ã‚ˆã‚‹æ©æµã‚’å—ã‘ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚</p>
<p></Tip></p>
<h3 id="load-a-quantized-model-from-the-hub_1">Load a quantized model from the ğŸ¤— Hub</h3>
<p><code>from_pretrained</code>ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã—ã¦ã€ãƒãƒ–ã‹ã‚‰é‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚å±æ€§ <code>quantization_config</code> ãŒãƒ¢ãƒ‡ãƒ«è¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ã€ãƒ—ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸé‡ã¿ãŒé‡å­åŒ–ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¾ã™ã€‚</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-19-1"><a id="__codelineno-19-1" name="__codelineno-19-1" href="#__codelineno-19-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span>
</span><span id="__span-19-2"><a id="__codelineno-19-2" name="__codelineno-19-2" href="#__codelineno-19-2"></a>
</span><span id="__span-19-3"><a id="__codelineno-19-3" name="__codelineno-19-3" href="#__codelineno-19-3"></a><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{your_username}</span><span class="s2">/bloom-560m-8bit&quot;</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>
</span></code></pre></div>
<p>ã“ã®å ´åˆã€å¼•æ•° <code>load_in_8bit=True</code> ã‚’æŒ‡å®šã™ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ãŒã€<code>bitsandbytes</code> ã¨ <code>accelerate</code> ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚
ã¾ãŸã€<code>device_map</code> ã¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ã™ãŒã€åˆ©ç”¨å¯èƒ½ãªãƒªã‚½ãƒ¼ã‚¹ä¸Šã§ãƒ¢ãƒ‡ãƒ«ã‚’åŠ¹ç‡çš„ã«ãƒ‡ã‚£ã‚¹ãƒ‘ãƒƒãƒã™ã‚‹ãŸã‚ã€æ¨è«–ã«ã¯ <code>device_map = 'auto'</code> ã‚’è¨­å®šã™ã‚‹ã“ã¨ãŒæ¨å¥¨ã•ã‚Œã¾ã™ã€‚</p>
<h3 id="advanced-use-cases_1">Advanced use cases</h3>
<p>ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯ã€8 ãƒ“ãƒƒãƒˆ ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã¨å®Ÿè¡Œä»¥å¤–ã«ä½•ãŒã§ãã‚‹ã‹ã‚’æ¢æ±‚ã—ãŸã„ä¸Šç´šãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’å¯¾è±¡ã¨ã—ã¦ã„ã¾ã™ã€‚</p>
<h4 id="offload-between-cpu-and-gpu">Offload between <code>cpu</code> and <code>gpu</code></h4>
<p>ã“ã®é«˜åº¦ãªä½¿ç”¨ä¾‹ã® 1 ã¤ã¯ã€ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã€<code>CPU</code>ã¨<code>GPU</code>ã®é–“ã§é‡ã¿ã‚’ãƒ‡ã‚£ã‚¹ãƒ‘ãƒƒãƒã§ãã‚‹ã“ã¨ã§ã™ã€‚ CPU ä¸Šã§ãƒ‡ã‚£ã‚¹ãƒ‘ãƒƒãƒã•ã‚Œã‚‹é‡ã¿ã¯ <strong>8 ãƒ“ãƒƒãƒˆã«å¤‰æ›ã•ã‚Œãªã„</strong>ãŸã‚ã€<code>float32</code>ã«ä¿æŒã•ã‚Œã‚‹ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚ã“ã®æ©Ÿèƒ½ã¯ã€éå¸¸ã«å¤§è¦æ¨¡ãªãƒ¢ãƒ‡ãƒ«ã‚’é©åˆã•ã›ã€ãã®ãƒ¢ãƒ‡ãƒ«ã‚’ GPU ã¨ CPU ã®é–“ã§ãƒ‡ã‚£ã‚¹ãƒ‘ãƒƒãƒã—ãŸã„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’å¯¾è±¡ã¨ã—ã¦ã„ã¾ã™ã€‚</p>
<p>ã¾ãšã€<code>transformers</code> ã‹ã‚‰ [<code>BitsAndBytesConfig</code>] ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã€å±æ€§ <code>llm_int8_enable_fp32_cpu_offload</code> ã‚’ <code>True</code> ã«è¨­å®šã—ã¾ã™ã€‚</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-20-1"><a id="__codelineno-20-1" name="__codelineno-20-1" href="#__codelineno-20-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">BitsAndBytesConfig</span>
</span><span id="__span-20-2"><a id="__codelineno-20-2" name="__codelineno-20-2" href="#__codelineno-20-2"></a>
</span><span id="__span-20-3"><a id="__codelineno-20-3" name="__codelineno-20-3" href="#__codelineno-20-3"></a><span class="n">quantization_config</span> <span class="o">=</span> <span class="n">BitsAndBytesConfig</span><span class="p">(</span><span class="n">llm_int8_enable_fp32_cpu_offload</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></code></pre></div>
<p><code>bigscience/bloom-1b7</code>ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã€<code>lm_head</code>ã‚’é™¤ããƒ¢ãƒ‡ãƒ«å…¨ä½“ã«â€‹â€‹é©åˆã™ã‚‹ã®ã«ååˆ†ãª GPU RAM ãŒã‚ã‚‹ã¨ã—ã¾ã™ã€‚ã—ãŸãŒã£ã¦ã€æ¬¡ã®ã‚ˆã†ã«ã‚«ã‚¹ã‚¿ãƒ  device_map ã‚’ä½œæˆã—ã¾ã™ã€‚</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-21-1"><a id="__codelineno-21-1" name="__codelineno-21-1" href="#__codelineno-21-1"></a><span class="n">device_map</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="__span-21-2"><a id="__codelineno-21-2" name="__codelineno-21-2" href="#__codelineno-21-2"></a>    <span class="s2">&quot;transformer.word_embeddings&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="__span-21-3"><a id="__codelineno-21-3" name="__codelineno-21-3" href="#__codelineno-21-3"></a>    <span class="s2">&quot;transformer.word_embeddings_layernorm&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="__span-21-4"><a id="__codelineno-21-4" name="__codelineno-21-4" href="#__codelineno-21-4"></a>    <span class="s2">&quot;lm_head&quot;</span><span class="p">:</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
</span><span id="__span-21-5"><a id="__codelineno-21-5" name="__codelineno-21-5" href="#__codelineno-21-5"></a>    <span class="s2">&quot;transformer.h&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="__span-21-6"><a id="__codelineno-21-6" name="__codelineno-21-6" href="#__codelineno-21-6"></a>    <span class="s2">&quot;transformer.ln_f&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="__span-21-7"><a id="__codelineno-21-7" name="__codelineno-21-7" href="#__codelineno-21-7"></a><span class="p">}</span>
</span></code></pre></div>
<p>ãã—ã¦ã€æ¬¡ã®ã‚ˆã†ã«ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚
<div class="language-python highlight"><pre><span></span><code><span id="__span-22-1"><a id="__codelineno-22-1" name="__codelineno-22-1" href="#__codelineno-22-1"></a><span class="n">model_8bit</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
</span><span id="__span-22-2"><a id="__codelineno-22-2" name="__codelineno-22-2" href="#__codelineno-22-2"></a>    <span class="s2">&quot;bigscience/bloom-1b7&quot;</span><span class="p">,</span>
</span><span id="__span-22-3"><a id="__codelineno-22-3" name="__codelineno-22-3" href="#__codelineno-22-3"></a>    <span class="n">device_map</span><span class="o">=</span><span class="n">device_map</span><span class="p">,</span>
</span><span id="__span-22-4"><a id="__codelineno-22-4" name="__codelineno-22-4" href="#__codelineno-22-4"></a>    <span class="n">quantization_config</span><span class="o">=</span><span class="n">quantization_config</span><span class="p">,</span>
</span><span id="__span-22-5"><a id="__codelineno-22-5" name="__codelineno-22-5" href="#__codelineno-22-5"></a><span class="p">)</span>
</span></code></pre></div></p>
<p>ä»¥ä¸Šã§ã™ï¼ãƒ¢ãƒ‡ãƒ«ã‚’æ¥½ã—ã‚“ã§ãã ã•ã„ï¼</p>
<h4 id="play-with-llm_int8_threshold">Play with <code>llm_int8_threshold</code></h4>
<p><code>llm_int8_threshold</code> å¼•æ•°ã‚’æ“ä½œã—ã¦ã€å¤–ã‚Œå€¤ã®ã—ãã„å€¤ã‚’å¤‰æ›´ã§ãã¾ã™ã€‚ å¤–ã‚Œå€¤ ã¨ã¯ã€ç‰¹å®šã®ã—ãã„å€¤ã‚ˆã‚Šå¤§ãã„éš ã‚ŒãŸçŠ¶æ…‹ã®å€¤ã§ã™ã€‚
ã“ã‚Œã¯ã€<code>LLM.int8()</code>è«–æ–‡ã§èª¬æ˜ã•ã‚Œã¦ã„ã‚‹å¤–ã‚Œå€¤æ¤œå‡ºã®å¤–ã‚Œå€¤ã—ãã„å€¤ã«å¯¾å¿œã—ã¾ã™ã€‚ã“ã®ã—ãã„å€¤ã‚’è¶…ãˆã‚‹éš ã—çŠ¶æ…‹ã®å€¤ã¯å¤–ã‚Œå€¤ã¨ã¿ãªã•ã‚Œã€ãã‚Œã‚‰ã®å€¤ã«å¯¾ã™ã‚‹æ“ä½œã¯ fp16 ã§å®Ÿè¡Œã•ã‚Œã¾ã™ã€‚é€šå¸¸ã€å€¤ã¯æ­£è¦åˆ†å¸ƒã—ã¾ã™ã€‚ã¤ã¾ã‚Šã€ã»ã¨ã‚“ã©ã®å€¤ã¯ [-3.5, 3.5] ã®ç¯„å›²å†…ã«ã‚ã‚Šã¾ã™ãŒã€å¤§è¦æ¨¡ãªãƒ¢ãƒ‡ãƒ«ã§ã¯å¤§ããç•°ãªã‚‹åˆ†å¸ƒã‚’ç¤ºã™ä¾‹å¤–çš„ãªç³»çµ±çš„å¤–ã‚Œå€¤ãŒã„ãã¤ã‹ã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã‚‰ã®å¤–ã‚Œå€¤ã¯ã€å¤šãã®å ´åˆ [-60, -6] ã¾ãŸã¯ [6, 60] ã®ç¯„å›²å†…ã«ã‚ã‚Šã¾ã™ã€‚ Int8 é‡å­åŒ–ã¯ã€å¤§ãã•ãŒ 5 ç¨‹åº¦ã¾ã§ã®å€¤ã§ã¯ã†ã¾ãæ©Ÿèƒ½ã—ã¾ã™ãŒã€ãã‚Œã‚’è¶…ãˆã‚‹ã¨ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå¤§å¹…ã«ä½ä¸‹ã—ã¾ã™ã€‚é©åˆ‡ãªãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã—ãã„å€¤ã¯ 6 ã§ã™ãŒã€ã‚ˆã‚Šä¸å®‰å®šãªãƒ¢ãƒ‡ãƒ« (å°è¦æ¨¡ãªãƒ¢ãƒ‡ãƒ«ã€å¾®èª¿æ•´) ã§ã¯ã€ã‚ˆã‚Šä½ã„ã—ãã„å€¤ãŒå¿…è¦ã«ãªã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚
ã“ã®å¼•æ•°ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®æ¨è«–é€Ÿåº¦ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã“ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è©¦ã—ã¦ã¿ã¦ã€ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã«æœ€é©ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¦‹ã¤ã‘ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-23-1"><a id="__codelineno-23-1" name="__codelineno-23-1" href="#__codelineno-23-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">BitsAndBytesConfig</span>
</span><span id="__span-23-2"><a id="__codelineno-23-2" name="__codelineno-23-2" href="#__codelineno-23-2"></a>
</span><span id="__span-23-3"><a id="__codelineno-23-3" name="__codelineno-23-3" href="#__codelineno-23-3"></a><span class="n">model_id</span> <span class="o">=</span> <span class="s2">&quot;bigscience/bloom-1b7&quot;</span>
</span><span id="__span-23-4"><a id="__codelineno-23-4" name="__codelineno-23-4" href="#__codelineno-23-4"></a>
</span><span id="__span-23-5"><a id="__codelineno-23-5" name="__codelineno-23-5" href="#__codelineno-23-5"></a><span class="n">quantization_config</span> <span class="o">=</span> <span class="n">BitsAndBytesConfig</span><span class="p">(</span>
</span><span id="__span-23-6"><a id="__codelineno-23-6" name="__codelineno-23-6" href="#__codelineno-23-6"></a>    <span class="n">llm_int8_threshold</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
</span><span id="__span-23-7"><a id="__codelineno-23-7" name="__codelineno-23-7" href="#__codelineno-23-7"></a><span class="p">)</span>
</span><span id="__span-23-8"><a id="__codelineno-23-8" name="__codelineno-23-8" href="#__codelineno-23-8"></a>
</span><span id="__span-23-9"><a id="__codelineno-23-9" name="__codelineno-23-9" href="#__codelineno-23-9"></a><span class="n">model_8bit</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
</span><span id="__span-23-10"><a id="__codelineno-23-10" name="__codelineno-23-10" href="#__codelineno-23-10"></a>    <span class="n">model_id</span><span class="p">,</span>
</span><span id="__span-23-11"><a id="__codelineno-23-11" name="__codelineno-23-11" href="#__codelineno-23-11"></a>    <span class="n">device_map</span><span class="o">=</span><span class="n">device_map</span><span class="p">,</span>
</span><span id="__span-23-12"><a id="__codelineno-23-12" name="__codelineno-23-12" href="#__codelineno-23-12"></a>    <span class="n">quantization_config</span><span class="o">=</span><span class="n">quantization_config</span><span class="p">,</span>
</span><span id="__span-23-13"><a id="__codelineno-23-13" name="__codelineno-23-13" href="#__codelineno-23-13"></a><span class="p">)</span>
</span><span id="__span-23-14"><a id="__codelineno-23-14" name="__codelineno-23-14" href="#__codelineno-23-14"></a><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_id</span><span class="p">)</span>
</span></code></pre></div>
<h4 id="skip-the-conversion-of-some-modules">Skip the conversion of some modules</h4>
<p>ä¸€éƒ¨ã®ãƒ¢ãƒ‡ãƒ«ã«ã¯ã€å®‰å®šæ€§ã‚’ç¢ºä¿ã™ã‚‹ãŸã‚ã« 8 ãƒ“ãƒƒãƒˆã«å¤‰æ›ã™ã‚‹å¿…è¦ãŒãªã„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒã„ãã¤ã‹ã‚ã‚Šã¾ã™ã€‚ãŸã¨ãˆã°ã€ã‚¸ãƒ¥ãƒ¼ã‚¯ãƒœãƒƒã‚¯ã‚¹ ãƒ¢ãƒ‡ãƒ«ã«ã¯ã€ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã„ãã¤ã‹ã® <code>lm_head</code> ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒã‚ã‚Šã¾ã™ã€‚ <code>llm_int8_skip_modules</code> ã§éŠã‚“ã§ã¿ã‚‹</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-24-1"><a id="__codelineno-24-1" name="__codelineno-24-1" href="#__codelineno-24-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">BitsAndBytesConfig</span>
</span><span id="__span-24-2"><a id="__codelineno-24-2" name="__codelineno-24-2" href="#__codelineno-24-2"></a>
</span><span id="__span-24-3"><a id="__codelineno-24-3" name="__codelineno-24-3" href="#__codelineno-24-3"></a><span class="n">model_id</span> <span class="o">=</span> <span class="s2">&quot;bigscience/bloom-1b7&quot;</span>
</span><span id="__span-24-4"><a id="__codelineno-24-4" name="__codelineno-24-4" href="#__codelineno-24-4"></a>
</span><span id="__span-24-5"><a id="__codelineno-24-5" name="__codelineno-24-5" href="#__codelineno-24-5"></a><span class="n">quantization_config</span> <span class="o">=</span> <span class="n">BitsAndBytesConfig</span><span class="p">(</span>
</span><span id="__span-24-6"><a id="__codelineno-24-6" name="__codelineno-24-6" href="#__codelineno-24-6"></a>    <span class="n">llm_int8_skip_modules</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;lm_head&quot;</span><span class="p">],</span>
</span><span id="__span-24-7"><a id="__codelineno-24-7" name="__codelineno-24-7" href="#__codelineno-24-7"></a><span class="p">)</span>
</span><span id="__span-24-8"><a id="__codelineno-24-8" name="__codelineno-24-8" href="#__codelineno-24-8"></a>
</span><span id="__span-24-9"><a id="__codelineno-24-9" name="__codelineno-24-9" href="#__codelineno-24-9"></a><span class="n">model_8bit</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
</span><span id="__span-24-10"><a id="__codelineno-24-10" name="__codelineno-24-10" href="#__codelineno-24-10"></a>    <span class="n">model_id</span><span class="p">,</span>
</span><span id="__span-24-11"><a id="__codelineno-24-11" name="__codelineno-24-11" href="#__codelineno-24-11"></a>    <span class="n">device_map</span><span class="o">=</span><span class="n">device_map</span><span class="p">,</span>
</span><span id="__span-24-12"><a id="__codelineno-24-12" name="__codelineno-24-12" href="#__codelineno-24-12"></a>    <span class="n">quantization_config</span><span class="o">=</span><span class="n">quantization_config</span><span class="p">,</span>
</span><span id="__span-24-13"><a id="__codelineno-24-13" name="__codelineno-24-13" href="#__codelineno-24-13"></a><span class="p">)</span>
</span><span id="__span-24-14"><a id="__codelineno-24-14" name="__codelineno-24-14" href="#__codelineno-24-14"></a><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_id</span><span class="p">)</span>
</span></code></pre></div>
<h4 id="fine-tune-a-model-that-has-been-loaded-in-8-bit">Fine-tune a model that has been loaded in 8-bit</h4>
<p>Hugging Face ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã®å…¬å¼ã‚µãƒãƒ¼ãƒˆã«ã‚ˆã‚Šã€8 ãƒ“ãƒƒãƒˆã§ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã§ãã¾ã™ã€‚
ã“ã‚Œã«ã‚ˆã‚Šã€å˜ä¸€ã® Google Colab ã§<code>flan-t5-large</code>ã‚„<code>facebook/opt-6.7b</code>ãªã©ã®å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚è©³ç´°ã«ã¤ã„ã¦ã¯ã€<a href="https://github.com/huggingface/peft"><code>peft</code></a> ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã”è¦§ãã ã•ã„ã€‚</p>
<p>ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ãã« <code>device_map</code> ã‚’æ¸¡ã™å¿…è¦ãŒãªã„ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚ãƒ¢ãƒ‡ãƒ«ãŒ GPU ã«è‡ªå‹•çš„ã«ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã™ã€‚å¿…è¦ã«å¿œã˜ã¦ã€ãƒ‡ãƒã‚¤ã‚¹ ãƒãƒƒãƒ—ã‚’ç‰¹å®šã®ãƒ‡ãƒã‚¤ã‚¹ã«è¨­å®šã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ (ä¾‹: <code>cuda:0</code>ã€<code>0</code>ã€<code>torch.device('cuda:0')</code>)ã€‚ <code>device_map=auto</code>ã¯æ¨è«–ã®ã¿ã«ä½¿ç”¨ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚</p>
<h3 id="bitsandbytesconfig">BitsAndBytesConfig</h3>
<p>[[autodoc]] BitsAndBytesConfig</p>
<h2 id="quantization-with-optimum">Quantization with ğŸ¤— <code>optimum</code></h2>
<p><code>optimum</code>ã§ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹é‡å­åŒ–æ–¹æ³•ã®è©³ç´°ã«ã¤ã„ã¦ã¯ã€<a href="https://huggingface.co/docs/optimum/index">Optimum ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ</a> ã‚’å‚ç…§ã—ã€ã“ã‚Œã‚‰ãŒè‡ªåˆ†ã®ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã«é©ç”¨ã§ãã‚‹ã‹ã©ã†ã‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚</p>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../../../../../../..", "features": ["navigation.tabs", "navigation.indexes", "navigation.instant", "navigation.sections", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow", "content.tabs.link", "content.code.copy"], "search": "../../../../../../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../../../../../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
    
  </body>
</html>